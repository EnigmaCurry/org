#+hugo_base_dir: ../hugo
#+hugo_section: /linux-workstation
#+hugo_weight: auto
#+hugo_paired_shortcodes: %notice badge button %children %index run stdout edit math mermaid openapi %env toc
#+STARTUP: align

* Linux Workstation
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 190
:END:

This book describes how I setup a Linux Workstation (on a personal
Desktop or Laptop computer).

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

* Introduction
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: introduction
:END:

** Introduction
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 200
:END:

A Linux Workstation is a single user computer that you use as your
primary interface for computing, especially for "work" purposes. At a
bare minimum, a workstation includes a keyboard and a display
(although a workstation could also be a VPS that you SSH into, this book
will focus on /physical/ workstations).

Historically, there has been a hardware distinction between a personal
computer (PC) and a Unix workstation, but ever since the introduction
of Linux, the difference in hardware doesn't really matter anymore,
and any computing device can become a workstation. The only important
distinction for a workstation is the role that it serves, and how
/you/ configure and use it on a daily basis.

The role of a workstation is very different than that of a server. A
workstation's only purpose is to serve /you/, during the moments that
you are interfacing with its physical keyboard/display. A workstation
is usually connected to a network, but only as a client (terminal, web
browser, etc.), not as a server. (Of course, you may bend this rule if
you like, to make your computer a server-workstation, or
"Sworkstation", but it is cleaner, and more secure, to use separate
[virtual] machines for all servers, even for development purposes.)

This book will describe my preferred method for setting up a new
computer, for use as a personal Linux workstation. It will also show
you how to bend the rules a bit, and create a few virtual machines
(VM) for running local development servers (Docker), or even public,
production-lite, and/or LAN party services.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

** Fedora Sway Atomic
:PROPERTIES:
:EXPORT_FILE_NAME: fedora-sway-atomic
:END:

I have tried a great many different Linux distributions over the
years, but I have recently settled on using [[https://fedoraproject.org/atomic-desktops/sway/][Fedora Sway Atomic]] for my
desktop and laptop workstations.

[[https://github.com/swaywm/sway][Sway]] is a minimal tiling window manager for Wayland. It is ideal for
efficient keyboard centric development and for getting out of your
way.

The "Atomic" part refers to [[https://coreos.github.io/rpm-ostree/][rpm-ostree]], which was originally used by
the CoreOS team to build an operating system that is built entirely to
support containers. The root file system of an Atomic host is mounted
read-only, and the packages are distributed in an image, rather than
installed individually. This makes updating (or rolling back) the
system far easier, and makes for a more stable environment. There is
no need to replace packages one-by-one, you just download the new
image provided by the distro, and then reboot the system to use it.

The base image includes all the typical things everyone needs:
coreutils, a display manager, web browser, terminal apps etc. However,
the base image is still pretty bare bones. Except for a few
directories, the root filesystem is immutable, so the process of
installing packages might be a bit different than what you are familar
with. If you want to install something that isn't in the base image,
you have a few different options:

 * Podman or Docker containers (including toolbox and distrobox).
   Since containers use their own image, they are separate from the
   root image, and can be freely created and destroyed separately (no
   reboot).
   
 * Flatpak is a type of application container that includes all of its
   dependencies, and it is sandboxed/isolated from the host system,
   therefore they can be installed/managed separately from the base
   image.

 * Use rpm-ostree to create a new image *layer*. This extends the root
   atomic layer with extra packages that you want to install natively
   (not in a container). It bundles all of the requested packages into
   a new layer, and this is laid on top of the root atomic layer. The
   machine must boot the combined layers as one image, so therefore
   you must reboot the machine each time you install new packages this
   way.
   
I only use a couple of Flatpak apps for a few things. For almost
everything else I use Podman containers via [[https://docs.fedoraproject.org/en-US/fedora-silverblue/toolbox/][toolbox]] and/or [[https://distrobox.it/][distrobox]]
and these can even include graphical applications. For a few things
that cannot be installed in a container, they are [[/linux-workstation/layering-packages][added as an
rpm-ostree layer]].

** Requirements
:PROPERTIES:
:EXPORT_FILE_NAME: requirements
:END:

You will need the following hardware:

 * An x86_64 desktop or laptop computer.
 * A USB drive for copying the .iso installer to.
 * A [[https://solokeys.com/][solokey]] or other FIDO2 compatible hardware authentication key.
   (This is optional, but highly recommended for storing secure shell
   keys, PGP keys, and logging into websites with Webauthn.)

* Install Linux (Fedora Atomic)
:PROPERTIES:
:EXPORT_FILE_NAME: install
:END:

*** Create USB installation media

#+attr_shortcode: :icon download :style primary :href https://fedoraproject.org/atomic-desktops/sway/download
#+begin_button
Download Fedora Sway Atomic.iso
#+end_button

Assuming you are temporarily using another Linux workstation, write
the .iso image to a USB drive:

#+begin_run
sudo dd if=~/Downloads/Fedora-Sericea-ostree-x86_64-40-1.14.iso \
        of=/dev/sdX bs=10M status=progress conv=sync
#+end_run

#+attr_shortcode: :style info
#+begin_notice
Replace ~/dev/sdX~ with your device name, and double check the =.iso=
filename you downloaded, it may have changed.
#+end_notice

*** Boot the installer

Boot the target workstation computer using the USB drive. It will boot
into the Anaconda install wizard. Just follow the prompts to install
it, it should be straight forward, and it is exactly the same as any
other Fedora / Redhat install.

Tips:

 * Buttons may be in an unexpected position. Sometimes they are found
   in the bottom right corner, other times in the upper left corner.
 * The installation summary page marks all the installaton items that
   you still need to configure. You can visit them in any order. Click
   the items that show an orange alert text, and do what it says.
 * Choosing installation destination:
   * Use the /entire disk/ for the OS install (ie. choose Delete All
     partitions / Reclaim Space). On a secure workstation, it is
     considered unsafe to dual boot any another operating system. If
     you want to run Windows, or play games, use a separate computer
     for that.
   * Enable whole disk encryption and choose a secure passphrase.
     Especially for laptop computers that you may travel with, this an
     important thing to do to keep your files safe at rest.
 * Create a user account, and check the box =Add administrative
   privileges to this user account (wheel group membership)=.
 * Disable the root account. You will use a normal user account and
   =sudo=.
 * Once all options are configured, click =Begin Installation=.

Once the installer finishes, click =Finish Installation=. Reboot,
remove the USB, enter your encryption passphrase to boot, and then log
in to your new system.

*** Login and initial config

Once you're logged in, you need to perform these initial steps.

**** Network Manager

If you are connected to wired ethernet, likely your network is already
active due to DHCP.

If you need to configure WiFi, find the NetworkManager applet in the
top right corner of the default Sway desktop. Click on it, and drop
down into the menu called =Available networks= and choose your WiFi
access point.


**** Open a terminal

Press =Win+Enter= to open a terminal window.

**** Open other apps like web browsers

 * Press =Win+D= to open the =drun= menu.
 * Type =firefox= and press =Enter=.
 * To close a window, press =Win+Shift+Q=.

* Upgrading
:PROPERTIES:
:EXPORT_FILE_NAME: upgrading
:END:

As mentioned before, Fedora Atomic is distributed as a full system
image. You can both upgrade the image, as well as rollback the image
(in case you have any issues with the upgrade.)

To upgrade to the latest image:

#+begin_run
sudo rpm-ostree upgrade
#+end_run

Let it finish downloading the new image, and then you must reboot:

#+begin_run
sudo systemctl reboot
#+end_run
The boot manager lists the last several images, which are still
available to choose from. The default is to boot the newly upgraded
image.

The above will /not/ upgrade to a new release version, eg. Fedora 39
to Fedora 40. It will only update the packages for the currently
installed release.

To find the list of all released versions, run :

#+begin_run
ostree remote refs fedora | grep "$(uname -m)/sericea$"
#+end_run

Upgrade to the new release (eg. 40):

#+begin_run
rpm-ostree rebase fedora:fedora/40/x86_64/sericea
#+end_run

Let it finish downloading the new image, and then reboot again.

* Layering packages
:PROPERTIES:
:EXPORT_FILE_NAME: layering-packages
:END:

See the [[https://docs.fedoraproject.org/en-US/iot/add-layered/][Fedora docs for Adding Layered Packages]]. For most packages,
you should not install them this way, but you should prefer installing
them inside of a /linux-workstation/config/toolbox / distrobox container instead. On the Fedora
Atomic host, you should install (layer) only those packages that
cannot be run from a container (or you really just want to run them
natively for some reason).

*** Layer packages with rpm-ostree

To create efficient layers, *you should try to install everything in
one go*, using as few layers as possible. Here is a list of packages
you might want to add all together as one layer:

#+begin_run
sudo rpm-ostree install wdisplays qemu-kvm libvirt virt-manager \
     virt-viewer virt-install libvirt-daemon-config-network \
     libvirt-daemon-kvm libguestfs-tools python3-libguestfs virt-top \
     net-tools gvfs-smb gvfs-archive gvfs-nfs gvfs-fuse gvfs-mtp \
     distrobox file-roller thunar-volman pamu2fcfg pam-u2f fido2-tools
#+end_run

[[https://fedoraproject.org/atomic-desktops/sway/][Fedora Atomic Sway edition (Sericea) already includes a lot of
packages layered on top of the core Fedora Atomic.]] So before you
install new things, check what comes preinstalled.

*** System reboot is required to load new packages

Everytime you install packages with =rpm-ostree=, you must reboot your
system to load them:

#+begin_run
sudo systemctl reboot
#+end_run

** Examples of applications you might want to layer

 * File explorer (thunar) plugins for archives and removeable drives.
 * Virtual filesystem plugins (gvfs).
 * Container tools (Distrobox).
 * Virtual Machine tools (Qemu and libvirt).
 * Basic network tools (net-tools arp)

Web browsers are fickle. Although they mostly work inside toolbx
containers just fine, Sericea includes Firefox in its base layer as a
native app, and that seems to work great. However, I have also tested
Chromium inside of a toolbx container without issue. For use cases
where Chromium needs to have native USB access, you might not want to
run it in a container.

** Check the list of layers:

#+begin_run
sudo rpm-ostree status
#+end_run

The top layer should list the =LayeredPackages= in your new layer.

Reboot.

** Reset all layers back to stock

#+attr_shortcode: :style warning
#+begin_notice
This will reset all the layered packages back to the stock image. This
may be useful if you are trying to clean up from lots of testing.

*All package layers will be destroyed!*

Your user home directories (=/var/home/=) and system configuration
(=/etc/=) are not affected.

#+begin_run
sudo rpm-ostree reset
sudo rpm-ostree cleanup -r
sudo systemctl reboot
#+end_run
#+end_notice

* Config
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: config
:END:

** Config
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 1200
:END:

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

** Sway
:PROPERTIES:
:EXPORT_FILE_NAME: sway
:END:

[[https://github.com/swaywm/sway?tab=readme-ov-file#readme][Sway]] is a reimagining of [[https://i3wm.org/][i3wm]] (X11), rewritten for Wayland. Sway (like
i3wm) is a keyboard centric tiling window manager. Although not a
source fork of i3wm, the configuration and user interface of Sway is
almost identical to that of i3wm.

*** Sway Config

The Fedora Atomic Sway edition includes a default configuration for
Sway. It's pretty nice out of the box, and so if you like it, you can
just use it. However, I use [[https://github.com/enigmacurry/sway-home][my own custom configuration]] that I replace
it with, and you can do the same if you like.

Open the default terminal emulator (foot) with the keyboard shortcut:
=Win+Enter= (hold down the "Windows" key on your keyboard, then
simultaneously press Enter.)

My custom config replaces several of the default configuration files.
So you must first get rid of these files, by renaming them with the
suffix =.orig= for posterity:

#+begin_run
mv ~/.config ~/.config.orig
mv ~/.bashrc ~/.bashrc.orig
mv ~/.bash_profile ~/.bash_profile.orig
#+end_run

Next, install my [[https://github.com/enigmacurry/sway-home][customized sway config repository]] :

#+begin_run
git clone https://github.com/enigmacurry/sway-home \
  ~/git/vendor/enigmacurry/sway-home
#+end_Run

Run the included setup script:

#+begin_run
cd ~/git/vendor/enigmacurry/sway-home
./setup.sh
#+end_run

The =setup.sh= script will make [[https://github.com/EnigmaCurry/sway-home/blob/master/setup.sh#L57-L61][symlinks]] to the repository files from
the same original paths as the files you just moved. It also asks you
some questions to help setup your git profile.

Once you have finished entering the information setup asks for, press
=Win+Shift+E=, and choose Log Out. Log back in, and this will load the
new config files.

*** Setup display resolutions and orientation

Fedora Sway Atomic ships with [[https://git.sr.ht/~emersion/kanshi][kanshi]] for display setup. Kanshi does
not include any GUI for setting it up, so another program called
[[https://github.com/artizirk/wdisplays][wdisplays]] is useful.

You can configure all of your displays using the wdisplays GUI
program, however, the configuration will not persist across login
sessions. So what you need to do is set it up how you like it, and
then transfer that information into the Kanshi config file so that it
sets it up the same way everytime you login.

For example, on my test system I have two display port monitors, with
outputs named =DP-3= and =DP-4=. These are shown in wdisplays and I
have set up the size, position, and DPI scaling exactly how I like it:

DP-3:

[[/img/wdisplays1.webp]]

DP-4:

[[/img/wdisplays2.webp]]

Open the Kanshi config file =~/.config/kanshi/config= and copy the
information into the config file:

#+attr_shortcode: :file ~/.config/kanshi/config
#+begin_edit
profile {
   output DP-3 enable mode 2560x1440 position 3840,0 scale 1 transform normal
   output DP-4 enable mode 3840x2160 position 1920,360 scale 2 transform normal
}
#+end_edit

Check out =man 5 kanshi= for more config options. Kanshi is
[[https://github.com/EnigmaCurry/sway-home/blob/9a7af6fbd60a671a7059ba7bd35f35c2ec3cbd1f/config/sway/config.d/autostart_applications#L2][automatically started]] when sway is, so you can test it by logging out
and logging back in.

** Firefox
:PROPERTIES:
:EXPORT_FILE_NAME: firefox
:END:

Fedora Atomic ships with the Firefox browser preinstalled. This
section describes how I like to set it up.

*** Remove clutter

**** Remove =Firefox View=, right click the upper left icon and select =Remove from toolbar=.

[[/img/firefox/firefox-view.webp]]

**** Remove existing bookmarks from bookmark bar, right click each one and select =Delete=.

**** Remove =Pocket=, right click the pocket icon in the upper right toolbar, select =Remove from toolbar=

[[/img/firefox/firefox-pocket.webp]]

**** Remove =Firefox Account= icon, select =Remove from toolbar=

[[/img/firefox/firefox-account.webp]]


*** Firefox Settings

Go into the Firefox settings: click the "hamburger" menu in the top
right toolbar. Select =Settings=.

[[/img/firefox/firefox-settings.webp]]

**** General Settings

***** Select =Open previous windows and tabs=

***** Turn on Dark mode

[[/img/firefox/firefox-general.webp]]

***** Turn off =Recommend extensions as you browse=

***** Turn off =Recommend features as you browse=

[[/img/firefox/firefox-browsing.webp]]

**** Home settings

***** =New Windows and Tabs=

Select =Blank Page= for both new windows and tabs.

[[/img/firefox/firefox-home.webp]]

***** Firefox Home Content

The home content won't show if you set =Blank Page= above, but I go
ahead and turn off all the home stuff anyway.


**** Search Settings

***** Choose a non-Google default search engine, eg. =DuckDuckGo=.

***** Turn off all Search Suggestions

***** Delete all the corporate Search Shortcuts other than your preferred one (eg. DuckDuckGo).

You can select each one and click =Remove= or you can press the Delete
key. Delete Google, Amazon, Bing, eBay, Wikipedia etc.

[[/img/firefox/firefox-search.webp]]


**** Privacy & Security settings

***** Enhanced Tracking Protection, select =Strict=

***** Set =Do Not Track= to =Always=

[[/img/firefox/firefox-privacy-1.webp]]

***** Logins and Passwords

Unselect =Suggest Firefox relay email masks=

Unselect =Show alerts about passwords for breached websites= (You
already use unique passwords for every website, right??)

***** IMPORTANT: select =Use a Primary Password=

[[/img/firefox/firefox-privacy-2a.webp]]

Without setting a primary password, any password that firefox saves
will be **unencrypted**! You must set a primary (master) password, and
you will need to type it in each time you restart your browser, to
unlock the password manager.

***** Address Bar - Firefox Suggest

Unselect =Search engines=

Unselect =Suggestions from the web=

Unselect =Suggestions from sponsors=

[[/img/firefox/firefox-privacy-2b.webp]]

***** Firefox Data Collection and Use

Unselect everything here.

[[/img/firefox/firefox-privacy-3a.webp]]

***** HTTPs-Only mode

Choose =Enable HTTPS-Only Mode in all windows=

[[/img/firefox/firefox-privacy-3b.webp]]


***** DNS over HTTPS

Especially if you use a portable laptop, or connect to various WiFi
access points, you should choose =Max Protection=.

[[/img/firefox/firefox-dns.webp]]

*** Extensions and Themes

From the Settings menu, near the bottom, click =Extensions & Themes=.

**** Themes

Choose a theme you like. For example, click =Dark= and then click =Enable=.

**** Extensions

Go to [[https://addons.mozilla.org][addons.mozilla.org]] and install the following extensions:

[[https://addons.mozilla.org/en-US/firefox/addon/darkreader/][Dark Reader]]

Dark reader makes all sites darker, and you can customize each site by
clicking on the Dark Reader extension in the menu bar.

[[https://addons.mozilla.org/en-US/firefox/addon/ublock-origin][Ublock Origin]]

Disables almost all ads on all websites. There's not much to configure
here, it basically works out of the box. However, you can customize it
per site if you want to enable ads on certain pages.

[[https://addons.mozilla.org/en-US/firefox/addon/noscript][NoScript]]

By default, all sites will have javascript disabled. On each site you
trust, you can customize the javascript availability by clicking the
NoScript extension in the menu bar.

[[https://addons.mozilla.org/en-US/firefox/addon/adsum-notabs][No Tabs]]

If you're using a tiling window manager (Sway), you might consider
disabling Firefox tabs, and have every site in its own window instead.
This extension does that.

[[https://addons.mozilla.org/en-US/firefox/addon/vimium-ff/][Vimium]]

Once vimium is installed, click the icon in the menu bar and click
=Enable all hosts permission=.

[[https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/][Firefox Multi-Account Containers]]

Read about [[https://support.mozilla.org/en-US/kb/containers][how to use Firefox Containers]]. Configure sites you trust to
open in specific containers, that way you can save your cookies per
container. By default, new sites will always open in temporary ones,
and so when you close your browser all the cookies for that site
disappears.

** Toolbox
:PROPERTIES:
:EXPORT_FILE_NAME: toolbox
:END:

[[https://docs.fedoraproject.org/en-US/fedora-silverblue/toolbox/][Toolbox]] is an integral part of Fedora Atomic, being one of the main
methods of installing software (the alternative being Flatpak), it
lets you run your applications inside of [[https://podman.io][Podman]] containers. Toolbox
can actually be used on any Linux system that is capable of running
Podman, but is especially useful on Atomic hosts. Toolbox is more
tightly integrated with your host OS than Docker or Podman containers
normally are. Toolbox containers share the same =/home= directory with
the host (bind mounted), and they live in the same network and process
namespace as the host (ie. you can run =ps= or =kill= from inside the
toolbox, and it will see/affect the host.) Toolbox containers are not
sandboxed like normal Docker containers are, but they are a
convenience for installing/removing software on Atomic hosts, because
theres not really any other way (since the host filesystem is
read-only). The applications you install in the container will live
only inside the toolbox.

The killer feature of a toolbox is that it lets you try things out,
and if you want to start over, you can just delete the toolbox
container, and create a new one. You are less likely to mess up the
host by playing around inside the toolbox. Just remember that =/home=
is bind mounted to the host, and so if you change or delete things in
those directories, they are also affected the same way on the host.

*** Dev toolbox (Fedora)

Let's create a toolbox to install some of the common development tools
we will use on a daily basis.

#+begin_run
toolbox create dev
#+end_run

This will create a new toolbox container called =dev= based upon the
same Fedora version as the host (the toolbox itself is not Atomic
though, but the normal Fedora Workstation version instead.)

To enter the toolbox run:

#+begin_run
toolbox enter dev
#+end_run

This will enter the toolbox container, and now you can install extra
software:

#+begin_run
sudo dnf install keychain htop
sudo dnf groupinstall "Development Tools" "Development Libraries"
#+end_run

*** Arch Linux toolbox

You are not limited to running Fedora toolboxes, in fact you can run
any container image you want, or even build your own from a
=Dockerfile=. Here is a Dockerfile for Arch Linux you can use to build
an Arch Linux toolbox container:

#+attr_shortcode: :file Dockerfile
#+begin_edit
FROM docker.io/archlinux/archlinux:latest
ENV NAME=arch-toolbox VERSION=rolling
LABEL com.github.containers.toolbox="true" \
  name="$NAME" \
  version="$VERSION"
RUN pacman -Syu --noconfirm \
    && pacman  -S --noconfirm sudo inetutils less \
       git base-devel go \
       noto-fonts noto-fonts-cjk \
       noto-fonts-emoji noto-fonts-extra \
    && pacman -Scc --noconfirm \
    && echo "%wheel ALL=(ALL) NOPASSWD: ALL" > /etc/sudoers.d/toolbox
RUN sudo -u nobody git clone https://aur.archlinux.org/yay-bin.git /tmp/yay \
    && cd /tmp/yay \
    && sudo -u nobody makepkg -s \
    && pacman -U --noconfirm yay-bin-*.pkg.tar.zst
CMD ["bash"]
#+end_edit

Write this to a file named =Dockerfile= and open your host terminal to
the same directory. Then run this command to build the container:

#+begin_run
podman build -t arch .
#+end_run

Now you can create a new toolbox based on the new image (both called
=arch=):

#+begin_run
toolbox create --image arch arch
#+end_run

To enter the Arch Linux container, run:

#+begin_run
toolbox enter arch
#+end_run

Now that you're inside the toolbox, you can run any Arch Linux command
(consult the [[http://wiki.archlinux.org/][Arch Wiki]]).

#+attr_shortcode: :title Run this inside the arch toolbox
#+begin_run
sudo pacman -Syu
sudo pacman -S keychain base-devel
#+end_run

*** Managing toolbox containers

You can list all of your toolboxes that you've created:

#+begin_run
toolbox list
#+end_run

You can remove existing toolboxes:

#+begin_run
toolbox rm --force arch
#+end_run

(force is only required if the toolbox is currently running.)

** Emacs
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-on-fedora
:END:

[[https://www.gnu.org/software/emacs/][Emacs]] is my long time favorite code editor (IDE) and for writing
documentation (including this book).

*** Install Emacs

Because Sway runs on Wayland, you'll want to install the Wayland
(pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk)
version is already the default. For Fedora 39, [[https://copr.fedorainfracloud.org/coprs/enigm-a/emacs-pgtk-nativecomp][you can use this COPR]]
(a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch
Linux), which includes a custom build for Wayland (pgtk).

To enable this, you need to be running your dev toolbox:

#+begin_run
toolbox enter dev
#+end_run

Install Emacs:

#+attr_shortcode: :title run this inside the toolbox:
#+begin_run
sudo dnf install emacs
#+end_run

*** Create Emacs script

In order to be able to quickly launch Emacs inside the toolbox from
the host, you will need a little script installed on the host.

You can create this script and put it in =/usr/local/bin/emacs=. Run
this on the host (not in the toolbox), to create it as the root user:

#+attr_shortcode: :file /usr/local/bin/emacs
#+begin_edit
#!/bin/bash
## Run Emacs in the dev toolbox and pass it any args:
toolbox run -c dev emacs $@
#+end_edit

#+begin_run
sudo chmod a+x /usr/local/bin/emacs
#+end_run

Now you can run Emacs from the host, and it will run inside the
Toolbox.

*** Install dependencies

Most Emacs packages are written in Emacs Lisp, and therefore have no
external dependencies. The one exception is for Vterm terminal
support, which requires compiling a C library (libvterm). This
compilation can be done automatically by Emacs, but it requires you
have some tools preinstalled:

 * CMake
 * libtool

Install the dependencies inside the toolbox:

#+attr_shortcode: :title run this inside the toolbox
#+begin_run
sudo dnf install cmake libtool
#+end_run

*** Remove any existing Emacs config

Assuming you want to use my Emacs config, you need to delete any
existing config you already have. Also note that Emacs creates a
default config the first time it runs, so if you started Emacs
already, you may have a config and not even know it.

Here's how to remove the existing Emacs config:

#+begin_run
rm ~/.emacs ~/.emacs.d -rf
#+end_run

*** Install my Emacs config

[[https://github.com/EnigmaCurry/emacs][My Emacs config is on github]]. Install it with the following script:

#+begin_run
REMOTE=git@github.com:EnigmaCurry/emacs.git
REPO=${HOME}/git/vendor/enigmacurry/emacs
BRANCH=straight

(set -e
test -d ~/.emacs.d && (echo "~/.emacs.d already exists. Aborting install." && exit 1)
test -d ${REPO} || git clone -b ${BRANCH} ${REMOTE} ${REPO}
mkdir ~/.emacs.d && ls -1 ${REPO}/*.el | xargs -iXX ln -s XX ~/.emacs.d
mkdir ~/.emacs.d/straight && ln -s ${REPO}/straight-versions ~/.emacs.d/straight/versions
ln -s ${REPO}/snippets ~/.emacs.d/snippets
)
#+end_run

*** Start Emacs to finish the installation

The first time Emacs starts, it will install all of the dependencies
listed in the main config file =~/.emacs.d/init.el=.

Run:

#+begin_run
emacs
#+end_run

Wait for everything to install. You may see a blank screen for up to
10 minutes, but you should see some minimal information of the
progress in the bottom minibuffer.

If it gets stuck at any point, quit and restart it, and it should
continue where it left off. If you get any error message, you may want
to start Emacs again with debug mode turned on:

#+begin_run
emacs --debug-init
#+end_run

This will usually give you a more verbose error message which can be
helpful in debugging the startup.


*** Read the README for my config

More notes are available in the [[https://github.com/EnigmaCurry/emacs#readme][README]].

** SSH
:PROPERTIES:
:EXPORT_FILE_NAME: ssh
:END:

SSH (secure shell) is a secure networking tool used between a client
and a server. Using an encrypted network protocol, it can be used to
securely login to a server remotely, as well as for more advanded
networking scenarios. Typical use cases for SSH include:

 * Access to a server's console shell, remotely.
 * Transfer files between the server and client (using =rsync=, =scp=,
   or =sftp=).
 * Create network tunnels to access private servers, in both
   directions, either on the server, or on the client.
 * Create a server that acts as a bastion or "jump" host, to be a port
   of entry into a larger private network. SSH is configured to only
   allow authorized client keys access through the bastion host.
 * Create a server to act as an HTTP (socks) client proxy, to allow
   remote clients to browse the web, using the server's IP address as
   the origin.
 * Remote controlling a Docker server using the =docker= command line
   client (SSH Docker Context).

SSH is based upon public key cryptography. Both the client and the
server need to create their own public/private keypair. Keys can be
encrypted on disk (eg. =~/.ssh/id_ecdsa=) or they may also be loaded
from a USB hardware token. Upon connecting to a remote server for the
first time, the client asks the user to validate the server's public
key fingerprint, and then the server's public key is written into a
file called =~/.ssh/known_hosts=, which marks the connection as
trusted from then on. The server also authorizes the client through a
predefined =authorized_keys= file. If either side rejects the key
presented by the other, the connection is unauthorized, and is closed
immediately.

*** Create SSH Keys

This book recommends the use of hardware authentication tokens, like
the [[https://solokeys.com/][Solokey]]. Traditional SSH keyfiles are also acceptable, but these
should be considered as a legacy format, as they are less secure.
Finally, plain password authentication (non-key based) is fully
deprecated and should *never* be used.

**** Setup Solokey (FIDO2) hardware authentication

Plug in your Solokey (or compatible hardware) to the USB port.

Initialize the hardware with a new SSH key:

#+begin_run
## You only need to do this one time per solokey!
ssh-keygen -t ed25519-sk -O resident -O verify-required
#+end_run

You will be required to create/enter a PIN for the Solokey.

**** Traditional SSH keyfiles

The Solokey still has some drawbacks, and cannot be used in all cases.
Traditional SSH keyfiles are still useful for automated and unattended
clients. Technically, the solokey is supposed to be able to work in a
"touchless" mode, by using the =-O no-touch-required= option, but I
never got this to work.

Key files should be created uniquely for each user and workstation.
They should never be shared between multiple users or workstations.

***** Choosing the SSH key type

It is recommended to use the newer =ed25519= key type, which uses the
latest encryption standards. Your distribution may still use the older
standard =rsa= by default (which is acceptable). You should explicitly
select the key type when creating the keyfile to be sure.

Some older servers don't accpet =ed25519= keys, and so in those cases
you should still create an =rsa= key as well. Each key type is stored
in a different file, so its OK to have multiple types installed on the
same machine.

***** Create the new SSH keys

Create the =rsa= key type:

#+begin_run
ssh-keygen -t rsa -f ~/.ssh/id_rsa
#+end_run

Create the =ed25519= key type:

#+begin_run
ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519
#+end_run

You will be prompted to enter an encryption passphrase for each file,
which you should definitely not skip!

*** Setup the ssh-agent

Because your keyfiles are encrypted with a passphrase, you need to
enter the passphrase everytime you use it. This is inconvenient, so
you can run =ssh-agent= to temporarily store your key/identity in
memory, and therefore you only need to enter your passphrase once,
when you log in. (In the case of the solokey, the key is never held in
memory, but you still need to hold the identity of it in the
ssh-agent.)

Keychain is a program that helps you setup the ssh-agent. Install
=keychain=:

#+attr_shortcode: :title Run this on your Fedora workstations:
#+begin_run
sudo dnf install keychain
#+end_run

#+attr_shortcode: :title Run this on your Debian / Ubuntu workstations:
#+begin_run
sudo apt install keychain
#+end_run

#+attr_shortcode: :title Run this on your Arch Linux workstations:
#+begin_run
sudo pacman -S keychain
#+end_run

To configure keychain, edit your =~/.bashrc= file:

#+attr_shortcode: :file ~/.bashrc
#+begin_edit
## Put this line in your ~/.bashrc:
## (If you're using my config, this is already in it.)
eval $(keychain --eval --quiet)
#+end_edit

Log out of your desktop session, and log back in. Open your terminal,
and you should be automatically prompted to enter your SSH passphrase.
Once you have entered the passphrase, the SSH key will remain resident
in memory until you log out.

Double check that the key has been loaded, run:

#+attr_shortcode: :title run this inside your toolbox
#+begin_run
ssh-add -L
#+end_run

The above should print your public key, loaded into the running
=ssh-agent=. Now you should be able to use your key without entering a
passphrase. Copy the output and upload it to your services as your
authorized key. For servers, put the key into
=~/.ssh/authorized_keys=. For hosted services, like GitHub, paste the
key into your SSH settings page.

*** Add your solokey identity per session

Apparently, keychain does not yet know how to load the Solokey
automatically. You must add the Solokey to the ssh-agent manually, one
time, each time you boot your workstation:

#+attr_shortcode: :title run this inside your toolbox
#+begin_run
## Do this to load your Solokey into the ssh-agent:
ssh-add -K
#+end_run

You will be prompted one time to enter your Solokey pin to unlock the
key.

* Two Factor Auth with Solokey
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: sudo-2FA
:END:

** Solokey authentication
*** Solokey authentication
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 1200
:END:

[[https://solokeys.com/][Solokeys]] are physical hardware authentication (U2F / FIDO2) devices,
that you plug into a USB port, which stores a secret key that can be
used as primary or secondary authentication factors (2FA), with
websites (Webauthn), and machines (sudo and SSH).

There are two versions of solokey now, v1 and v2, and they require
separate toolchains. The instructions diverge here depending on which
hardware revision you have.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

*** Get your Solokey
:PROPERTIES:
:EXPORT_FILE_NAME: get-your-solokey
:EXPORT_HUGO_WEIGHT: 100
:END:

I know of two places to buy solokeys:

 * https://solokeys.com/collections/all
 * https://www.crowdsupply.com/solokeys/somu#products

What to buy:

 * Recommended: [[https://solokeys.com/collections/all/products/solo-tap-usb-a-preorder][Solo 2 USB-A]] (touch capacitive, but its long and
   sticks out of the USB port).
 * Recommended: [[https://solokeys.com/collections/all/products/solo-tap-usb-a-preorder][Solo 1 Tap USB-A]] (durable clicky button, but its long
   and sticks out of the USB port).
 * Recommended: [[https://www.crowdsupply.com/solokeys/somu][Somu]] (semi-permanent flush mount USB-A port, soft
   touch design).
 * Get the *"secure"* version, don't buy the "hacker" version. 
 * Buy at least two (and store one as a backup).


*** Solokey v2
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: solo-v2
:END:

**** Solokey v2
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 200
:END:

***** Set PIN

You should set a device PIN for the solokey, so that it cannot be used
if it is stolen.

Identify the device name (=/dev/hidrawX=):

#+begin_run
fido2-token -L
#+end_run

This probably shows the device as =/dev/hidraw0=:

#+begin_stdout
/dev/hidraw0: ......
#+end_stdout

Set the PIN for the device (=/dev/hidraw0=):

#+begin_run
fido2-token -C /dev/hidraw0
#+end_run

***** Steps to update the Solokey (v2)
****** Install solo2-cli
#+attr_shortcode: :style tip
#+begin_notice
solo2-cli is only required if you need to update your device.
#+end_notice

Find the [[https://github.com/solokeys/solo2-cli/releases][latest version of solo2-cli]]

#+begin_env
SOLO2_VERSION=0.2.2
PLATFORM=x86_64-unknown-linux-gnu
#+end_env

#+begin_run
(set -e
curl -L -o solo2 \
  https://github.com/solokeys/solo2-cli/releases/download/v${SOLO2_VERSION}/solo2-v${SOLO2_VERSION}-${PLATFORM}
sudo install solo2 /usr/local/bin/
rm -f solo2
)
#+end_run

****** Identify solokey

#+begin_run
solo2 list
#+end_run

#+begin_stdout
Solo 2 xxxxxxxxxxx (CTAP+PCSC, firmware 2:20220822.0, locked)
#+end_stdout

****** Install udev rules

#+begin_run
curl https://raw.githubusercontent.com/solokeys/solo2-cli/main/70-solo2.rules | \
  sudo tee /etc/udev/rules.d/solokey2.rules
sudo udevadm trigger
#+end_run

****** Update solokey
#+begin_run
solo2 update
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
You may need to run =sudo solo2 update= if the udev rules aren't
working correctly.
#+end_notice

*** Solokey v1
:PROPERTIES:
:EXPORT_FILE_NAME: solo-v1
:END:

**** Install Solokey CLI (v1) tool
***** Create Python environment for solokey

#+begin_run
SOLO_ROOT=~/git/vendor/solokeys
(set -e
git clone https://github.com/solokeys/solo1-cli \
    ${SOLO_ROOT}/solo1-cli
)
#+end_run

***** Lock Fido2 version to 0.9.1 to fix outstanding bugs

#+attr_shortcode: :style warning
#+begin_notice
Double check if these outstanding bugs are still open:

 * https://github.com/solokeys/solo1-cli/issues/151
 * https://github.com/solokeys/solo1-cli/discussions/156

Both of these are related to Fido2 v1.0.0. If you lock the version to
the last known good version of 0.9.1, it will work:

#+begin_run
sed -i 's/fido2 >= 0.9.1/fido2 == 0.9.1/' ${SOLO_ROOT}/solo1-cli/pyproject.toml
#+end_run
#+end_notice

***** Build solo1 key environment

#+begin_run
python -m venv ${SOLO_ROOT}/env
${SOLO_ROOT}/env/bin/pip3 install -e ${SOLO_ROOT}/solo1-cli
#+end_run

***** Add =solo= alias to your .bashrc

#+attr_shortcode: :file ~/.bashrc
#+begin_edit
alias solo1=${HOME}/git/vendor/solokeys/env/bin/solo1
#+end_edit

Restart your shell to load the new alias.

**** Update your Solokey (v1)
***** Plug your solokey into the USB port
***** Identify your solokey
#+begin_run
solo1 ls
#+end_run

#+begin_stdout
:: Solos
AABBCC00112233: SoloKeys Solo 4.1.5
#+end_stdout

***** Update the firmware

Check for the [[https://github.com/solokeys/solo1/releases][latest release of solo v1]] and compare it to the version
that is reported by =solo ls=. If your solokey is not running the
latest version, it is recommended to update it.

Enter bootloader mode:

#+begin_run
solo1 program aux enter-bootloader
#+end_run

The solokey should now be rapidly flashing to indicate it is in boot
loader mode.

Update the firmware:

#+begin_run
solo1 key update
#+end_run

#+begin_stdout
...
Congratulations, your key was updated to the latest firmware version: 4.1.5
#+end_stdout

**** Program your Solokey (v1)
***** Reset solokey (recommended first time only)
#+attr_shortcode: :style warning
#+begin_notice
This will wipe all identity from the solokey device!
#+begin_run
solo1 key reset
#+end_run
#+end_notice


***** Set device PIN

#+begin_run
solo1 key set-pin
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
This will only work if the device does not already have a pin (which
is the state it is in after a reset).

If you want to change the PIN which was already set:

#+begin_run
solo1 key change-pin
#+end_run
#+end_notice


***** Verify PIN

#+begin_run
solo1 key verify
#+end_run

#+begin_stdout
PIN: 
Please press the button on your Solo key
Register valid
Valid Solo with firmware from SoloKeys.
#+end_stdout


*** Sudo with Solokey
:PROPERTIES:
:EXPORT_FILE_NAME: sudo-2FA
:END:

Having =sudo= privileges enabled for your normal workstation user
account is both a convenience and a security concern. The Pluggable
Authentication Module for Linux (PAM) allows us to strengthen the
requirements for using =sudo=, to include several authentication
methods beyond just asking for a password. This chapter will install
[[https://developers.yubico.com/pam-u2f/][pam_u2f]], which enables PAM authentication via FIDO2/U2F compatible
hardware tokens like the [[https://solokeys.com/][Solokey]]. Each time =sudo= asks for
authentication, it will prompt for a Solokey button press /and/ a
password to be entered.

#+attr_shortcode: :style credits :title CREDITS :icon gift
#+begin_notice
Some of this guide was adapted from these other guides:

 * [[https://fedoraproject.org/wiki/Using_Solokeys_with_Fedora#Introduction:_Using_Solo_Keys_with_Fedora][Using Solokeys with Fedora]]
 * [[https://docs.fedoraproject.org/en-US/quick-docs/using-yubikeys/][Using YubiKeys with Fedora]]

Thank you to the Fedora documentation team!
#+end_notice
 
***** Open a root session as an anti-lockout measure

To prevent yourself from being locked out of your own system during
the setup process, it is recommended to start a new terminal in a root
session, and to keep it open. That way if you lock yourself out, you
still have a way you can fix it.

#+begin_run
## Open root session and leave it alone in another window ....
sudo su
#+end_run

****** Consider adding a root password

If you use =sudo= a lot, you might not actually know the real =root=
password of your system (or one might not even be set). As a backup,
you may want to set a secure long random passphrase for the =root=
user and keep it safe (you will rarely need it).

#+attr_shortcode: :style warning
#+begin_notice
Reset the root password with a random string:

#+begin_run
(set -e
LENGTH=26
PASSWORD=$(tr -dc 'A-Za-z0-9!@#$%^&*()[]~+-_=?<>.,;:' < /dev/urandom | head -c ${LENGTH})
echo -e "\nSave this ${LENGTH} character long password somewhere safe:    ${PASSWORD}\n"
read -e -p "Do you want to reset the root password with this value (y/N)? " answer
(test "${answer,,}" == "y" || test "${answer,,}" == "yes") && \
    sudo sh -c "echo 'root:${PASSWORD}' | chpasswd && echo Done." || \
    echo "Cancelled."
)
#+end_run

Test that the root password works /without/ using =sudo=:

#+begin_run
su
#+end_run
#+end_notice

***** Register Solokeys

It is recommended that you register *at least two* solokeys: a primary
key, and a backup key. That way, if you lose one of the keys, you can
still use the other one.

#+attr_shortcode: :style tip
#+begin_notice
Do the next steps as your *normal workstation user account*, which is
the account that should already have =sudo= privileges.
#+end_notice

Create a tempory file to capture solo key registrations:

#+begin_env
TMP_KEYS=$(mktemp)
#+end_env

 * Plug in the first solokey, then run:

#+begin_run
pamu2fcfg >> ${TMP_KEYS} && \
     echo >> ${TMP_KEYS}
#+end_run

It may ask you to enter the PIN of the solokey:

#+begin_stdout
Enter PIN for /dev/hidraw1: 
#+end_stdout

 * When the solokey lights up, press the button.

 * Unplug the first solokey and repeat the last command for the second
   solokey.

 * Unplug the second solokey and repeat for additional solokeys.
 
 * When you've written all the keys to =${TMP_KEYS}=, reformat and
   install them into their final destination:

#+begin_run
echo "${USER}:$(cat ${TMP_KEYS} | \
    cut -d ":" -f 2 | tr '\n' ':')" | sed 's/:$//' | \
    sudo tee /etc/u2f_authorized_keys
#+end_run

***** Create custom PAM modules for U2F

You will create two new PAM modules: =u2f-required= and
=u2f-sufficient=. They will both include these required settings:

 1. The =authfile= path to our authorized key list file.
 2. The =cue= literal to show the =Please touch the device= prompt
    message for each authentication. (If you omit this, it will print
    nothing, which can be confusing).

The only difference between the two PAM modules is that one is
*required*, and the other is merely *sufficient*.

 * =required= means to *enable 2FA*: solokey + password required.
 * =sufficient= means to *disable 2FA*: solokey OR password is sufficient.
 
#+begin_run
cat << EOF | sudo tee /etc/pam.d/u2f-required
#%PAM-1.0
auth       required     pam_u2f.so authfile=/etc/u2f_authorized_keys cue
EOF
cat << EOF | sudo tee /etc/pam.d/u2f-sufficient
#%PAM-1.0
auth       sufficient     pam_u2f.so authfile=/etc/u2f_authorized_keys cue
EOF
#+end_run

#+attr_shortcode: :style warning
#+begin_notice
The PAM modules you just created (=/etc/pam.d/u2f-required= and
=/etc/pam.d/u2f-sufficient=) can be used for extending any of the
other pam modules found in =/etc/pam.d=, by adding an appropriate
=include= line at the right place. This can affect many more system
authentication methods than just =sudo=, so be careful, but only
=sudo= will be covered for now.
#+end_notice

***** Configure PAM hook for sudo

As =root=, edit the file =/etc/pam.d/sudo=, and insert a new line
directly after the =#%PAM-1.0= header. A PAM module follows rules in
top down order, as they are listed. Therefore your solokey rule needs
to be the /first/ authentication mechanism, and the existing password
flow is the /second/ authentication method.

#+attr_shortcode: :file /etc/pam.d/sudo
#+begin_edit
#%PAM-1.0
auth	  include      u2f-required
auth       include      system-auth
account    include      system-auth
password   include      system-auth
session    optional     pam_keyinit.so revoke
session    required     pam_limits.so
session    include      system-auth
#+end_edit

#+attr_shortcode: :style tip
#+begin_notice
Line 2 (=auth include u2f-required=) is the only line that was added
to this file. Everything else in this file was here originally and is
left intact.
#+end_notice

#+attr_shortcode: :style warning
#+begin_notice
If you change =u2f-required= to =u2f-sufficient=, then it will *disable
2FA* allowing solokey press *OR* user password as sufficient!
#+end_notice

***** Test sudo

#+attr_shortcode: :style tip
#+begin_notice
When testing sudo, always open a new terminal for *each* test. This is
to avoid the auth caching mechanism (which is reset for new
terminals).

#+begin_run
sudo
#+end_run

The PAM system should now ask for you to touch your solokey (or press
the button), and afterward prompt for your password.

#+begin_stdout
Please touch the device.
[sudo] password for ryan: 
#+end_stdout
#+end_notice

*** SSH with Solokey
:PROPERTIES:
:EXPORT_FILE_NAME: ssh-2FA
:END:

Follow the chapter on [[/linux-workstation/config/ssh/][SSH config]].

* Application users
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: app-users
:END:

** Application users
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

With strong authentication for sudo taken care of by [[/linux-workstation/sudo-2fa][Solokey]], we can
separate permissions for privileged data access, by creating
additional user accounts.

One use case for this can be to control access to command line
programs that store sensitive API tokens, via =sudo=.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

** DigitalOcean
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: digitalocean
:END:

*** DigitalOcean CLI (doctl)
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

[[https://docs.digitalocean.com/reference/doctl/][doctl]] is the official DigitalOcean command line interface (CLI). It
allows you to interact with the DigitalOcean API via the command line.

You should create a dedicated user for the =doctl= application, so
that it can securely store the Personal Access Token for the
DigitalOcean API. You can then access the privileged =doctl= command
from your normal workstation account via =sudo=.

**** Create doctl user

#+begin_run
sudo useradd -s /bin/bash -m doctl
#+end_run

**** Install doctl client

Following the [[https://docs.digitalocean.com/reference/doctl/how-to/install/][doctl install guide]], install the doctl client directly
in the home directory of the doctl user:

#+begin_run
DOCTL_VERSION=1.104.0
DOCTL_PLATFORM=linux-amd64
(set -e
sudo curl -L -O --output-dir /usr/local/src https://github.com/digitalocean/doctl/releases/download/v${DOCTL_VERSION}/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz
sudo tar -C ~doctl/ -x -f /usr/local/src/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz
sudo ~doctl/doctl completion bash | sudo tee /etc/profile.d/doctl_completion.sh
)
#+end_run

**** Create app alias for normal user account

In your normal workstation account, create this alias in your
=~/.bashrc= to make it more convenient to run doctl via =sudo=:

#+attr_shortcode: :file ~/.bashrc
#+begin_edit
## DigitalOcean client (dotcl):
alias doctl='sudo -u doctl ~doctl/doctl'
## Bash completion for dotcl:
BASH_COMPLETION=/etc/profile.d/bash_completion.sh
DOCTL_COMPLETION=/etc/profile.d/doctl_completion.sh
test -f ${BASH_COMPLETION} && source ${BASH_COMPLETION}
test -f ${DOCTL_COMPLETION} && source ${DOCTL_COMPLETION}
#+end_edit

Restart your terminal, and you can now use =doctl= from your normal
account.

**** Create a Personal Access Token

[[https://docs.digitalocean.com/reference/api/create-personal-access-token/][Read the offical documentation for creating tokens]]

Tokens allow programmatic access to the resources owned by a single
[[https://docs.digitalocean.com/platform/teams/][Team]].

 * [[https://cloud.digitalocean.com/account/team/create?i=01afa5][Create a new Team]], or choose an existing one. (If the domain name,
   or another resource you want to use, is already controlled by an
   existing team, choose that team).
 * [[https://cloud.digitalocean.com/account/api/tokens/new][Create the new token for the team]].
 * Decide what scopes you want to allow the doctl user to access, or
   choose =Full Access=.
 * Copy the token string to the clipboard.

Register the client using the token, choose any context name (but it
should reference your team name and/or role somehow):

#+begin_run
DOCTL_CONTEXT=my_team
doctl auth init --context "${DOCTL_CONTEXT}"
#+end_run

**** Use the doctl client

Read the [[/d.rymcg.tech/required-infrastructure][Self-hosting Docker]] book and setup a Docker server on
DigitalOcean, using doctl.

[[https://docs.digitalocean.com/reference/doctl/reference/][Read the doctl command reference]].

* KVM / libvirt
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: kvm-libvirt
:EXPORT_HUGO_WEIGHT: 4000
:END:

** KVM / libvirt
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

Idealistically, the [[/linux-workstation/introduction/][introduction]] declared a "No Sworkstations" rule
(No Server-Workstations). Pragmatically, you can bend this rule a bit,
by hosting some development servers inside of virtual machines (VM).
Hosting VMs on your workstation is convenient for having a portable
lab environment. By using virtual machines for all services, we get to
maintain our core distinction between the roles of workstation and
server.

This paradigm is considerably more adhoc than a proper hypervisor
operating system like [[https://blog.rymcg.tech/tags/proxmox][Proxmox]]. For pure server installs, Proxmox
should be preferred. But if you want to have a mixed-mode native
workstation, with extra server VMs, in the same portable platform,
this setup works really well.

Using this config, your workstation will stay relatively pure, because
these VMs are isolated from your normal account. They are
automatically started on boot, running under a dedicated VM user
account (=libvirt-admin=). You can treat these VMs just like any other
*remote* Linux host. From your normal workstation account, you can
access the VM's =root= shell, over (local) SSH connection, and you can
remotely install Docker on these target VMs.

These instructions will cover installing [[https://libvirt.org/][libvirt]], and creating a
barebones Debian or Fedora VM (but any cloud-init image should work),
inside of a private host-only network (No public ports are open by
default, but outgoing internet access is allowed). This is mainly for
local development/testing purposes only, but near the end of this
chapter, you'll get to decide if you'd like to bend this rule too, and
open the VMs up to public (LAN) routes for production-lite roles.

#+attr_shortcode: :style info :title Guest OS compatibility
#+begin_notice
The following *guest* Linux distributions, have been tested as
working:

 *  Debian 12 cloud image
 *  Fedora 40 cloud image
 *  Ubuntu 24.04 cloud image

These instructions should work for any operating system that is
shipped as a "Cloud" image (Cloud-Init image).
#+end_notice

#+attr_shortcode: :style orange :title Host workstation compatibility
#+begin_notice
The following *host* Linux distributions, have been tested as working
(only x86_64 tested so far):

 *  Fedora Atomic Workstation (40)
 *  Fedora Server (40)
 *  Fedora CoreOS (40)
 *  Arch Linux

The following *host* Linux distributions have some issues:

 *  Debian (12) *hosts* are only partially compatible, I have not been able to get the autostart service to run, due to an app armor permission issue, however the VMs do run if you start them manually.
#+end_notice

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index


#+attr_shortcode:
#+begin_toc
table of contents
#+end_toc

** Install libvirtd
:PROPERTIES:
:EXPORT_FILE_NAME: install-libvirtd
:EXPORT_HUGO_WEIGHT: 100
:END:

This book is primarily about [[/introduction/fedora-sway-atomic/][Fedora Atomic Desktop]] (sway) hosts, but
these instructions are generic enough to work on a wide variety of
systemd based Linux operating systems, including Fedora Workstation
(traditional), Fedora CoreOS, Arch Linux, and Debian (with caveats).

*** Packages for Fedora Atomic Desktop hosts

#+attr_shortcode: :style tip
#+begin_notice
Full package installation for Fedora Atomic Desktop hosts are covered
in the chapter on [[/linux-workstation/layering-packages][Layering packages]].
#+end_notice

*** Packages for Fedora CoreOS

#+begin_run
sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \
     virt-install libvirt-daemon-config-network libvirt-daemon-kvm \
     libguestfs-tools python3-libguestfs virt-top distrobox make
#+end_run

*** Packages for traditional Fedora Workstation hosts

#+attr_shortcode: :style info
#+begin_notice

These are the packages you would need to install on traditional Fedora
Workstation (or Server, but not CoreOS nor Atomic hosts)

#+attr_shortcode:
#+begin_run
sudo dnf install qemu-kvm libvirt virt-manager virt-viewer \
     virt-install libvirt-daemon-config-network libvirt-daemon-kvm \
     libguestfs-tools python3-libguestfs virt-top net-tools
#+end_run
#+end_notice


*** Packages for Arch Linux hosts

#+attr_shortcode: :style info
#+begin_notice
For Arch Linux, it is recommended to do a full system update and
reboot prior to installing the libvirt packages.
#+begin_run
sudo pacman -Syu
sudo reboot
#+end_run

After reboot, install packages:

#+begin_run
sudo pacman -S libvirt iptables-nft dnsmasq qemu-base virt-install \
               sysfsutils bridge-utils ebtables git make which jq \
               dmidecode pkgconf gcc
#+end_run
#+end_notice


*** Packages for Debian/Ubuntu hosts

#+attr_shortcode: :style info
#+begin_notice
For Debian (or Ubuntu), it is recommended to do a full system upgrade and
reboot prior to installing the libvirt packages.
#+begin_run
sudo apt update
sudo apt upgrade
sudo reboot
#+end_run

After reboot, install packages:

#+begin_run
sudo apt install --no-install-recommends \
                 libvirt-daemon-system virtinst libvirt-clients \
                 dnsmasq sysfsutils bridge-utils ebtables git make \
                 which jq dmidecode pkgconf gcc curl \
                 python3 python-is-python3
#+end_run
#+end_notice


** Setup libvirtd
:PROPERTIES:
:EXPORT_FILE_NAME: setup-libvirtd
:EXPORT_HUGO_WEIGHT: 100
:END:

*** Enable libvirtd service

#+begin_run
sudo systemctl enable --now libvirtd
sudo systemctl enable --now libvirt-guests
sudo systemctl status --no-pager libvirtd
#+end_run

*** Start the default network

#+begin_run
sudo virsh net-start default
sudo virsh net-autostart default
#+end_run

*** Configure /etc/group

Add the existing =libvirt= group to =/etc/group=, if it isn't already:

#+begin_run
grep "^libvirt:" /etc/group || sudo bash -c "getent group libvirt >> /etc/group"
#+end_run

*** TODO Extra steps only needed for Debian workstations

#+attr_shortcode: :style warning :title Warning Debian install is a WIP :icon dumpster-fire
#+begin_notice
This doesn't actually fully work on Debian 12 yet. Debian hosts
apparently have an additional requirement to run *qemu-bridge-helper*
(I didn't need it on Fedora or Arch Linux). However, I couldn't figure
out how to get it to work on Debian 12, because I ran into strange app
armor errors. YMMV.
#+end_notice

#+attr_shortcode: :style tip :title Debian workstations only
#+begin_notice
On a Debian workstation, creating a config for qemu-bridge-helper was
required, and modifying it to run setuid root to prevent user
permission error (=failed to create tun device: Operation not permitted:
Transport endpoint is not connected=):

#+begin_run
(set -e
sudo mkdir -p /etc/qemu
echo "allow virbr0" | sudo tee /etc/qemu/bridge.conf
sudo chmod u+s /usr/lib/qemu/qemu-bridge-helper
)
#+end_run

I also had to disable apparmor for libvirtd, otherwise I got
permission errors:

#+begin_run
sudo truncate --size 0 /etc/apparmor.d/usr.sbin.libvirtd
sudo apparmor_parser -R /etc/apparmor.d/usr.sbin.libvirtd
#+end_run
#+end_notice

** Create VM admin
:PROPERTIES:
:EXPORT_FILE_NAME: dedicated-vm-user
:EXPORT_HUGO_WEIGHT: 101
:END:

This will create a new user account on your workstation named
=libvirt-admin=. This user will be used as the owner for all the VM
disk images, config files, and for running the libvirt (qemu)
processes that run your VM.

This separation from the normal account you use is important to limit
the privileges that you have over the VM infrastructure. Your normal
account should be able to SSH /into/ the VM and have full root
privleges inside the VM. But your normal account should /not/ have
access to the underlying VM disk image files, nor its configuration.
Access to all VM administrative tasks must be done through =sudo= to
control the =libvirt-admin= account.

*** Create =libvirt-admin= user

#+begin_run
VM_ADMIN=libvirt-admin
sudo useradd -m ${VM_ADMIN} -s /bin/bash -G libvirt 
#+end_run

**** Extra steps for Debian workstations

#+attr_shortcode: :style tip
#+begin_notice
On a Debian workstation, adding the user to the =kvm= group was also
required:

#+begin_run
sudo gpasswd -a ${VM_ADMIN} kvm
#+end_run
#+end_notice

*** Configure systemd for the =libvirt-admin= user

#+begin_run
sudo loginctl enable-linger ${VM_ADMIN}
sudo su ${VM_ADMIN} -c \
  "echo export XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN}) > ~/.bashrc"
#+end_run

*** Copy your public SSH key into the =libvirt-admin= home directory
#+attr_shortcode: :style tip
#+begin_notice
If you don't have an SSH key yet, run =ssh-keygen -t ed25519=.
#+end_notice

Set =SSH_KEY= variable to point to your public SSH key file:

#+begin_env
SSH_KEY=~/.ssh/id_ed25519.pub
#+end_env

#+begin_run
TMP_SSH=$(mktemp)
cat ${SSH_KEY} > ${TMP_SSH}
chmod a+r ${TMP_SSH}
sudo su ${VM_ADMIN:-libvirt-admin} -c "mkdir -p ~/libvirt && cp ${TMP_SSH} ~/libvirt/user-ssh.pub"
#+end_run
** Cloud-Init VMs
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: cloud-init
:END:

*** Cloud-Init VMs
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

*** Configure VM (cloud-init)
:PROPERTIES:
:EXPORT_FILE_NAME: config-vm
:END:

**** Choose a name

#+begin_env
NAME=debian-dev
#+end_env

**** Choose hardware sizes

#+attr_shortcode:
#+begin_env
MEMORY=1024
CPUS=2
DISK_SIZE=50
#+end_env

**** Choose cloud image

You can choose any standard cloud image that supports cloud-init.

***** Debian 12

#+attr_shortcode:
#+begin_env
OS_VARIANT=debian12
CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2
#+end_env


#+attr_shortcode: :style tip
#+begin_notice
On slighly older versions of libvirt, you may need to set OS_VARIANT
differently, but the image should still work:
#+begin_env
OS_VARIANT=debian11
#+end_env
#+end_notice

***** Fedora 40

#+attr_shortcode:
#+begin_env
OS_VARIANT=fedora40
CLOUD_IMAGE=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Cloud/x86_64/images/Fedora-Cloud-Base-Generic.x86_64-40-1.14.qcow2
#+end_env

**** Find the default subnet (=virbr0=)
#+attr_shortcode:
#+begin_run
ip route | grep virbr0 | cut -d " " -f 1
#+end_run
#+begin_stdout
192.168.122.0/24
#+end_stdout


**** Configure IP Address and MAC address

#+begin_env
IP_ADDRESS=192.168.122.2
MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]')
#+end_env

#+attr_shortcode: :style tip
#+begin_notice
You need to choose a valid IP_ADDRESS in the range of your subnet,
although on every machine I've tried this on so far, the default has
been =192.168.122.0/24=. The MAC address will be randomized to create
a static lease.
#+end_notice

**** Create static DHCP lease

#+attr_shortcode:
#+begin_run
sudo virsh net-update default add-last ip-dhcp-host "&lt;host mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /&gt;" --live --config --parent-index 0
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
You can edit the file manually to do more cleanup. After editing, you
must stop (destroy) and restart the network.

#+begin_run
sudo virsh net-edit default
sudo virsh net-destroy default
sudo rm /var/lib/libvirt/dnsmasq/virbr0.status
sudo virsh net-start default
sudo virsh net-dhcp-leases default
#+end_run
#+end_notice

**** Create env file to store main config settings

#+attr_shortcode:
#+begin_run
TMP_ENV=$(mktemp)
cat << EOF > ${TMP_ENV}
export NAME=${NAME}
export OS_VARIANT=${OS_VARIANT}
export IP_ADDRESS=${IP_ADDRESS}
export MAC_ADDRESS=${MAC_ADDRESS}
export CLOUD_IMAGE=${CLOUD_IMAGE}
export MEMORY=${MEMORY}
export CPUS=${CPUS}
export DISK_SIZE=${DISK_SIZE}
export USER_DATA=~/libvirt/cloud-init/${NAME}.yaml
EOF
chmod a+r ${TMP_ENV}
sudo su ${VM_ADMIN:-libvirt-admin} -c \
    "mkdir -p ~/libvirt && cp ${TMP_ENV} ~/libvirt/${NAME}.env"
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
This will create a new config file *in the libvirt-admin user's home directory*
=~/libvirt/${NAME}.env=.
#+end_notice

*** Create VM (cloud-init)
:PROPERTIES:
:EXPORT_FILE_NAME: create-vm
:END:
#+attr_shortcode: :style info
#+begin_notice
*For this entire section you need to perform the VM config as the =libvirt-admin= user.*

Login to the shell account of  =libvirt-admin=:

#+begin_run
sudo su libvirt-admin -l
#+end_run
#+end_notice

**** Source the config

Now, and anytime you come back later to work on the same VM, source the config file:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
NAME=debian-dev
source ~/libvirt/${NAME}.env
#+end_run

**** Create directories to hold the VM disks and config files:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso}
#+end_run

**** Create the cloud-init config file:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
cat << EOF | sed 's/\xe2\x80\x8b//g' > ${USER_DATA}
#cloud-config
hostname: ${NAME}
users:
  - name: root
    ssh_authorized_keys:
      - $(cat ~/libvirt/user-ssh.pub)
EOF
#+end_run

**** Download the cloud image:

#+attr_shortcode: :style tip
#+begin_notice
You only need to download each CLOUD_IMAGE once, they will be cached
in =~/libvirt/cloud-images=, so they can be be reused.
#+end_notice

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
(set -e
cd ~/libvirt/cloud-images
curl -LO ${CLOUD_IMAGE}
chmod a-w $(echo ${CLOUD_IMAGE} | grep -Po ".*/\K.*$")
)
#+end_run

**** Clean up old VMs with the same name:
#+attr_shortcode: :style warning
#+begin_notice
If you already have a VM with the same name, and you want to start
again from scratch, you need to clean up from the previous install
first:
#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
## To cleanup and REMOVE an old VM named debian-dev:
virsh destroy debian-dev
virsh managedsave-remove debian-dev
virsh undefine debian-dev
#+end_run
#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+end_notice

**** Create the disk image for the new VM:
#+attr_shortcode: :style warning
#+begin_notice
This is destructive of the existing disk file!
#+end_notice


#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
(set -e
cp ~/libvirt/cloud-images/$(echo ${CLOUD_IMAGE} | grep -Po ".*/\K.*") \
   ~/libvirt/disks/${NAME}.qcow2
chmod u+w ~/libvirt/disks/${NAME}.qcow2
qemu-img resize ~/libvirt/disks/${NAME}.qcow2 +${DISK_SIZE}G
echo Created ~/libvirt/disks/${NAME}.qcow2
)
#+end_run

**** Create the VM
#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
virt-install \
  --name ${NAME} \
  --os-variant ${OS_VARIANT} \
  --virt-type kvm \
  --cpu host \
  --vcpus ${CPUS} \
  --memory ${MEMORY} \
  --graphics none \
  --console pty,target_type=serial \
  --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \
  --cloud-init user-data=${USER_DATA} \
  --import \
  --disk ~/libvirt/disks/${NAME}.qcow2
#+end_run

**** Watch the console for any errors

As the VM starts up, your terminal will attach to the console output
of the VM. This is to monitor any errors that may occur during the
bootup, especially relating to cloud-init.

Wait until you see this Login message:

#+begin_stdout
debian-dev login: 
#+end_stdout

**** Disconnect from the VM console
To disconnect from the VM console, press the keyboard combination
=Ctrl+]= (meaning to hold the Control key and the right square bracket
key at the same time.)

**** Shutdown the VM

#+attr_shortcode: :style info
#+begin_notice
It is important to shut down the VM the first time after install,
otherwise you will get an error about the unejected cloud-init ISO.
#+end_notice

#+attr_shortcode: :style secondary :title Run this as the libvirt-admin usre
#+begin_run
virsh shutdown ${NAME}
#+end_run

**** Verify VM is shut down
#+attr_shortcode: :style secondary :title Run this as the libvirt-admin user
#+begin_run
virsh list --all
#+end_run

#+begin_stdout
 Id   Name         State
-----------------------------
 -    debian-dev   shut off
#+end_stdout

Before proceeding to the next step, make sure the VM is in the off
state.

** Raw disk VMs
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: raw-disk
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :hidden true
:END:

*** Raw disk VMs
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

If you OS is not packaged as a cloud-init enabled image, you can boot
a raw disk image instead. The example will install Fedora IoT (40)
from raw disk image.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

*** Configure VM (raw disk)
:PROPERTIES:
:EXPORT_FILE_NAME: config
:END:

**** Configure VM with raw disk image

#+begin_env
RAW_DISK=https://download.fedoraproject.org/pub/alt/iot/40/IoT/x86_64/images/Fedora-IoT-raw-40-20240422.3.x86_64.raw.xz
NAME=fedora-iot
OS_VARIANT=fedora40
MEMORY=2048
CPUS=2
DISK_SIZE=30
IP_ADDRESS=192.168.122.6
MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]')
#+end_env

**** Create DHCP lease

#+begin_run
sudo virsh net-update default add-last ip-dhcp-host "&lt;host mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' />" --live --config --parent-index 0
#+end_run

**** Copy config to libvirt-user account

#+begin_run
TMP_ENV=$(mktemp)
cat << EOF > ${TMP_ENV}
export NAME=${NAME}
export OS_VARIANT=${OS_VARIANT}
export IP_ADDRESS=${IP_ADDRESS}
export MAC_ADDRESS=${MAC_ADDRESS}
export RAW_DISK=${RAW_DISK}
export MEMORY=${MEMORY}
export CPUS=${CPUS}
export DISK_SIZE=${DISK_SIZE}
EOF
chmod a+r ${TMP_ENV}
sudo su ${VM_ADMIN:-libvirt-admin} -c \
    "mkdir -p ~/libvirt && cp ${TMP_ENV} ~/libvirt/${NAME}.env"
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
This will create a new config file *in the libvirt-admin user's home directory*
=~/libvirt/${NAME}.env=.
#+end_notice

*** Create VM (raw disk)
:PROPERTIES:
:EXPORT_FILE_NAME: create-vm
:END:
#+attr_shortcode: :style info
#+begin_notice
*For this entire section you need to perform the VM config as the =libvirt-admin= user.*

Login to the shell account of  =libvirt-admin=:

#+begin_run
sudo su libvirt-admin -l
#+end_run
#+end_notice

**** Source the config

Now, and anytime you come back later to work on the same VM, source the config file:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
NAME=fedora-iot
source ~/libvirt/${NAME}.env
#+end_run

**** Create directories to hold the VM disks and config files:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
mkdir -p ~/libvirt/{cloud-images,raw,disks,cloud-init,iso}
#+end_run

**** Download the raw disk:

#+attr_shortcode: :style tip
#+begin_notice
You only need to download each RAW_DISK once, they will be cached
in =~/libvirt/raw=, so they can be be reused.
#+end_notice

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
(set -e
cd ~/libvirt/raw
curl -LO ${RAW_DISK}
chmod a-w $(echo ${RAW_DISK} | grep -Po ".*/\K.*$")
)
#+end_run

**** Create the disk image for the new VM:
#+attr_shortcode: :style warning
#+begin_notice
This is destructive of the existing disk file!
#+end_notice

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
(set -e
xzcat ~/libvirt/raw/$(echo ${RAW_DISK} | grep -Po ".*/\K.*") \
   > ~/libvirt/disks/${NAME}.raw
chmod u+w ~/libvirt/disks/${NAME}.raw
echo Created ~/libvirt/disks/${NAME}.raw
)
#+end_run

**** Create the VM
#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
virt-install \
  --name ${NAME} \
  --os-variant ${OS_VARIANT} \
  --virt-type kvm \
  --cpu host \
  --vcpus ${CPUS} \
  --memory ${MEMORY} \
  --graphics vnc,port=5901,listen=127.0.0.1 \
  --console pty,target_type=serial \
  --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \
  --import \
  --disk ~/libvirt/disks/${NAME}.raw,format=raw
#+end_run

**** Watch the console for any errors

As the VM starts up, your terminal will attach to the console output
of the VM. This is to monitor any errors that may occur during the
bootup, especially relating to cloud-init.

Wait until you see this Login message:

#+begin_stdout
debian-dev login: 
#+end_stdout

**** Disconnect from the VM console
To disconnect from the VM console, press the keyboard combination
=Ctrl+]= (meaning to hold the Control key and the right square bracket
key at the same time.)

**** Shutdown the VM

#+attr_shortcode: :style info
#+begin_notice
It is important to shut down the VM the first time after install,
otherwise you will get an error about the unejected cloud-init ISO.
#+end_notice

#+attr_shortcode: :style secondary :title Run this as the libvirt-admin usre
#+begin_run
virsh shutdown ${NAME}
#+end_run

**** Verify VM is shut down
#+attr_shortcode: :style secondary :title Run this as the libvirt-admin user
#+begin_run
virsh list --all
#+end_run

#+begin_stdout
 Id   Name         State
-----------------------------
 -    debian-dev   shut off
#+end_stdout

Before proceeding to the next step, make sure the VM is in the off
state.


** Systemd services to control VMs
:PROPERTIES:
:EXPORT_FILE_NAME: systemd
:EXPORT_HUGO_WEIGHT: 4001
:END:

Systemd services can provide an easy way to manage the on/off state of
the VMs (=systemctl start/stop=), and can (optionally) start VMs
automatically when the host system boots.

#+attr_shortcode: :style warning
#+begin_notice
libvirt has its own =autostart= feature, but we're not using that,
because I couldn't get it to work in user session mode. Systemd units
per VM feels nicer anyway.
#+end_notice

*** Download libvirt python interface

#+attr_shortcode: :style tip
#+begin_notice
You should now be in your *normal workstation account* Bash shell.
#+end_notice

#+begin_run
(set -e
sudo mkdir -p /usr/local/src/
sudo su -c "cd /usr/local/src && git clone https://github.com/EnigmaCurry/virsh-start-stop"
)
#+end_run

#+attr_shortcode: :style credits :title CREDITS :icon gift
#+begin_notice
EnigmaCurry/virsh-start-stop is my own fork of
[[https://github.com/avollmerhaus/virsh-start-stop][avollmerhaus/virsh-start-stop]] which has been slightly customized for
this configuration. Thank you to avollmerhaus for creating this
service manager!
#+end_notice

*** Create Unit template

This is an instantiable template used for all VM services:

#+begin_run
VM_ADMIN=${VM_ADMIN:-libvirt-admin}
cat << EOF | sudo tee /etc/systemd/system/libvirt@.service
[Unit]
Description=${VM_ADMIN} VM: %i
Requires=libvirtd.service
After=libvirtd.service

[Service]
Type=oneshot
RemainAfterExit=true
User=${VM_ADMIN}
Group=libvirt
Environment="XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})"
ExecStart=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state started
ExecStop=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state stopped

[Install]
WantedBy=default.target
EOF
#+end_run

*** Enable each VM service

This will instantiate the VM service template, and enable a VM named
=debian-dev=, which will automatically start on workstation boot:

#+begin_run
NAME=${NAME:-debian-dev}
sudo systemctl enable --now libvirt@${NAME}
sudo systemctl status libvirt@${NAME}
#+end_run

** Public routes to VMs
:PROPERTIES:
:EXPORT_FILE_NAME: public-routes
:EXPORT_HUGO_WEIGHT: 5000
:END:

By default, all incoming traffic to the VMs must originate from your
workstation (or another VM on your workstation) - no traffic is routed
to your VMs from any other interface.

If you want to break this rule, and allow public routes into these VMs
(DNAT port forwarding), you will need to install the libvirt hook that
sets up the iptables forwarding rules:

*** Download the port-forwarding hook

#+begin_run
sudo mkdir -p /usr/local/src/
sudo su -c "cd /usr/local/src && git clone https://github.com/EnigmaCurry/libvirt-hook-qemu.git"
#+end_run

#+attr_shortcode: :style credits :title CREDITS :icon gift
#+begin_notice
EnigmaCurry/libvirt-hook-qemu is my own fork of
[[https://github.com/saschpe/libvirt-hook-qemu][saschpe/libvirt-hook-qemu]] which has been slightly customized for this
configuration. Thank you to Sascha Peilicke for creating this hook!
#+end_notice

*** Install the hook files

#+begin_run
sudo mkdir -p /etc/libvirt-dnat-hook
sudo cp /usr/local/src/libvirt-hook-qemu/hooks.schema.json /etc/libvirt-dnat-hook
#+end_run

*** Set config variables

Set some temporary variables the same as from your config:

#+begin_env
NAME=debian-dev
IP_ADDRESS=192.168.122.2
#+end_env

*** Customize the port-forwarding hook

Use the [[https://github.com/EnigmaCurry/libvirt-hook-qemu/blob/master/hooks.json][example]] and [[https://github.com/EnigmaCurry/libvirt-hook-qemu/blob/master/hooks.schema.json][schema]] as a reference, then setup the port mapping
you want for each VM:

#+begin_run
NAME=${NAME:-debian-dev}
IP_ADDRESS=${IP_ADDRESS:-192.168.122.2}
cat << EOF | jq | sudo tee /etc/libvirt-dnat-hook/hooks.json
{
  "${NAME}": {
    "interface": "virbr0",
    "private_ip": "${IP_ADDRESS}",
    "port_map": {
        "tcp": [
            [2222, 22],
            [80, 80],
            [443, 443]
        ]
    }
  }
}
EOF
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
This example opens the following public ports:

 * Public TCP port =2222= forwards to the VM's port =22=.
 * Public TCP port =80= forwards to the VM's port =80=.
 * Public TCP port =443= forwards to the VM's port =443=.

UDP ports need to be in their own section, a sibling of TCP. Each VM
needs its own config, mapped at the top level by the VM's unique name.
#+end_notice

*** Autostart port-forwarding script on boot

#+begin_aside
I have not figured out how libvirt hooks are supposed to work with
user-mode VMs. It seems like when the VM starts, the hook never gets
called. So, this section adds another service that triggers the hook
manually on boot to setup the port forwarding for each VM.
#+end_aside

**** Create DNAT service template

#+begin_run
VM_ADMIN=${VM_ADMIN:-libvirt-admin}
cat << EOF | sudo tee /etc/systemd/system/libvirt-DNAT@.service
[Unit]
Description=${VM_ADMIN} VM: %i - DNAT port forwarding
Requires=libvirt@%i.service
Requires=network-online.target
After=libvirt@%i.service
After=network-online.target

[Service]
Type=oneshot
RemainAfterExit=true
Environment="XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})"
Environment="CONFIG_PATH=/etc/libvirt-dnat-hook"
ExecStart=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i start
ExecStop=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i stopped

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl daemon-reload
#+end_run

**** Enable DNAT service once per VM you want to expose

#+begin_run
NAME=${NAME:-debian-dev}
sudo systemctl enable --now libvirt-DNAT@${NAME}.service
sudo systemctl status libvirt-DNAT@${NAME}.service
#+end_run

#+attr_shortcode: :style orange :title Stopping and/or Disabling the service
#+begin_notice
If you want to disable the port mapping, run:

#+begin_run
NAME=${NAME:-debian-dev}
sudo systemctl disable --now libvirt-DNAT@${NAME}.service
#+end_run

Or to temporarily stop the port mapping (until you run =start= or
reboot):

#+begin_run
NAME=${NAME:-debian-dev}
sudo systemctl stop libvirt-DNAT@${NAME}.service
#+end_run

#+end_notice

**** Reboot workstation

Once rebooted, test that your port forward rule exists in iptables
rules:

#+begin_run
sudo iptables-save | grep 2222
#+end_run

#+begin_stdout
-A DNAT-debian-dev -d 10.13.13.227/32 -p tcp -m tcp --dport 2222 -j DNAT --to-destination 192.168.122.2:22
-A SNAT-debian-dev -s 192.168.122.2/32 -d 192.168.122.2/32 -p tcp -m tcp --dport 2222 -j MASQUERADE
#+end_stdout
** Setup workstation SSH config
:PROPERTIES:
:EXPORT_FILE_NAME: setup-workstation
:EXPORT_HUGO_WEIGHT: 5000
:END:

#+attr_shortcode: :style info
#+begin_notice
*For this section, you are back to using your normal workstation user.*
#+end_notice

Append a new host config into your SSH config (=~/.ssh/config=):

#+attr_shortcode: :file ~/.ssh/config
#+begin_edit
Host debian-dev
    Hostname 192.168.122.2
    User root
    ControlMaster auto
    ControlPersist yes
    ControlPath /tmp/ssh-%u-%r@%h:%p
#+end_edit

#+attr_shortcode: :style info
#+begin_notice
*Make sure =Host= and =Hostname= are set correctly for your VM.*
#+end_notice

With this config, you can now use SSH to control the VM:

#+begin_run
ssh debian-dev whoami
#+end_run

#+begin_stdout
root
#+end_stdout

*** Install Docker

You're now ready to use your VM as an install target for whatever you
want. It is recommended to install Docker, which you can learn about
in the volume [[/d.rymcg.tech][Self-hosting Docker]] in the chapter called [[/d.rymcg.tech/workstation][Setup your
workstation]].

** Create VM from .iso (CoreOS)
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: vm-from-iso
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :hidden true
:END:

*** Create VM from .iso image
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 6000
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :hidden true
:END:

The previous section named [[/linux-workstation/kvm-libvirt/create-vm][Create VM (cloud-init)]] installed a VM from
a cloud-init enabled image (colloquially known as a "cloud image"),
which is the streamlined and preferred method of VM installation.
However, not all Linux distributions have a cloud image available. You
may need to manually install the OS using a traditional graphical
installer. Thats what this section is all about.

As an example, these are the steps to install a VM using [[https://fedoraproject.org/coreos/][Fedora CoreOS]]
(which does not support cloud-init, nor a traditional installer). You
will be using the graphical [[https://fedoraproject.org/workstation/download/][Fedora Workstation Live .iso image]] as a
temporary OS to bootstrap CoreOS onto a blank virtual disk.


#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index


*** Configure VM with .iso boot
:PROPERTIES:
:EXPORT_FILE_NAME: configure-vm
:EXPORT_HUGO_WEIGHT: 1000
:END:

**** Configure VM

#+begin_env
NAME=coreos-dev
OS_VARIANT=fedora-coreos-stable
CPUS=1
MEMORY=2048
DISK_SIZE=25
IP_ADDRESS=192.168.122.5
MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]')
ISO_MEDIA=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-40-1.14.iso
#+end_env

**** Write config file into libvirt user directory

#+attr_shortcode:
#+begin_run
TMP_ENV=$(mktemp)
cat << EOF > ${TMP_ENV}
export NAME=${NAME}
export OS_VARIANT=${OS_VARIANT}
export IP_ADDRESS=${IP_ADDRESS}
export MAC_ADDRESS=${MAC_ADDRESS}
export MEMORY=${MEMORY}
export CPUS=${CPUS}
export DISK_SIZE=${DISK_SIZE}
export ISO_MEDIA=${ISO_MEDIA}
EOF
chmod a+r ${TMP_ENV}
sudo su ${VM_ADMIN:-libvirt-admin} -c \
    "mkdir -p ~/libvirt && cp ${TMP_ENV} ~/libvirt/${NAME}.env"
#+end_run

**** Create DHCP lease

#+begin_run
sudo virsh net-update default add-last ip-dhcp-host \
  "&lt;host mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /&gt;" \
  --live --config --parent-index 0
#+end_run
*** Boot VM from .iso
:PROPERTIES:
:EXPORT_FILE_NAME: install-vm
:END:

**** Switch to the libvirt user account
#+attr_shortcode: :style info
#+begin_notice
*For the rest of this section you need to perform the VM config as the
=libvirt-admin= user.*

Login to the shell account of  =libvirt-admin=:

#+begin_run
xhost +local:libvirt-admin
sudo -u libvirt-admin /bin/bash
#+end_run
#+end_notice

#+attr_shortcode: :style tip
#+begin_notice
The =xhost= line is to allow graphical apps (=virt-viewer=) from the
other user appear on your display. You may need to play with xhost a
few times to get it to work. Try =xhost += to temporarily allow all
hosts to use the DISPLAY (and =xhost -= afterward to set it back). If
you start the VM, and the =virt-viewer= fails to load, you can just
fix it, try it again, and reconnect to an existing VM already running
in the background.
#+end_notice

**** Source the config

Now, and anytime you come back later to work on the same VM, source the config file:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
NAME=coreos-dev
source ~/libvirt/${NAME}.env
#+end_run

**** Create directories to hold the VM disks and config files:

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso}
#+end_run

**** Download the ISO image:

#+attr_shortcode: :style tip
#+begin_notice
You only need to download each ISO_MEDIA once, they will be cached
in =~/libvirt/iso=, so they can be be reused.
#+end_notice

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
(set -e
cd ~/libvirt/iso
curl -LO ${ISO_MEDIA}
chmod a-w $(echo ${ISO_MEDIA} | grep -Po ".*/\K.*$")
)
#+end_run

**** Create virtual disk

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
qemu-img create -f qcow2 ~/libvirt/disks/${NAME}.qcow2 ${DISK_SIZE}G
#+end_run

**** Start VM

#+attr_shortcode:  :style secondary :title Run this as the libvirt-admin user
#+begin_run
virt-install \
  --name ${NAME} \
  --os-variant ${OS_VARIANT} \
  --virt-type kvm \
  --graphics spice \
  --cpu host \
  --vcpus ${CPUS} \
  --memory ${MEMORY} \
  --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \
  --boot cdrom,hd,menu=on \
  --disk ~/libvirt/disks/${NAME}.qcow2 \
  --cdrom ~/libvirt/iso/$(echo ${ISO_MEDIA} | grep -Po ".*/\K.*$")
#+end_run

**** Boot Fedora Workstation Live environment

Once the VM starts, the =virt-viewer= window should open and display
the virtual console of the VM.

[[/img/fedora/grub.webp]]

Choose /Start Fedora-Workstation-Live/.

**** Welcome

[[/img/fedora/welcome.webp]]

Wait a minute for the Welcome screen to appear. To use the Live
environment, click /Not Now/.

**** Press Alt-F2 to run a command

[[/img/fedora/run-a-command.webp]]

Open the terminal by pressing =Alt-F2= and then typing the name of the
command: =gnome-terminal=.

**** Gnome Terminal

[[/img/fedora/gnome-terminal.webp]]

**** Verify network IP address

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
ip addr show dev enp1s0 | grep inet
#+end_run

#+begin_stdout
...
inet 192.168.122.5/24 brd 192.168.122.255 scope global dynamic noprefixroute enp1s0
...
#+end_stdout

**** Enable remote SSH access

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
sudo systemctl enable --now sshd
#+end_run

**** Set the live user password

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
passwd
#+end_run

**** Leave the virt-viewer window alone

You're now done needing to use the graphical console of the live
environment, but until you're done setting things up, you'll need to
leave it running for the time being. For now, just hide the window in
another workspace (or minimize the window) but leave it running.

#+attr_shortcode: :style tip
#+begin_notice
I have noticed that the Live environment is set to go to sleep after a
period of inactivity. If it goes to sleep, you may need to move/click
the mouse inside the =virt-viewer= window to wake it up again. There's
probably a great command to disable this, but I don't know it yet..
#+end_notice

**** Leave the libvirt-admin shell

You're also done with the =libvirt-admin= shell for now, press
=Ctrl-D= to leave it. Proceed now, back to using the normal
workstation shell.

*** Bootstrap CoreOS
:PROPERTIES:
:EXPORT_FILE_NAME: bootstrap-coreos
:END:

#+attr_shortcode: :style tip
#+begin_notice
These commands should be run on your *normal workstation account*.
#+end_notice

**** Configure variables to connect to Live environment

#+begin_env
IP_ADDRESS=192.168.122.5
#+end_env

**** Copy SSH key to the liveuser

#+begin_run
ssh-copy-id liveuser@${IP_ADDRESS}
#+end_run

When prompted, type the password that you set for the liveuser
account.

**** SSH into Live environment

From your normal workstation account, connect to the SSH server of the
Fedora Live environment:

#+begin_run
ssh liveuser@${IP_ADDRESS}
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
The reset of the commands in this section should be run *in the Fedora
Live environment*.
#+end_notice

**** Create Butane Config

[[https://coreos.github.io/butane/getting-started/][Butane]] is an intermediate tool used to generate the [[https://coreos.github.io/ignition/][Ignition]] bootstrap
file required for CoreOS.

Create a YAML config file that includes your public SSH keys:

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
(set -eo pipefail
cat << EOF | sed 's/\xe2\x80\x8b//g' > fcos.yaml
variant: fcos
version: 1.5.0
passwd:
  users:
    - name: core
      ssh_authorized_keys:
EOF
cat ~/.ssh/authorized_keys | xargs -iXX echo "        - XX" >> fcos.yaml
podman pull quay.io/coreos/butane:release
podman run --rm --interactive       \
           --security-opt label=disable        \
           --volume ${PWD}:/pwd --workdir /pwd \
           quay.io/coreos/butane:release \
           --pretty --strict fcos.yaml > fcos.ign
)
#+end_run

**** Identify the storage device to install on

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
lsblk
#+end_run

#+begin_stdout
NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
loop0         7:0    0    2G  1 loop 
loop1         7:1    0    8G  1 loop 
live-rw   253:0    0    8G  0 dm   /
live-base 253:1    0    8G  1 dm   
loop2         7:2    0   32G  0 loop 
live-rw   253:0    0    8G  0 dm   /
sr0          11:0    1  2.1G  0 rom  /run/initramfs/live
zram0       251:0    0  956M  0 disk [SWAP]
vda         252:0    0   25G  0 disk 
#+end_stdout

#+attr_shortcode: :style tip
#+begin_notice
For the default VM config, you can see the 25G device named =vda=.
#+end_notice

#+begin_env
DEVICE=vda
#+end_env

**** Install Fedora CoreOS onto the storage device

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
sudo podman run --pull=always --privileged --rm \
    -v /dev:/dev -v /run/udev:/run/udev -v .:/data -w /data \
    quay.io/coreos/coreos-installer:release \
    install /dev/${DEVICE} -i fcos.ign
#+end_run

**** Shutdown Fedora Live environment

CoreOS is now installed, so you can now shutdown the Fedora Live
environment:

#+attr_shortcode:  :style secondary :title Run this in the Fedora Live environment
#+begin_run
sudo poweroff
#+end_run

This will immediately restart the VM and CoreOS should now boot. If
successful you should see the console print the following information:

#+begin_stdout
enp1s0: 192.168.122.5 ....
Ignition: user-provided config was applied
Ignition: wrote ssh authorized keys file for user: core
#+end_stdout

**** Close virt-viewer window.

**** Shutdown CoreOS VM

#+begin_env
NAME=coreos-dev
#+end_env

#+begin_run
sudo XDG_RUNTIME_DIR=/var/run/user/$(id -u libvirt-admin) -u libvirt-admin \
    virsh destroy ${NAME}
#+end_run

**** Edit VM config

Create an XSLT template that will perform the necessary edits to
remove the CD-ROM disk and graphics adapter entries:

#+begin_run
cat &lt;&lt; EOF &gt; edit-coreos-vm.xslt.xml
&lt;xsl:stylesheet version="1.0"
 xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;

 &lt;xsl:output omit-xml-declaration="yes"/&gt;

    &lt;xsl:template match="node()|@*"&gt;
      &lt;xsl:copy&gt;
         &lt;xsl:apply-templates select="node()|@*"/&gt;
      &lt;/xsl:copy&gt;
    &lt;/xsl:template&gt;

    &lt;xsl:template match="bootmenu[@enable='yes']"/&gt;
    &lt;xsl:template match="boot[@dev='cdrom']"/&gt;
    &lt;xsl:template match="disk[@device='cdrom']"/&gt;
    &lt;xsl:template match="channel[@type='spicevmc']"/&gt;
    &lt;xsl:template match="graphics"/&gt;
    &lt;xsl:template match="sound"/&gt;
    &lt;xsl:template match="audio"/&gt;
    &lt;xsl:template match="redirdev[@type='spicevmc']"/&gt;
    &lt;xsl:template match="video"/&gt;
&lt;/xsl:stylesheet&gt;
EOF
#+end_run

Redefine the VM using the edited config:

#+begin_run
(set -e
virsh dumpxml ${NAME} | xsltproc edit-coreos-vm.xslt.xml - > ${NAME}.xml
virsh define ${NAME}.xml
)
#+end_run

**** Enable systemd service to start VM

#+begin_run
sudo systemctl enable --now libvirt@${NAME}
sudo systemctl status libvirt@${NAME}
#+end_run
**** Create SSH config

Create a Host entry in your =~/.ssh/config= file to make connections
easy:

#+attr_shortcode: :file ~/.ssh/config
#+begin_edit
Host coreos-dev
     Hostname 192.168.122.5
     User core
     ControlMaster auto
     ControlPersist yes
     ControlPath /tmp/ssh-%u-%r@%h:%p
#+end_edit

Remove the old host keys from the live user environment for your
=~/.ssh/known_hosts= file:

#+begin_run
ssh-keygen -R ${IP_ADDRESS}
#+end_run

Test logging into the VM from your workstation:

#+begin_run
ssh coreos-dev
#+end_run

**** Install Docker

Docker comes preinstalled on CoreOS, you just have to enable it:

#+begin_run
ssh coreos-dev sudo gpasswd -a core docker
ssh coreos-dev sudo systemctl enable --now docker
#+end_run

#+attr_shortcode: :style warning
#+begin_notice
Because of the =ControlMaster= config, you will need to kill your
existing connection to reload the session, and load new groups.

#+begin_run
ssh -O exit coreos-dev
#+end_run

Then check your groups again, to be sure it includes =docker=:

#+begin_run
ssh coreos-dev groups
#+end_run

#+begin_stdout
core adm wheel sudo systemd-journal docker
#+end_stdout
#+end_notice

Next, follow the [[/d.rymcg.tech][Self-Hosting Docker]] book to setup this VM as a Docker
context on your workstation.

* Firewall
:PROPERTIES:
:EXPORT_FILE_NAME: firewall
:EXPORT_HUGO_WEIGHT: 9000
:END:

** Firewalld

[[https://firewalld.org/][Firewalld]] is an abstraction of [[https://netfilter.org/projects/nftables/index.html][nftables]] (which is an abstraction of
[[https://netfilter.org/][netfilter]]). Firewalld is installed on Fedora systems by default, and
it is what is used to configure the system firewall.

Firewalld rules are grouped into /zones/. There can be multiple zones,
and you may switch between them. There can only be /one active/ zone
per network interface.

*** Don't mess with it

#+attr_shortcode: :style warning
#+begin_notice
Fedora Atomic installs a good default zone for workstation use, named
=public=. Theres really nothing more for you to do here. *This chapter
will mostly discuss things you should /NOT/ change on a workstation*,
but this is a general guide as to how these things work, and how to
modify the rules if the need should arise.

If you are running virtual machines, these use a different interface
=virbr0=, and so they use a different zone named =libvirt=. The VM
routes are configured separately. Read the chapter [[/linux-workstation/kvm-libvirt/public-routes][Public routes to
VMs]].
#+end_notice

*** Default Zone

Firewalld lets you configure multiple zones, which are segmented
realms for different network activity or locations (for example, there
are predefined zones for =home= and =work=).

Check out the default zones of the system:

#+begin_run
firewall-cmd --get-active-zones
#+end_run

#+begin_stdout
libvirt
  interfaces: virbr0
public (default)
  interfaces: enp4s0
#+end_stdout

This shows two active zones, one per interface:

 * =public=, which it mentions is the default, is attached to the
   primary network interface =enp4s0=.
 * =libvirt=, which is all the [[/linux-workstation/kvm-libvirt/public-routes][libvirt rules defined for VMs]], and only
   listening on the libvirt network interface =virbr0=.

*** Changing the default zone
   
#+attr_shortcode: :style tip
#+begin_notice
As long as you don't need multiple zones, it's recommended to use the
default =public= zone. But here is how you can switch zones if you
need to change it to something else (eg. =work=):

#+begin_run
ZONE=work
sudo firewall-cmd --set-default-zone ${ZONE}
#+end_run

This change is *permanent*, until you change it again.
#+end_notice

*** Zone files
On Fedora Atomic, there are two directories that contain firewalld
zone files:

 * =/etc/firewalld/zones= this is the /primary/ zone directory, and it
   takes precedence. The directory is empty by default.
 * =/usr/lib/firewalld/zones/= this is the /secondary/ *read-only*
   default zone directory. The files here are loaded only if the
   primary zone directory is missing a file with the same name.
   
*** Public zone

Look at the default public zone file:

#+begin_run
cat /usr/lib/firewalld/zones/public.xml
#+end_run

#+begin_stdout
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;zone&gt;
  &lt;short&gt;Public&lt;/short&gt;
  &lt;description&gt;For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.&lt;/description&gt;
  &lt;service name="ssh"/&gt;
  &lt;service name="mdns"/&gt;
  &lt;service name="dhcpv6-client"/&gt;
  &lt;forward/&gt;
&lt;/zone&gt;
#+end_stdout

You can find out what these services are by grepping =/etc/services=:

#+begin_run
cat /etc/services | grep -P "^(dhcpv6-client|ssh|mdns) " | sort -u
#+end_run

#+begin_stdout
dhcpv6-client   546/tcp
dhcpv6-client   546/udp
mdns            5353/tcp    # Multicast DNS
mdns            5353/udp    # Multicast DNS
ssh             22/sctp     # SSH
ssh             22/tcp      # The Secure Shell (SSH) Protocol
ssh             22/udp      # The Secure Shell (SSH) Protocol
#+end_stdout

So that means that the only incoming ports that are allowed are:

 * SSH (port 22, but only if you enable the SSH service.)
 * multicast (broadcast) DNS (port 5353)
 * IPV6 link-local DHCP (port 546)

*** Test blocked ports
Start a local netcat server on port 5000 (which is blocked by default):

#+begin_run
nc -l 5000
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
Leave the =nc= server running, and open another terminal window to
continue on. When you are done testing, press =Ctrl-C= to quit nc.
#+end_notice

From /another machine/, on the same network, try connecting to the
blocked port 5000 on the workstations LAN ip address:

#+attr_shortcode: :style none :title Run this on another machine on the same network
#+begin_run
WORKSTATION=192.168.1.10; nc ${WORKSTATION} 5000
#+end_run

It should immediately exit (return 1), and print nothing, because the
port is blocked.

*** Adding a temporary rule

#+begin_run
sudo firewall-cmd --add-port=5000/tcp
#+end_run

From /another machine/, on the same network, try connecting to the now
open port 5000:

#+attr_shortcode: :style none :title Run this on another machine on the same network
#+begin_run
WORKSTATION=192.168.1.10; nc ${WORKSTATION} 5000
#+end_run

This time it should sucessfully connect. You can type some message and
then press =Enter=. You should see the message in the original window
running the =nc= server. If you see the message, you know the port is
open.

This rule is temporary, and will go away when the system reboots.

*** Adding a permanent rule

#+begin_run
sudo firewall-cmd --add-port=5000/tcp --permanent
#+end_run

This adds the rule to the permanent config
=/etc/firewalld/zones/public.xml=, and it will survive a system
reboot:

#+attr_shortcode: :title Excerpt from /etc/firewalld/zones/public.xml
#+begin_notice
<port port="5000" protocol="tcp">
#+end_notice

*** Remove a permanent rule

#+begin_run
sudo firewall-cmd --remove-port=5000/tcp --permanent
#+end_run

*** Adding a new zone

#+begin_run
NEW_ZONE=foo
sudo firewall-cmd --permanent --new-zone=${NEW_ZONE}
#+end_run

*** Promoting all temporary rules to permanent rules

#+begin_run
sudo firewall-cmd --runtime-to-permanent
#+end_run

*** Showing all firewall rules

To show all the netfilter rules formatted for nftables:

#+begin_run
sudo nft list ruleset
#+end_run

To show all the netfilter rules formatted for iptables:

#+begin_run
sudo iptables-save
sudo ip6tables-save
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
nftables and iptables are equivalent interfaces to the same netfilter
backend. They show the same rules, just in a different format,
depending on your preference.
#+end_notice

*** How to query nftables
**** Show all tables
#+begin_run
sudo nft list tables
#+end_run
#+begin_stdout
table inet firewalld
table ip filter
table ip nat
table ip mangle
table ip6 filter
table ip6 nat
table ip6 mangle
#+end_stdout
**** Show table chains
#+begin_run
TABLE=filter
sudo nft list table ip ${TABLE}
#+end_run
**** Show chain
#+begin_run
TABLE=filter
CHAIN=FORWARD
sudo nft list chain ip ${TABLE} ${CHAIN}
#+end_run
*** How to query JSON info from nftables
**** Get chain

#+begin_run
CHAIN=filter_IN_public_allow
sudo nft -j list ruleset | jq '.nftables[] | select(has("chain")) | select(.chain.name == "'${CHAIN}'")'
#+end_run

#+begin_stdout
{
  "chain": {
    "family": "inet",
    "table": "firewalld",
    "name": "filter_IN_public_allow",
    "handle": 153
  }
}
#+end_stdout

**** Get rules per chain

#+begin_run
CHAIN=filter_IN_public_allow
sudo nft -j list ruleset | jq '.nftables[] | select(has("rule")) | select(.rule.chain == "'${CHAIN}'")'
#+end_run

**** Get destination ports (DNAT) per chain

#+begin_run
CHAIN=filter_IN_public_allow
sudo nft -j list ruleset | jq -c '.nftables[] | select(has("rule")) | select(.rule.chain == "'${CHAIN}'") | .rule.expr[0] | select(.match.left.payload.field == "dport") | .match.right'
#+end_run

#+begin_stdout
22
5000
#+end_stdout

#+attr_shortcode: :style warning
#+begin_notice
This might need better filtering and account for the "allow" action only.
#+end_notice

*** Read firewalld script

=/usr/lib/python3.12/site-packages/firewall/core/nftables.py=

*** Useful links

 * [[https://wiki.nftables.org/wiki-nftables/index.php/Netfilter_hooks][Netfilter hooks flowchart]]
