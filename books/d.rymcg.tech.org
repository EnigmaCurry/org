#+hugo_base_dir: ../hugo
#+hugo_section: /d.rymcg.tech
#+hugo_weight: auto
#+hugo_paired_shortcodes: %notice badge button %children %index %run %stdout %edit math mermaid openapi
#+STARTUP: align

* Self-hosting Docker with d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :linkTitle Self-hosting Docker
:EXPORT_HUGO_WEIGHT: 200
:END:

This book describes how to get started with self-hosting your own
Docker server, using the tools provided by [[https://d.rymcg.tech][d.rymcg.tech]].

#+attr_shortcode: :icon code-branch :style primary :href https://github.com/EnigmaCurry/d.rymcg.tech#readme
#+begin_button
d.rymcg.tech
#+end_button

#+attr_shortcode: :icon comment-dots :style red :href https://matrix.to/#/#d.rymcg.tech:enigmacurry.com
#+begin_button
Chat with us on Matrix
#+end_button

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

* Introduction
:PROPERTIES:
:EXPORT_FILE_NAME: introduction
:EXPORT_HUGO_WEIGHT: 200
:END:


** What is self-hosting?

Self-hosting is the practice of hosting network applications (web /
internet / LAN / etc), using your own server hardware, or at least on
virtual machines that you fundamentally control (ie. you have root
access). As a preparedness skill, the self-hoster prioritizes the use
of open source software, as it becomes an inalienable toolset to
bootstrap infrastructure in the wilderness.

You can apply self-hosting a little bit, or a lot. On the one hand,
you could post all of your content on Facebook (obviously, this is
/not/ self-hosting), and on the other hand you could build all your
servers yourself, from parts, and run them in your basement, on your
own network, bootstrapping everything. For most people though,
self-hosting means to use a Raspberry Pi at home, or a cloud computing
provider that offers you a generic Linux VPS (virtual private server)
on the public internet, to configure in any way you wish, but still
letting the cloud provider handle the hardware and network side of
things for a monthly fee.

Demarcate your own level of abstraction. Test that your operations
work in a generic way, portable to any other provider at the same
level of abstraction. Try running it entirely at home, at least for
development purposes. Don't get locked into a single vendor. Use open
source software, or software you built yourself. This is self-hosting.

** What is Docker?

[[https://www.docker.com/][Docker]] is a software platform for running containers on Linux.
Containers let you install and run software in an isolated and generic
way. It solves the problems of [[https://en.wikipedia.org/wiki/Dependency_hell]["dependency hell"]] and [[https://donthitsave.com/comic/2016/07/15/it-works-on-my-computer]["But it works on
my computer!"]], for all Linux distributions. Containers are created
from images that include /all/ of their dependencies, including the
operating system to support it. The only thing a container does /not/
include, is the Linux kernel, which is shared from the host with all
the containers running on the same host. This abstraction makes it
work the same way on all computers, regardless of Linux distribution
(assuming an up to date kernel). Docker maintains persistent volumes
for each container, so that they may mount it into their own virtual
filesystem, and thus storing all of its important data into the
volume. You may upgrade, or even delete these containers, and as long
as you keep the volume(s), you can simply reprovision the same images
(even on new hardware), and the containers will load all of its same
data from before.

** What is a container?

Although it is possible to run desktop software inside of a Docker
container, 99% of the time a Docker container is created to run a
/service/, assumed to run on a server, assumed to be serving remote
clients. Generally, a container is designed only to run a single
service. For example: /A/ web server, /a/ chat server, /a/ DNS server,
/a/ python server you write, etc. Multiple instances of the same image
can run as separate containers, and they can even share volumes, if
you want (though generally not).

Containers are related to a different technology that you might
already be familar with: Virtual Machines. However, there are several
fundamental differences between containers and virtual machines, and
so it is useful to describe them here as a comparison:

| Feature           | Container                                                                                                                  | Virtual Machine                                                       |
|-------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------|
| Kernel            | Containers share a kernel with the host                                                                                    | VMs runs their own kernel                                             |
| Hardware          | Containers share hardware with the host, but with the addition of a permissions model to access it                         | VMs use hardware virtualization features                              |
| Memory            | Containers share memory with the host                                                                                      | VMs use a fixed size virtual hardware memory space                    |
| Disk              | Containers share storage system with the host (volumes live under =/var/lib/docker/= by default)                           | VMs use a fixed size (but expandable) virtual hard disk image         |
| Network           | Containers support Host level networking, or can do NAT                                                                    | NAT or bridge network, not host level                                 |
| Execution model   | Containers are just a regular Linux processes, run under a given user account                                              | VMs run their own kernel and init (systemd)                           |
| Init process      | Containers don't need an init process, Docker runs the containers process (CMD) directly                                   | VMs run their own kernel and init (systemd)                           |
| Process isolation | Containers run as as regular Linux processes, which have a capabilities system to limit privileges                         | VMs are like a separate machine, and a have a separate process space  |
| Root filesystem   | Containers inherit a root filesystem from their image, which contain all the application files, and the OS, minus a kernel | VMs are run from (linked) virtual disk images                         |
| Volumes           | Containers automatically mount volumes provided from Docker. Docker maintains the lifecycle of these volumes.              | VMs can have multiple virtual disks, or manually mount remote volumes |

Containerization uses features of the Linux kernel, (specifically,
namespaces and cgroups). For the purposes of this book, the term
"container" will always imply that it is running on a Linux host; it
is inseparable from the host kernel, and it can't work without it!
(You may be aware that you can install a product called "Docker
Desktop" on Windows or MacOS. This product installs a Linux virtual
machine on your host OS and runs Docker inside it, and then it
installs the docker client on the host OS, so it appears seamless.)

In a general context, there are other OS containers, like Windows
containers, however they are on the fringe, and will not be discussed
in this book. Containers imply Linux.

Docker is a good platform to pick for self-hosting containers, because
it's a mature open source project, and it works on virtually any Linux
computer or VPS. Docker is server focussed, and therefore ideal for
self-hosting. Docker is easy to get started with, even if you're a
beginner.

** What is Docker Compose?

Docker uses a client-server API pattern of control. You install the
Docker daemon on a server machine, and this machine is called the
Docker Host. Usually you interact with the API through the command
line =docker= tool. Docker provides primitive commands for running
single containers directly, with =docker run=. However, for larger
projects that need more than one container (eg. a webserver + a
database) and need to be able to talk to one another, =docker run= is
not the best tool to use.

=docker compose= is a command that operates your containers from a
project level abstraction. =docker compose= lets you define all the
containers and volumes that you need for a given project, in a
declarative way, in a =docker-compose.yaml= file.

With =docker compose= you can start/stop/delete all the project
containers together, as a single unit.

** What is d.rymcg.tech?

[[https://github.com/EnigmaCurry/d.rymcg.tech][d.rymcg.tech]] is a collection of docker compose projects for various
open source server applications, but it can also be used as a template
for your own services. It has an integrated frontend proxy ([[https://doc.traefik.io/traefik/][Traefik
Proxy)]], including sentry authorization middleware (mTLS, OAuth2, or
HTTP Basic auth) and IP address filtering. It is a framework for
packaging your own applications, and managing several container
instances at the same time, each with seprate configs in .env files.

d.rymcg.tech focuses on the config rules of the [[https://12factor.net/config][12-factor principle]].
All of the configuration for a container should be specified as
environment variables, which Docker loads from a standard =.env= file.
All of the data for a container should live inside a [[https://docs.docker.com/storage/volumes/][Docker Volume]]
(not a bind mount), and so the lifecycle of the volume is maintained
by Docker directly.

*d.rymcg.tech is designed to run on a workstation, not the docker
host*. The Docker server API is accessed remotely over SSH. Only your
personal workstation should be used to issue =docker= commands that
affect the server, they should never be run on the server itself. It's
important to keep the server as bare bones and hands off as possible.
The server's only job is to /run/ containers. The job of /configuring/
them is always performed from a remote workstation. Once the server is
setup, you won't normally need to even login to the server console
ever again. By controlling the server from your workstation, you can
manage the server in a clean fashion. You can even create a new server
from scratch, in no time. All of the important configuration stays on
your workstation (and are backed up in a git repository).

* Required Infrastructure
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: required-infrastructure
:END:

** Required Infrastructure
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 201
:END:

A public internet Docker server needs several resources that you need
to procure :

 * A domain name registrar (eg. Gandi.net).
 * A domain name server (eg. DigitalOcean DNS).
 * A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet).
 * An internet network connection (eg. DigitalOcean network).

#+begin_index
index
#+end_index

** Register a domain name
:PROPERTIES:
:EXPORT_FILE_NAME: register-a-domain-nameom
:END:

To host a web service, one of the first things you will need is to
register your domain name. This will be the domain name used for all
of your service links, and it is what your users will need to type
into their browsers (or click on) to visit your pages.

Public domain names are a scarce resource. Because of their scarcity,
you must pay for your domain registrations, doing so in 1 year
increments. If domain names were free, all the good ones would be
taken by now, but because they cost money, there are still some good
enough ones left to be had. In return for your fee, you receive
exclusive use of your domain name for the period that you paid for.
You "own" the domain name, and its configuration, but you need to keep
paying a registrar to keep the record active (so its more like
renting). You can pre-pay for several years in advance, or for just
pay one year at a time. If you stop paying, and the records expire,
they will no longer resolve to your services, and you may lose control
of the domain, possibly forever.

*** Domain names for private servers

If you control your own DNS servers, you could use completely made up
domain names under the =.internal= domain, which are [[https://www.icann.org/en/public-comment/proceeding/proposed-top-level-domain-string-for-private-use-24-01-2024][RFC recoginized
for private usage]]. But for most public servers, where most clients
use different DNS servers, you will want to register a "real" domain
instead.

For private servers, (eg. running a private Docker server at home),
it is still recommended that you use a valid internet domain name,
using public DNS servers, because you will still need this in order to
create valid TLS certificates from [[https://letsencrypt.org/][Let's Encrypt]]. However, having
valid working TLS is not /required/ for development purposes (but
certainly nice to have!), so you may choose to make up your own fake
domain name instead, and forgo TLS, or you can setup [[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/step-ca#readme][Step-CA]] for
off-grid TLS. In either case, you will still need to setup DNS, and
this is explained in the next section.

*** Register an Internet domain name

You can buy (rent) a domain name from lots of places. For
documentation purposes, we will use [[https://www.gandi.net][Gandi.net]], but these instructions
will be similar regardless of the domain provider you pick.

 * Sign up for an account at [[https://www.gandi.net/][Gandi.net]]
 * Once signed in, from your dashboard, click =Register=.
 * Search for any domain name you like, eg. =your-name.com=.
 * Add your domain to the shopping cart, go to checkout, and complete
   your purchase.
 * Once you have purchased the domain, it should show up in your
   =Dashboard=, under the =Domain= tab.
 * Leave this browser tab open, you will return to it in the next
   chapter.
** Setup public DNS service
:PROPERTIES:
:EXPORT_FILE_NAME: setup-dns
:END:

A DNS server maps your domain (and all subdomain) names to the various
IP addresses of your servers. DNS is required for your users to be
able to type (or click on) your domain name =prod.example.com= and
have it resolve to the IP address that is required to contact your
Docker server (=prod=). Beyond this, DNS is also a means of proving to
a third party that you are the owner (controller) of your own domain,
which is used as a part of the ACME challenge that Let's Encrypt (or
Step-CA) uses when signing your TLS certificates.

Now that you have registered a domain name, you need to tell your
registrar where your DNS server is. Usually you will use the DNS
server that your cloud provider gives you, but you may choose any DNS
provider you like. If you are creating a private server, you may still
want to choose a public DNS server, but using private IP addresses
ranges for the records. You can also setup a local/private DNS server,
but this will be discussed later.

For the purposes of ACME (automatic TLS certificate issuing/renewals),
your DNS server/provider will need to support [[https://go-acme.github.io/lego/dns/#dns-providers][one of the APIs
supported by the go-lego project]]. Find out what API tokens or other
settings your provider may need by by finding your provider in the
list on that page.

For documentation purposes, this chapter will assume you are using
Gandi.net as your domain registrar, and that you want to use
DigitalOcean.com as your domain's public DNS server (and [[https://go-acme.github.io/lego/dns/digitalocean/][digitalocean
is supported by go-lego]]), but these instructions will be similar
regardless of the supported provider you pick.

*** Configure your domain's DNS server on Gandi.net

 * Login to your [[https://admin.gandi.net][gandi.net]] dashboard.
 * Click the =Domain= tab.
 * Find your domain name in the list and click on it.
 * Click on the =Nameservers= tab.
 * Click on the edit button to create new =External nameservers=.
 * Delete all existing nameservers that may exist.
 * Add the following nameservers, specific to DigitalOcean:
   
   * =ns1.digitalocean.com=
   * =ns2.digitalocean.com=
   * =ns3.digitalocean.com=

Wait a few minutes for the change to take effect, then you can verify
the setting from your workstation, using the =whois= command:

#+begin_run
whois example.com
#+end_run

#+begin_stdout
Domain Name: example.com
Registrar WHOIS Server: whois.gandi.net
Name Server: DNS1.EXAMPLE.NET
Name Server: DNS2.EXAMPLE.NET
Name Server: DNS3.EXAMPLE.NET
Name Server: DNS4.EXAMPLE.NET
#+end_stdout

The output shows a report for your domain registration, including the
list of the new nameservers.

*** Setup public DNS on DigitalOcean.com

 * Signup for an account at [[https://m.do.co/c/069af06b869e][DigitalOcean]], if you haven't already.
 * Login to the [[https://cloud.digitalocean.com/][cloud console]].
 * Click on the =Networking= tab in the menu.
 * Click on the =Domains= tab.
 * Enter your domain name into the box and click =Add Domain=.

DigitalOcean is now in charge of your DNS for your domain. You will
return to this screen later on, when creating individual subdomain
records for your services.
** Create a public server (VPS)
:PROPERTIES:
:EXPORT_FILE_NAME: public-docker-server
:END:

This section will guide you to create your own public Docker server,
using a DigitalOcean droplet as an example. In a similar fashion, you
can install Docker on any cloud provider, or dedicated host that you
prefer.

**** Choosing a VPS provider

One of the most basic units of cloud computing is the Virtual Private
Server (VPS). A VPS is a (Linux) virtual machine that is provisioned
by a cloud service, and you are given root access to fully administer
it, to install whatever you want on it. VPS generally come with a dedicated
IP address and have a public internet connection, although some VPS
only have NAT, but with dedicated port forwarding.

In this guide you will create a VPS with a DigitalOcean droplet.

You can install Docker on almost any Linux machine, but some are
better than others. DigitalOcean droplets (VPS) are a good choice for
experimenting, because they are billed hourly, and because the service
layer has an integrated firewall, external to the droplet operating
system. Having a firewall that is external (in front of) the VPS is
one of the most important features to look for in a hosting provider.

**** Setup your SSH key on DigitalOcean

If you have not yet setup an SSH key on your workstation, [[file:linux-workstation.org][read the
Linux Workstation book]] and do that first.

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Settings= in the menu.
 * Click on the =Security= tab.
 * Click on the =Add SSH Key= button.
 * Paste your public SSH key into the box. (copy your pub key from the
   output of ~ssh-add -L~.)
 * Enter a key name, I recommend this be the name of your workstation
   computer.
 * Finish adding the key, click =Add SSH Key=.

**** Create a DigitalOcean firewall template

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Firewalls= tab.
 * Click =Create Firewall=.
 * Enter the name, eg. =basic-docker-public-web=.
 * Enter the following rules:
   * SSH:
     * Type: =SSH=
     * Protocol: =TCP=
     * Port Range: =22=
     * Sources: All IPv4, All IPv6, or a specific static IP address if
       you want to be more secure.
   * HTTP:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =80=
     * Sources: All IPv4, All IPv6.
   * HTTPS:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =443=
     * Sources: All IPv4, All IPv6.
   * Wireguard VPN (optional):
     * Type: =Custom=
     * Protocol: =UDP=
     * Port Range: =51820=
     * Sources: All IPv4, All IPv6.
  * Click =Create Firewall=.
 
**** Creating a DigitalOcean droplet for a Docker server

DigitalOcean provides a Docker image with which to create a droplet
(DigitalOcean's name for their own VPS product).

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Droplets= in the menu.
 * Click =Create Droplet=.
 * Choose a Region (eg. New York), where the droplet will be created.
 * Underneath the heading =Choose an image=, choose =Debian= (select
   the latest version).
 * Choose a droplet size. 2GB RAM and 50GB disk recommended for medium
   size production installs. (It is tested working on as little as
   512MB ram, [[https://blog.rymcg.tech/blog/linux/zram/][if you enable zram]] and/or create a 1GB swapfile. Do not
   abuse swap space like this in production! However I think its fine
   for development use, but you may occasionally run into low memory
   issues if less than 1GB.)
 * Optional: Add a block storage device, in order to store your Docker
   volumes. (This is useful to store data separate from the droplet
   lifecycle, or to have a larger amount of storage than the droplet
   size gives you for the root filesystem. If your basic droplet size
   is already sufficient, and you perform regular backups, this might
   not be needed.)
 * Select your SSH key for the root user.
 * Set the hostname for the docker server. The name should be short
   and typeable, as it will become a part of the canononical service
   URLs. For this example, we choose =prod=.
 * Verify everything's correct, and then click =Create Dropet=.

**** Apply the DigitalOcean droplet firewall

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Find the firewall template you created, and click it.
 * Click on the firewall's =Droplets= tab.
 * Click =Add Droplets= and search for the droplet you created and select it.
 * Click =Add Droplet= to add the firewall to the droplet.

**** Create wildcard DNS records for the droplet

For the purposes of documentation, assume you you own the domain
=example.com= and you have created the Docker server named =prod=. You
should replace =example.com= with your actual domain name, and =prod=
with your actual docker instance name/stage.

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Domains= tab.
 * Find the domain you created earlier, and click it.
 * Create an =A= record:
   * Hostname: enter the subdomain name without the domain part (eg.
     =prod=, the name of your docker server, without the
     =.example.com= suffix).
   * Will direct to: select the droplet you created from the list.
   * Click =Create Record=.
 * Create another =A= record, for the wildcard:
   * Hostname: enter the same name as before but prepend =*.= in front
     of it (eg. if the server is named =prod=, create a record for
     =*.prod=, without the =.example.com= suffix).
   * Will direct to: select the same droplet as before.
   * Click =Create Record=.
 * Optional: create additional records on the root domain. If you
   don't want the docker instance name in the subdomain you give to
   people (eg. =www.prod.example.com=), you could create additional
   (non-wildcard) records on the root domain now (eg.
   =www.example.com=, or even just =example.com=). However, it would
   be wasteful to put a wildcard record on the root domain
   (=*.example.com=) because then the domain could only be used with a
   single Docker instance, therefore all records on the root should be
   non-wildcard, and this means you must add them one by one.

Test that your wildcard record actually works. Use the =dig= command
(For Debian/Ubuntu install the =dnsutils= package. For Arch Linux
install =bind-tools=. For Fedora install =bind-utils=.)

Pick some random subdomain off your domain:

#+begin_run
dig laksdflkweieri.prod.example.com
#+end_run

#+begin_stdout
;; ANSWER SECTION:
laksdflkweieri.prod.example.com.    3600    IN      A       153.114.12.78
#+end_stdout

Since you created the wildcard record for =*.prod.example.com= dig
should return your Docker server's IP address in the =ANSWER SECTION=
of the output. You can test all your other records the same way.

If you run into DNS caching problems, verify with the source DNS
server directly:

#+begin_run
dig @ns1.digitalocean.com laksdflkweieri.prod.example.com
#+end_run

**** Congratulations

You have now finished installation of a remote host running Debian.

You must now configure your workstation to remotely control your
remote Docker context.

* Workstation
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: workstation
:END:

** Setup your workstation
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

You should dedicate the use a physical or virtual Linux machine to be
used as your workstation. A single workstation can manage several
remote Docker contexts.

Follow the [[https://book.rymcg.tech/linux-workstation][Linux Workstation book]] for details on basic
workstation setup.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

** Install Docker client tools
:PROPERTIES:
:EXPORT_FILE_NAME: install-docker-command-line-tools
:END:

You need to install Docker Engine (not Docker Desktop!) on your
workstation.

*** Various ways to install Docker Engine
**** Try your system package manager

Some Linux distributions have decent packages for up-to-date Docker
versions. Some other distributions lag behind by several versions, or
may even introduce non-standard changes of their own. Your mileage may
vary with different operating systems.

If you're on Arch Linux, this is known to be a good configuration:

#+attr_shortcode: :title Run this on your Arch Linux workstations:
#+begin_run
sudo pacman -S docker docker-compose docker-buildx
#+end_run

**** Use the generic Docker installer to install the latest version

If your Linux distribution doesn't provide a Docker package, or you've
decided its not good for your situation, you may be better off by running
the generic installer script from the upstream Docker organization:

#+begin_run
curl -fsSL https://get.docker.com -o install-docker.sh
sudo sh install-docker.sh
#+end_run

**** Install from custom package repository

Use the guides from Docker.com.

 * [[https://docs.docker.com/engine/install/debian/][Debian]]
 * [[https://docs.docker.com/engine/install/ubuntu/][Ubuntu]]
 * [[https://docs.docker.com/engine/install/fedora/][Fedora]]

**** DON'T install Docker Desktop!

 1. Docker Desktop isn't open source. 
 2. Docker Desktop runs a VM to run Docker on localhost. (we don't
    want that, since we will use a remote Docker context instead.)

Always prefer installing Docker Engine instead of Docker Desktop. We
won't need to run the Docker Daemon anyway, so we only need to install
it for the CLI tools it provides (eg. the =docker= command).

*** Disable Docker daemon on your workstation

Your workstation should only be the manager for other Docker hosts, so
it should not run the Docker daemon itself.

Run the following commands to disable the Docker daemon:

#+begin_run
sudo systemctl disable --now docker
sudo systemctl mask docker
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
There will always be a vestigal Docker context named "default", and
this was used to manage the Docker daemon of the local host. However, it
will be of no use to you, since Docker is now completely disabled on
the workstation. Furthermore, the "default" context cannot be deleted,
so its best to just ignore it. In the next couple of steps, you'll
create new contexts that you'll use instead.
#+end_notice

** Install d.rymcg.tech tools
:PROPERTIES:
:EXPORT_FILE_NAME: install-d-rymcg-tech
:END:

Install d.rymcg.tech and its dependencies *on your workstation*.

*** Install dependent packages

#+attr_shortcode: :title If you run Fedora workstations, run this as root
#+begin_run
dnf install bash gettext openssl git xdg-utils jq sshfs curl \
            inotify-tools httpd-tools make wireguard-tools
#+end_run

#+attr_shortcode: :title If you run Debian/Ubuntu workstations, run this as root
#+begin_run
apt-get install bash build-essential gettext git openssl \
        apache2-utils xdg-utils jq sshfs wireguard curl \
        inotify-tools
#+end_run

#+attr_shortcode: :title If you run Arch Linux workstations, run this as root
#+begin_run
pacman -S bash base-devel gettext git openssl apache xdg-utils \
          jq sshfs wireguard-tools curl inotify-tools
#+end_run

*** Clone d.rymcg.tech repository

#+begin_run
git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \
   ${HOME}/git/vendor/enigmacurry/d.rymcg.tech
#+end_run

#+attr_shortcode: :style warning
#+begin_notice
By convention, *you should not change the clone path*. It is
intentionally placed in a vendor neutral path location for all to use.
But if you're adamant to do so, it should still work, regardless of
where you put it. But watch out, as this may break external projects
that assume =ROOT_DIR= is using the conventional path.
#+end_notice

*** Setup =d.rymcg.tech= command line tool

You must edit your workstation user's =~/.bashrc= file, which modifies
the Bash shell environment config:

#+attr_shortcode: :file ~/.bashrc
#+begin_edit
## Put this in ~/.bashrc to enable d.rymcg.tech command line tools:
export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user
eval "$(d.rymcg.tech completion bash)"
## Setup shorter alias for d.rymcg.tech as just 'd'
__d.rymcg.tech_cli_alias d
#+end_edit

#+attr_shortcode: :style info :title Important
#+begin_notice
Close and restart your shell (terminal) to load the new config in a new session.
#+end_notice

*** Test the =d.rymcg.tech= aliases

In your new shell session, you have the following aliases defined:

 * =d.rymcg.tech=
 * =d=

These are both the same, but for brevity, the rest of this
documentation will prefer the =d= alias, but they can be used
interchangeably.

#+begin_run
d
#+end_run

#+begin_stdout
Found ROOT_DIR=/var/home/ryan/git/vendor/enigmacurry/d.rymcg.tech

\## Main d.rymcg.tech sub-commands - Optional arguments are printed in brackets [OPTIONAL_ARG]
cd [SUBDIR]                   Enter a sub-shell and go to the ROOT_DIR directory
create [PROJECT] [TEMPLATE]   Create a new external project from a template
make [PROJECT] [ARGS ...]     Run a `make` command for the given d.rymcg.tech project name
context                       View or set the current Docker context
new-context                   Create a new Docker context
ssh [COMMAND ...]             Run command or shell on active docker context SSH host
completion                    Setup TAB completion in your shell

\## Documentation sub-commands:
help                          Show this help screen
list                          List available d.rymcg.tech projects
                              (not including external projects, unless you symlink them into ROOT_DIR)
readme                        Open the main d.rymcg.tech README.md in your browser
readme [PROJECT]              Open the README.md for the given project name
readme digitalocean           Open root documentation file: DIGITALOCEAN.md
readme security               Open root documentation file: SECURITY.md
readme aws                    Open root documentation file: AWS.md
readme license                Open root documentation file: LICENSE.txt
readme raspberry_pi           Open root documentation file: RASPBERRY_PI.md
readme makefile_ops           Open root documentation file: MAKEFILE_OPS.md
#+end_stdout

** Create SSH config and Docker Context
:PROPERTIES:
:EXPORT_FILE_NAME: ssh-config-and-docker-context
:END:

To remotely control your Docker host from your workstation, you need
two additional configs:

 * SSH Host config in =~/.ssh/config=.
 * Docker Context config via =docker context create ...=.

Both of these can be created automatically by running:
 
#+begin_run
d context new
#+end_run

This will prompt you if you really want to proceed:

#+begin_stdout
? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y
#+end_stdout

You can choose to create a new SSH config, or use an existing one:

#+begin_stdout
? You must specify the SSH config entry to use  
  I already have an SSH host entry in ~/.ssh/config that I want to use
> I want to make a new SSH host entry in ~/.ssh/config
[↑↓ to move, enter to select, type to filter, ESC to cancel]
#+end_stdout

Enter the short one word name for the SSH Host entry:

#+begin_stdout
? Enter the new SSH context name (short host name) : foo
#+end_stdout

Enter the fully qualified DNS name of the Docker host:

#+begin_stdout
? Enter the fully qualified SSH Host DNS name : foo.example.com
#+end_stdout

It will propose to create a new SSH config entry that looks like this:

#+begin_stdout
## Here is the new SSH config entry:
Host foo
     Hostname foo.example.com
     User root
     ControlMaster auto
     ControlPersist yes
     ControlPath /tmp/ssh-%u-%r@%h:%p
? Do you want to append this config to ~/.ssh/config? (y/N) y
#+end_stdout

It will ask you if you want to immediately switch the active Docker
context:

#+begin_stdout
? Do you want to switch to the new foo context now? (y/N) y
foo
Current context is now "foo"
#+end_stdout

*** List all Docker contexts and switch the active one

#+begin_run
d context
#+end_run

#+begin_stdout
? Select the Docker context to use  
  deb
> foo
  step-ca
[↑↓ to move, enter to select, type to filter, ESC to cancel]

Current context is now "foo"
#+end_stdout

** Install Docker on your remote host
:PROPERTIES:
:EXPORT_FILE_NAME: install-docker-on-remote-host
:END:

The base Debian image only has a few basic commands preinstalled. You
must now install the Docker packages and enable the service:

#+attr_shortcode: :title Choose the active Docker context
#+begin_run
d context
#+end_run

#+begin_run
d install-docker
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
=d install-docker= will install Docker *on the remote VPS*, according
to your active docker context.
#+end_notice

*** Test that the context works from your workstation

#+begin_run
docker run hello-world
#+end_run

#+begin_run
docker ps
#+end_run

** Main config for d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: main-config-for-d.rymcg.tech
:EXPORT_HUGO_WEIGHT: 2010
:END:

*** Select your active Docker context

#+begin_run
d context
#+end_run

Each Docker context has a separate config file (=.env_{CONTEXT}=),
stored in the root d.rymcg.tech directory
(=~/git/vendor/enigmacurry/d.rymcg.tech=), so you must actively select
your current context before you can configure it.

*** Configure d.rymcg.tech for the current Docker context

#+begin_run
d make - config
#+end_run

This will create a config file for your current Docker context, and
name it =.env_{CONTEXT}= (eg. =.env_prod=). You must run this for each
new Docker context you create, so that each context has its own config
file.

The interactive config will ask you to enter the =ROOT_DOMAIN=
variable, which needs to be the root domain that you want to apply to
your Docker host.

#+begin_stdout
ROOT_DOMAIN: Enter the root domain for this context (eg. d.example.com)
: prod.example.com
#+end_stdout

The root domain serves as the example root domain for all application
default configs.

* Install Traefik Proxy
:PROPERTIES:
:EXPORT_FILE_NAME: install-traefik-proxy
:EXPORT_HUGO_WEIGHT: 2020
:END:

Traefik Proxy is the central service that acts as a gateway for all of
your applications, so that they can take advantage of automatic TLS
certificates (ACME), perform user authentication (mTLS, OAuth2, HTTP
Basic), apply sentry authorization, and IP address filtering
middlewares, and ultimately decides to route incoming requests to
the backend service containers, or not.

** Configure Traefik Proxy

#+begin_run
d make traefik config
#+end_run

This creates a config for Traefik on your active Docker context. The
configuration is driven by a text wizard menu system.

Once complete, it will have created and configured your
=.env_{CONTEXT}= file for you.

#+begin_stdout
? Traefik config main menu:  
> Create system user on Docker host
  Configure entrypoints (including dashboard)
  Configure Certificate Authorities (CA)
  Configure ACME (Let's Encrypt or Step-CA)
  Configure TLS certificates and domains (make certs)
  Configure middleware (including auth)
v Configure error page template
[↑↓ to move, enter to select, type to filter, ESC to cancel]
#+end_stdout

Use your arrow keys to select a menu item and press the =Enter= key.
To cancel, press the =ESC= key.

*** Create system user on Docker host

This option will create a new username on the Docker host, called
=traefik=. This is necessary to reserve a unique UID for traefik to
run as on the system. Run this first before anything else.

*** Configure entrypoints

Traefik uses various entrypoints to allow requests on certain TCP
ports. By default, only port 80 and 443 are enabled. You can enable
extra entrypoints through this menu, which may be necessary for any
application that doesn't use the standard =websecure= entrypoint (port
443).

By default, the Traefik Dashboard is not enabled. To enable it, you
must select it via this menu option, and set a username / password. It
is only ever exposed to localhost, or through an SSH tunnel, never to
the public network, but it is still best to leave it turned off if you
don't need it.

*** Configure Certificate Authorities (CA)

If you're planning on running a public server, using TLS certificates
from Let's Encrypt, you can skip this option.

You only need to run this if you wish to modify the TLS certificate
trust store to accomodate a "self-signed" Step-CA authority.

*** Configure ACME (Let's Encrypt or Step-CA)

Choose this option to configure ACME, which makes requesting and
renewing TLS certificates an easy and automatic process.

#+begin_stdout
? Which ACME provider do you want to use?  
> Let's Encrypt (ACME)
  Step-CA (ACME)
  Disable ACME
  Cancel / Go back
#+end_stdout

For most installs, you should choose =Let's Encrypt (ACME)=. This is
the only option that will create valid TLS certificates for public
websites.

If you want to run private services, you may want to consider using
=Step-CA= instead, as it does not rely upon any external platform like
Let's Encrypt does.

Finally, if you want to setup TLS certificates manually, you can
choose =Disable ACME=.

**** Configure Let's Encrypt environment

#+begin_stdout
? Which LE environment do you want to use?  
> Production (recommended!)
  Staging (untrusted / testing)
#+end_stdout

#+attr_shortcode: :style tip
#+begin_notice
Always choose the =Production= environment, unless you really know
what you're doing. =Production= is the only environment that produces
valid (trusted) TLS certificates.
#+end_notice

**** Choose type of ACME challenge

#+begin_stdout
? Which type of ACME challenge should be used?  
> TLS-ALPN-01 (default for public servers, easy, but no wildcard certs)
  DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs)
#+end_stdout

#+attr_shortcode: :style tip
#+begin_notice
For your first install, choose =TLS-ALPN-01=, it is the easiest method
to use for public servers.

If you want to use wildcard DNS records, you must choose the more
advanced method =DNS-01=, and setup your DNS platform for programmatic
access with an API token.
#+end_notice


**** Configure ACME email address (optional)

You don't have to provide your email address, but if you do, Let's
Encrypt can email you about configuration issues, like certitficates
about to expire.

*** Configure TLS certificates and domains

d.rymcg.tech uses explicit certificate requests configured centrally,
on the traefik project:

#+begin_stdout
? Configure Traefik TLS certificates  
> Manage all certificates.
  Create a new certificate.
  Done / Go back
#+end_stdout

**** Manage all certificates

This will show you all the certificate requests that have been defined
and allow you to manage each one. It will be blank to start out with.

**** Create a new certificate

Use this to define all the certificates you need for all your
applications.

***** Set certificate main domain (CN)

Each certificate needs a main name (CN), which should be the main
domain name of the certificate.

: prod.example.com

#+attr_shortcode: :style info
#+begin_notice
Each certificate also may contain several other domain names, known as
SANs (Subject Alternative Names). You can use this to list as many
additional domain names that you want to allow for the certificate.
#+end_notice

*** Configure middleware
*** Configure error page template
*** Configure wireguard VPN
*** Install Traefik

To install Traefik (on your active Docker context), you can simply
choose the =Reinstall Traefik= option in the menu, or you can run that
step all by itself from the command line at any time:

#+begin_run
d make traefik install
#+end_run

You should always reinstall Traefik after changing any configuration
setting.
