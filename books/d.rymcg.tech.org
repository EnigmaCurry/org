#+hugo_base_dir: ../hugo
#+hugo_section: /d.rymcg.tech
#+hugo_weight: auto
#+hugo_paired_shortcodes: %notice badge button %children %index run stdout edit math mermaid openapi toc env
#+STARTUP: align

* Self-hosting Docker with d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :linkTitle Self-hosting Docker
:EXPORT_HUGO_WEIGHT: 200
:END:

This book describes how to get started with self-hosting your own
Docker server, using the tools provided by [[https://d.rymcg.tech][d.rymcg.tech]].

#+attr_shortcode: :icon code-branch :style primary :href https://github.com/EnigmaCurry/d.rymcg.tech#readme
#+begin_button
d.rymcg.tech
#+end_button

#+attr_shortcode: :icon comment-dots :style red :href https://matrix.to/#/#d.rymcg.tech:enigmacurry.com
#+begin_button
Chat with us on Matrix
#+end_button

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

* Introduction
:PROPERTIES:
:EXPORT_FILE_NAME: introduction
:EXPORT_HUGO_WEIGHT: 200
:END:


** What is self-hosting?

Self-hosting is the practice of hosting network applications (web /
internet / LAN / etc), using your own server hardware, or at least on
virtual machines that you fundamentally control (ie. you have root
access). As a preparedness skill, the self-hoster prioritizes the use
of open source software, as it becomes an inalienable toolset to
bootstrap infrastructure in the wilderness.

You can apply self-hosting a little bit, or a lot. On the one hand,
you could post all of your content on Facebook (obviously, this is
/not/ self-hosting), and on the other hand you could build all your
servers yourself, from parts, and run them in your basement, on your
own network, bootstrapping everything. For most people though,
self-hosting means to use a Raspberry Pi at home, or a cloud computing
provider that offers you a generic Linux VPS (virtual private server)
on the public internet, to configure in any way you wish, but still
letting the cloud provider handle the hardware and network side of
things for a monthly fee.

Demarcate your own level of abstraction. Test that your operations
work in a generic way, portable to any other provider at the same
level of abstraction. Try running it entirely at home, at least for
development purposes. Don't get locked into a single vendor. Use open
source software, or software you built yourself. This is self-hosting.

** What is Docker?

[[https://www.docker.com/][Docker]] is a software platform for running containers on Linux.
Containers let you install and run software in an isolated and generic
way. It solves the problems of [[https://en.wikipedia.org/wiki/Dependency_hell]["dependency hell"]] and [[https://donthitsave.com/comic/2016/07/15/it-works-on-my-computer]["But it works on
my computer!"]], for all Linux distributions. Containers are created
from images that include /all/ of their dependencies, including the
operating system to support it. The only thing a container does /not/
include, is the Linux kernel, which is shared from the host with all
the containers running on the same host. This abstraction makes it
work the same way on all computers, regardless of Linux distribution
(assuming an up to date kernel). Docker maintains persistent volumes
for each container, so that they may mount it into their own virtual
filesystem, and thus storing all of its important data into the
volume. You may upgrade, or even delete these containers, and as long
as you keep the volume(s), you can simply reprovision the same images
(even on new hardware), and the containers will load all of its same
data from before.

** What is a container?

Although it is possible to run desktop software inside of a Docker
container, 99% of the time a Docker container is created to run a
/service/, assumed to run on a server, assumed to be serving remote
clients. Generally, a container is designed only to run a single
service. For example: /A/ web server, /a/ chat server, /a/ DNS server,
/a/ python server you write, etc. Multiple instances of the same image
can run as separate containers, and they can even share volumes, if
you want (though generally not).

Containers are related to a different technology that you might
already be familar with: Virtual Machines. However, there are several
fundamental differences between containers and virtual machines, and
so it is useful to describe them here as a comparison:

| Feature           | Container                                                                                                                  | Virtual Machine                                                       |
|-------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------|
| Kernel            | Containers share a kernel with the host                                                                                    | VMs runs their own kernel                                             |
| Hardware          | Containers share hardware with the host, but with the addition of a permissions model to access it                         | VMs use hardware virtualization features                              |
| Memory            | Containers share memory with the host                                                                                      | VMs use a fixed size virtual hardware memory space                    |
| Disk              | Containers share storage system with the host (volumes live under =/var/lib/docker/= by default)                           | VMs use a fixed size (but expandable) virtual hard disk image         |
| Network           | Containers support Host level networking, or can do NAT                                                                    | NAT or bridge network, not host level                                 |
| Execution model   | Containers are just a regular Linux processes, run under a given user account                                              | VMs run their own kernel and init (systemd)                           |
| Init process      | Containers don't need an init process, Docker runs the containers process (CMD) directly                                   | VMs run their own kernel and init (systemd)                           |
| Process isolation | Containers run as as regular Linux processes, which have a capabilities system to limit privileges                         | VMs are like a separate machine, and a have a separate process space  |
| Root filesystem   | Containers inherit a root filesystem from their image, which contain all the application files, and the OS, minus a kernel | VMs are run from (linked) virtual disk images                         |
| Volumes           | Containers automatically mount volumes provided from Docker. Docker maintains the lifecycle of these volumes.              | VMs can have multiple virtual disks, or manually mount remote volumes |

Containerization uses features of the Linux kernel, (specifically,
namespaces and cgroups). For the purposes of this book, the term
"container" will always imply that it is running on a Linux host; it
is inseparable from the host kernel, and it can't work without it!
(You may be aware that you can install a product called "Docker
Desktop" on Windows or MacOS. This product installs a Linux virtual
machine on your host OS and runs Docker inside it, and then it
installs the docker client on the host OS, so it appears seamless.)

In a general context, there are other OS containers, like Windows
containers, however they are on the fringe, and will not be discussed
in this book. Containers imply Linux.

Docker is a good platform to pick for self-hosting containers, because
it's a mature open source project, and it works on virtually any Linux
computer or VPS. Docker is server focussed, and therefore ideal for
self-hosting. Docker is easy to get started with, even if you're a
beginner.

** What is Docker Compose?

Docker uses a client-server API pattern of control. You install the
Docker daemon on a server machine, and this machine is called the
Docker Host. Usually you interact with the API through the command
line =docker= tool. Docker provides primitive commands for running
single containers directly, with =docker run=. However, for larger
projects that need more than one container (eg. a webserver + a
database) and need to be able to talk to one another, =docker run= is
not the best tool to use.

=docker compose= is a command that operates your containers from a
project level abstraction. =docker compose= lets you define all the
containers and volumes that you need for a given project, in a
declarative way, in a =docker-compose.yaml= file.

With =docker compose= you can start/stop/delete all the project
containers together, as a single unit.

** What is d.rymcg.tech?

[[https://github.com/EnigmaCurry/d.rymcg.tech][d.rymcg.tech]] is a collection of docker compose projects for various
open source server applications, but it can also be used as a template
for your own services. It has an integrated frontend proxy ([[https://doc.traefik.io/traefik/][Traefik
Proxy)]], including sentry authorization middleware (mTLS, OAuth2, or
HTTP Basic auth) and IP address filtering. It is a framework for
packaging your own applications, and managing several container
instances at the same time, each with seprate configs in .env files.

d.rymcg.tech focuses on the config rules of the [[https://12factor.net/config][12-factor principle]].
All of the configuration for a container should be specified as
environment variables, which Docker loads from a standard =.env= file.
All of the data for a container should live inside a [[https://docs.docker.com/storage/volumes/][Docker Volume]]
(not a bind mount), and so the lifecycle of the volume is maintained
by Docker directly.

*d.rymcg.tech is designed to run on a workstation, not the docker
host*. The Docker server API is accessed remotely over SSH. Only your
personal workstation should be used to issue =docker= commands that
affect the server, they should never be run on the server itself. It's
important to keep the server as bare bones and hands off as possible.
The server's only job is to /run/ containers. The job of /configuring/
them is always performed from a remote workstation. Once the server is
setup, you won't normally need to even login to the server console
ever again. By controlling the server from your workstation, you can
manage the server in a clean fashion. You can even create a new server
from scratch, in no time. All of the important configuration stays on
your workstation (and are backed up in a git repository).

* Required Infrastructure
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: required-infrastructure
:END:

** Required Infrastructure
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: 201
:END:

A public internet Docker server needs several resources that you need
to procure :

 * A domain name registrar (eg. Gandi.net).
 * A domain name server (eg. DigitalOcean DNS).
 * A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet).
 * An internet network connection (eg. DigitalOcean network).

#+begin_index
index
#+end_index

** Register a domain name
:PROPERTIES:
:EXPORT_FILE_NAME: register-a-domain-nameom
:END:

To host a web service, one of the first things you will need is to
register your domain name. This will be the domain name used for all
of your service links, and it is what your users will need to type
into their browsers (or click on) to visit your pages.

Public domain names are a scarce resource. Because of their scarcity,
you must pay for your domain registrations, doing so in 1 year
increments. If domain names were free, all the good ones would be
taken by now, but because they cost money, there are still some good
enough ones left to be had. In return for your fee, you receive
exclusive use of your domain name for the period that you paid for.
You "own" the domain name, and its configuration, but you need to keep
paying a registrar to keep the record active (so its more like
renting). You can pre-pay for several years in advance, or for just
pay one year at a time. If you stop paying, and the records expire,
they will no longer resolve to your services, and you may lose control
of the domain, possibly forever.

*** Domain names for private servers

If you control your own DNS servers, you could use completely made up
domain names under the =.internal= domain, which are [[https://www.icann.org/en/public-comment/proceeding/proposed-top-level-domain-string-for-private-use-24-01-2024][RFC recoginized
for private usage]]. But for most public servers, where most clients
use different DNS servers, you will want to register a "real" domain
instead.

For private servers, (eg. running a private Docker server at home),
it is still recommended that you use a valid internet domain name,
using public DNS servers, because you will still need this in order to
create valid TLS certificates from [[https://letsencrypt.org/][Let's Encrypt]]. However, having
valid working TLS is not /required/ for development purposes (but
certainly nice to have!), so you may choose to make up your own fake
domain name instead, and forgo TLS, or you can setup [[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/step-ca#readme][Step-CA]] for
off-grid TLS. In either case, you will still need to setup DNS, and
this is explained in the next section.

*** Register an Internet domain name

You can buy (rent) a domain name from lots of places. For
documentation purposes, we will use [[https://www.gandi.net][Gandi.net]], but these instructions
will be similar regardless of the domain provider you pick.

#+attr_shortcode: :style info :title Setup on Gandi.net
#+begin_notice
 * Sign up for an account at [[https://www.gandi.net/][Gandi.net]]
 * Once signed in, from your dashboard, click =Register=.
 * Search for any domain name you like, eg. =your-name.com=.
 * Add your domain to the shopping cart, go to checkout, and complete
   your purchase.
 * Once you have purchased the domain, it should show up in your
   =Dashboard=, under the =Domain= tab.
 * Leave this browser tab open, you will return to it in the next
   chapter.
#+end_notice

** Setup public DNS service
:PROPERTIES:
:EXPORT_FILE_NAME: setup-dns
:END:

A DNS server maps your domain (and all subdomain) names to the various
IP addresses of your servers. DNS is required for your users to be
able to type (or click on) your domain name =prod.example.com= and
have it resolve to the IP address that is required to contact your
Docker server (=prod=). Beyond this, DNS is also a means of proving to
a third party that you are the owner (controller) of your own domain,
which is used as a part of the ACME challenge that Let's Encrypt (or
Step-CA) uses when signing your TLS certificates.

Now that you have registered a domain name, you need to tell your
registrar where your DNS server is. Usually you will use the DNS
server that your cloud provider gives you, but you may choose any DNS
provider you like. If you are creating a private server, you may still
want to choose a public DNS server, but using private IP addresses
ranges for the records. You can also setup a local/private DNS server,
but this will be discussed later.

For the purposes of ACME (automatic TLS certificate issuing/renewals),
your DNS server/provider will need to support [[https://go-acme.github.io/lego/dns/#dns-providers][one of the APIs
supported by the go-lego project]]. Find out what API tokens or other
settings your provider may need by by finding your provider in the
list on that page.

For documentation purposes, this chapter will assume you are using
Gandi.net as your domain registrar, and that you want to use
DigitalOcean.com as your domain's public DNS server (and [[https://go-acme.github.io/lego/dns/digitalocean/][digitalocean
is supported by go-lego]]), but these instructions will be similar
regardless of the supported provider you pick.

*** Configure your domain's DNS server on Gandi.net

#+attr_shortcode: :style info :title Setup on Gandi.net
#+begin_notice

 * Login to your [[https://admin.gandi.net][gandi.net]] dashboard.
 * Click the =Domain= tab.
 * Find your domain name in the list and click on it.
 * Click on the =Nameservers= tab.
 * Click on the edit button to create new =External nameservers=.
 * Delete all existing nameservers that may exist.
 * Add the following nameservers, specific to DigitalOcean:
   
   * =ns1.digitalocean.com=
   * =ns2.digitalocean.com=
   * =ns3.digitalocean.com=
#+end_notice

 
Wait a few minutes for the change to take effect, then you can verify
the setting from your workstation, using the =whois= command:

#+begin_run
whois example.com
#+end_run

#+begin_stdout
Domain Name: example.com
Registrar WHOIS Server: whois.gandi.net
Name Server: DNS1.EXAMPLE.NET
Name Server: DNS2.EXAMPLE.NET
Name Server: DNS3.EXAMPLE.NET
Name Server: DNS4.EXAMPLE.NET
#+end_stdout

The output shows a report for your domain registration, including the
list of the new nameservers.

*** Add your domain on DigitalOcean.com

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup, run:

#+begin_run
DOMAIN=example.com
doctl compute domain create ${DOMAIN}
#+end_run

To list all your domains, run:

#+begin_run
doctl compute domain list
#+end_run

#+end_notice

#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Signup for an account at [[https://m.do.co/c/069af06b869e][DigitalOcean]], if you haven't already.
 * Login to the [[https://cloud.digitalocean.com/][cloud console]].
 * Click on the =Networking= tab in the menu.
 * Click on the =Domains= tab.
 * Enter your domain name into the box and click =Add Domain=.
#+end_notice

DigitalOcean is now in charge of your DNS for your domain. You will
return to this screen later on, when creating individual subdomain
records for your services.

** Create a public server (VPS)
:PROPERTIES:
:EXPORT_FILE_NAME: public-docker-server
:END:

This section will guide you to create your own public Docker server,
using a DigitalOcean droplet as an example. In a similar fashion, you
can install Docker on any cloud provider, or dedicated host that you
prefer.

**** Choosing a VPS provider

One of the most basic units of cloud computing is the Virtual Private
Server (VPS). A VPS is a (Linux) virtual machine that is provisioned
by a cloud service, and you are given root access to fully administer
it, to install whatever you want on it. VPS generally come with a dedicated
IP address and have a public internet connection, although some VPS
only have NAT, but with dedicated port forwarding.

In this guide you will create a VPS with a DigitalOcean droplet.

You can install Docker on almost any Linux machine, but some are
better than others. DigitalOcean droplets (VPS) are a good choice for
experimenting, because they are billed hourly, and because the service
layer has an integrated firewall, external to the droplet operating
system. Having a firewall that is external (in front of) the VPS is
one of the most important features to look for in a hosting provider.

**** Setup your SSH key on DigitalOcean

If you have not yet setup an SSH key on your workstation, [[file:linux-workstation.org][read the
Linux Workstation book]] and do that first.

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup:

List all your SSH keys:
#+begin_run
doctl compute ssh-key list
#+end_run

Configure the SSH public key file you want to use:

#+begin_env
SSH_KEY=~/.ssh/id_ed25519.pub
#+end_env

Install the public key on DigitalOcean:

#+begin_run
(set -e
test -f ${SSH_KEY} || (echo "SSH key not found: ${SSH_KEY}" && exit 1)
SSH_TMP=$(mktemp) && chmod a+r ${SSH_TMP}
cat ${SSH_KEY} > ${SSH_TMP}
doctl compute ssh-key import ${USER}@${HOSTNAME} --public-key-file ${SSH_TMP}
rm -f ${SSH_TMP}
)
#+end_run

#+end_notice

#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Settings= in the menu.
 * Click on the =Security= tab.
 * Click on the =Add SSH Key= button.
 * Paste your public SSH key into the box. (copy your pub key from the
   output of ~ssh-add -L~.)
 * Enter a key name, I recommend this be the name of your workstation
   computer.
 * Finish adding the key, click =Add SSH Key=.
#+end_notice

**** Create a DigitalOcean firewall template

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup:

#+begin_run
doctl compute firewall list
#+end_run

#+begin_run
(set -e
FIREWALL_ID=$(doctl compute firewall create \
    --name "ssh-web-https-wireguard" \
    --inbound-rules "protocol:tcp,ports:22,address:0.0.0.0/0" \
    --no-header --format ID)
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --inbound-rules "protocol:tcp,ports:80,address:0.0.0.0/0"
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --inbound-rules "protocol:tcp,ports:443,address:0.0.0.0/0"
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --inbound-rules "protocol:tcp,ports:51820,address:0.0.0.0/0"
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --outbound-rules "protocol:tcp,ports:0,address:0.0.0.0/0"
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --outbound-rules "protocol:udp,ports:0,address:0.0.0.0/0"
doctl compute firewall add-rules "${FIREWALL_ID}" \
    --outbound-rules "protocol:icmp,ports:0,address:0.0.0.0/0"
echo ${FIREWALL_ID}
)
#+end_run
#+end_notice

#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Firewalls= tab.
 * Click =Create Firewall=.
 * Enter the name, eg. =ssh-web-https-wireguard=.
 * Enter the following rules:
   * SSH:
     * Type: =SSH=
     * Protocol: =TCP=
     * Port Range: =22=
     * Sources: All IPv4, All IPv6, or a specific static IP address if
       you want to be more secure.
   * HTTP:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =80=
     * Sources: All IPv4, All IPv6.
   * HTTPS:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =443=
     * Sources: All IPv4, All IPv6.
   * Wireguard VPN (optional):
     * Type: =Custom=
     * Protocol: =UDP=
     * Port Range: =51820=
     * Sources: All IPv4, All IPv6.
  * Click =Create Firewall=.
#+end_notice

**** Creating a DigitalOcean droplet for a Docker server

DigitalOcean provides a Docker image with which to create a droplet
(DigitalOcean's name for their own VPS product).

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup:

Set variables to configure the droplet:

#+begin_env
NAME=docker-dev
IMAGE=debian-12-x64
REGION=nyc1
SIZE=s-1vcpu-2gb
SSH_KEY=~/.ssh/id_ed25519.pub
SSH_FINGERPRINT=$(ssh-keygen -E md5 -l -f ${SSH_KEY} | grep -Po "MD5:\K[a-f0-9\:]+")
#+end_env

Create the droplet:

#+begin_run
DROPLET_ID=$(doctl compute droplet create \
    "${NAME}" \
    --image "${IMAGE}" \
    --size "${SIZE}" \
    --region "${REGION}" \
    --ssh-keys "${SSH_FINGERPRINT}" \
    --tag-names "doctl-${USERNAME}@${HOST}" \
    --wait --no-header --format ID)
echo ${DROPLET_ID}
#+end_run

#+end_notice

#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Droplets= in the menu.
 * Click =Create Droplet=.
 * Choose a Region (eg. New York), where the droplet will be created.
 * Underneath the heading =Choose an image=, choose =Debian= (select
   the latest version).
 * Choose a droplet size. 2GB RAM and 50GB disk recommended for medium
   size production installs. (It is tested working on as little as
   512MB ram, [[https://blog.rymcg.tech/blog/linux/zram/][if you enable zram]] and/or create a 1GB swapfile. Do not
   abuse swap space like this in production! However I think its fine
   for development use, but you may occasionally run into low memory
   issues if less than 1GB.)
 * Optional: Add a block storage device, in order to store your Docker
   volumes. (This is useful to store data separate from the droplet
   lifecycle, or to have a larger amount of storage than the droplet
   size gives you for the root filesystem. If your basic droplet size
   is already sufficient, and you perform regular backups, this might
   not be needed.)
 * Select your SSH key for the root user.
 * Set the hostname for the docker server. The name should be short
   and typeable, as it will become a part of the canononical service
   URLs. For this example, we choose =prod=.
 * Verify everything's correct, and then click =Create Dropet=.
#+end_notice

**** Apply the DigitalOcean droplet firewall

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup:

#+begin_run
FIREWALL_ID=$(doctl compute firewall list | grep ssh-web-https-wireguard | cut -d " " -f1)
doctl compute firewall add-droplets \
    "${FIREWALL_ID}" \
    --droplet-ids "${DROPLET_ID}"
#+end_run
#+end_notice

#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Find the firewall template you created, and click it.
 * Click on the firewall's =Droplets= tab.
 * Click =Add Droplets= and search for the droplet you created and select it.
 * Click =Add Droplet= to add the firewall to the droplet.
#+end_notice

**** Create wildcard DNS records for the droplet

For the purposes of documentation, assume you you own the domain
=example.com= and you have created the Docker server named =prod=. You
should replace =example.com= with your actual domain name, and =prod=
with your actual docker instance name/stage.

#+attr_shortcode: :style tip
#+begin_notice
If you have the [[/linux-workstation/app-users/digitalocean][doctl client]] setup:

List all domains:

#+begin_run
doctl compute domain list
#+end_run

#+begin_env
ROOT_DOMAIN=example.com
HOST=docker-dev
HOST_IP=$(doctl compute droplet get --no-header --format "Public IPv4" ${DROPLET_ID})
TTL=1800
#+end_env

List all records for =ROOT_DOMAIN=:

#+begin_run
doctl compute domain records list ${ROOT_DOMAIN}
#+end_run

Create Host record:

#+begin_run
doctl compute domain records create \
    "${ROOT_DOMAIN}" \
    --record-type A \
    --record-name "${HOST}" \
    --record-data ${HOST_IP} \
    --record-ttl ${TTL} \
    --record-tag "doctl-${USERNAME}@${HOST}"
#+end_run

Create Wildcard subdomain record:

#+begin_run
doctl compute domain records create \
    "${ROOT_DOMAIN}" \
    --record-type A \
    --record-name "*.${HOST}" \
    --record-data ${HOST_IP} \
    --record-ttl ${TTL} \
    --record-tag "doctl-${USERNAME}@${HOST}"
#+end_run

#+end_notice
#+attr_shortcode: :style info :title How to do this in the DigitalOcean cloud console
#+begin_notice
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Domains= tab.
 * Find the domain you created earlier, and click it.
 * Create an =A= record:
   * Hostname: enter the subdomain name without the domain part (eg.
     =prod=, the name of your docker server, without the
     =.example.com= suffix).
   * Will direct to: select the droplet you created from the list.
   * Click =Create Record=.
 * Create another =A= record, for the wildcard:
   * Hostname: enter the same name as before but prepend =*.= in front
     of it (eg. if the server is named =prod=, create a record for
     =*.prod=, without the =.example.com= suffix).
   * Will direct to: select the same droplet as before.
   * Click =Create Record=.
 * Optional: create additional records on the root domain. If you
   don't want the docker instance name in the subdomain you give to
   people (eg. =www.prod.example.com=), you could create additional
   (non-wildcard) records on the root domain now (eg.
   =www.example.com=, or even just =example.com=). However, it would
   be wasteful to put a wildcard record on the root domain
   (=*.example.com=) because then the domain could only be used with a
   single Docker instance, therefore all records on the root should be
   non-wildcard, and this means you must add them one by one.
#+end_notice

#+attr_shortcode: :style orange :title Test DNS
#+begin_notice
Test that your wildcard record actually works. Use the =dig= command
(For Debian/Ubuntu install the =dnsutils= package. For Arch Linux
install =bind-tools=. For Fedora install =bind-utils=.)

Pick some random subdomain off your domain:

#+begin_run
dig laksdflkweieri.prod.example.com
#+end_run

#+begin_stdout
;; ANSWER SECTION:
laksdflkweieri.prod.example.com.    3600    IN      A       153.114.12.78
#+end_stdout

Since you created the wildcard record for =*.prod.example.com= dig
should return your Docker server's IP address in the =ANSWER SECTION=
of the output. You can test all your other records the same way.

If you run into DNS caching problems, verify with the source DNS
server directly:

#+begin_run
dig @ns1.digitalocean.com laksdflkweieri.prod.example.com
#+end_run
#+end_notice

**** Congratulations

You have now finished installation of a remote host running Debian.

You must now configure your workstation to remotely control your
remote Docker context.

** Create a private server (libvirt VM)
:PROPERTIES:
:EXPORT_FILE_NAME: private-docker-server
:END:

*** Create Debian VM on libvirt

Follow the [[/linux-workstation][Linux Workstation]] book chapter on [[/linux-workstation/kvm-libvirt][KVM / libvirt]] to install
a Debian VM on your local workstation, and to create a local SSH
config to connect to it.

*** Setup DNS records for VM services

You will need a DNS server to create (wildcard) records for all VM
services. You can use the canonical DNS server on the internet, or you
can use a local DNS resolver to override the name on the LAN.

You can follow the [[/d.rymcg.tech/required-infrastructure/public-docker-server/#create-wildcard-dns-records-for-the-droplet][wildcard DNS record guide]] from the public VPS
chapter, except instead of pointing to a droplet IP address, it will
be your private VM (or workstation) IP address.

*** Use the Traefik ACME DNS-01 challenge

If you install [[/d.rymcg.tech/install-traefik-proxy/][Traefik Proxy]] on a non-public server, and you want to
enable ACME for Let's Encrypt TLS certificiates, make sure to
configure ACME for the DNS-01 challenge type, as it is the only
challenge type that will work for a server behind a restrictive LAN
firewall.

* Workstation
:PROPERTIES:
:EXPORT_HUGO_SECTION_FRAG: workstation
:END:

** Setup your workstation
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:

You should dedicate the use a physical or virtual Linux machine to be
used as your workstation. A single workstation can manage several
remote Docker contexts.

Follow the [[https://book.rymcg.tech/linux-workstation][Linux Workstation book]] for details on basic
workstation setup.

All the commands in this chapter assume you are using the standard
Bash shell.

#+attr_shortcode: :depth 999
#+begin_index
index
#+end_index

** Install Docker client tools
:PROPERTIES:
:EXPORT_FILE_NAME: install-docker-command-line-tools
:END:

You need to install Docker Engine (not Docker Desktop!) on your
workstation.

You will completely disable the Docker daemon on your workstation,
you're only installing Docker Engine for its client tools (eg. the
=docker= command).

*** Various ways to install Docker Engine
**** Try your system package manager

Some Linux distributions have decent packages for up-to-date Docker
versions. Some other distributions lag behind by several versions, or
may even introduce non-standard changes of their own. Your mileage may
vary with packages provided by your operating system.

If you're on Arch Linux, this is known to be a good configuration:

#+attr_shortcode: :title Run this on your Arch Linux workstations:
#+begin_run
sudo pacman -S docker docker-compose docker-buildx
#+end_run

**** Install from upstream Docker package repository

The Docker organization provides several up-to-date packages for
various Linux distributions:

 * [[https://docs.docker.com/engine/install/debian/][Debian]]
 * [[https://docs.docker.com/engine/install/ubuntu/][Ubuntu]]
 * [[https://docs.docker.com/engine/install/fedora/][Fedora]]

**** Use the generic Docker installer to install the latest version

If your Linux distribution doesn't provide a Docker package, or you've
decided its not good for your situation, you may be better off by running
the generic installer script from the upstream Docker organization:

#+begin_run
curl -fsSL https://get.docker.com -o install-docker.sh
sudo sh install-docker.sh
#+end_run

**** DON'T install Docker Desktop!

 1. Docker Desktop isn't open source. 
 2. Docker Desktop runs a VM to run the Docker daemon on localhost.
    (we don't want that, since we will use a remote Docker context
    instead.)
 3. Docker Desktop does not support host mode networking, so it
    wouldn't have worked with our Traefik config anyway. (This
    situation may have changed in more recent versions of Docker
    Desktop 4.29+).
 4. Docker Desktop provide the same =docker= client tools, so it will
    actually still work, if thats the package you prefer to install.
    Just be sure to disable the VM that it creates by default, you
    will /not/ need it! Keep your workstation clean, don't run
    containers / VMs on it!

    
*** Disable Docker daemon on your workstation

Your workstation is the /manager/ of /remote/ Docker hosts, so it
should not run the Docker daemon itself, but only the client.

Run the following commands to disable the Docker daemon:

#+begin_run
sudo systemctl disable --now docker
sudo systemctl mask docker
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
There is a vestigal Docker context named "default" left on your system
(see =docker context ls=), and this context was originally used to
manage the Docker daemon of the local host
(=unix:///var/run/docker.sock=). However, this will be of no use to
you now, since the Docker daemon is now completely disabled on the
workstation. Furthermore, the "default" context cannot be deleted, so
its best to just ignore it (the =d.rymcg.tech= CLI won't even show
it). In the next couple of steps, you'll create and activate new
*remote SSH contexts* that you'll use instead of the "default"
context.
#+end_notice

** Install d.rymcg.tech tools
:PROPERTIES:
:EXPORT_FILE_NAME: install-d-rymcg-tech
:END:

Install [[https://github.com/EnigmaCurry/d.rymcg.tech#readme][d.rymcg.tech]] and its dependencies on your workstation.

*** Install dependent packages

#+attr_shortcode: :title If you run Fedora workstations, run this as root
#+begin_run
dnf install bash gettext openssl git xdg-utils jq sshfs curl \
            inotify-tools httpd-tools make wireguard-tools
#+end_run

#+attr_shortcode: :title If you run Debian/Ubuntu workstations, run this as root
#+begin_run
apt-get install bash build-essential gettext git openssl \
        apache2-utils xdg-utils jq sshfs wireguard curl \
        inotify-tools
#+end_run

#+attr_shortcode: :title If you run Arch Linux workstations, run this as root
#+begin_run
pacman -S bash base-devel gettext git openssl apache xdg-utils \
          jq sshfs wireguard-tools curl inotify-tools
#+end_run

*** Clone d.rymcg.tech repository

#+begin_run
git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \
   ${HOME}/git/vendor/enigmacurry/d.rymcg.tech
#+end_run

#+attr_shortcode: :style warning
#+begin_notice
By convention, *you should not change the clone path*. It is
intentionally placed in a vendor neutral path location for all to use.
But if you're adamant to do so, it should still work, regardless of
where you put it. But watch out, as this may break documentation, and
for some external projects that assume =ROOT_DIR= is using the
conventional path. For compatability reasons, consider making a
symlink from =${HOME}/git/vendor/enigmacurry/d.rymcg.tech= pointing to
your actual clone path.
#+end_notice

*** Setup =d.rymcg.tech= command line tool

You must edit your workstation user's =~/.bashrc= file, which modifies
the Bash shell environment config:

#+attr_shortcode: :file ~/.bashrc
#+begin_edit
## Put this in ~/.bashrc to enable d.rymcg.tech command line tools:
export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user
eval "$(d.rymcg.tech completion bash)"
## Setup shorter alias for d.rymcg.tech as just 'd'
__d.rymcg.tech_cli_alias d
#+end_edit

#+attr_shortcode: :style info :title Important
#+begin_notice
Close and restart your shell (terminal) to load the new config in a new session.
#+end_notice

*** Test the =d.rymcg.tech= aliases

In your new shell session, you have the following aliases defined:

 * =d.rymcg.tech=
 * =d=

These are both the same, but for brevity, the rest of this
documentation will prefer the =d= alias, but they can be used
interchangeably.

#+begin_run
d
#+end_run

#+begin_stdout
Found ROOT_DIR=/var/home/ryan/git/vendor/enigmacurry/d.rymcg.tech

\## Main d.rymcg.tech sub-commands - Optional arguments are printed in brackets [OPTIONAL_ARG]
cd [SUBDIR]                   Enter a sub-shell and go to the ROOT_DIR directory
create [PROJECT] [TEMPLATE]   Create a new external project from a template
make [PROJECT] [ARGS ...]     Run a `make` command for the given d.rymcg.tech project name
context                       View or set the current Docker context
new-context                   Create a new Docker context
ssh [COMMAND ...]             Run command or shell on active docker context SSH host
completion                    Setup TAB completion in your shell

\## Documentation sub-commands:
help                          Show this help screen
list                          List available d.rymcg.tech projects
                              (not including external projects, unless you symlink them into ROOT_DIR)
readme                        Open the main d.rymcg.tech README.md in your browser
readme [PROJECT]              Open the README.md for the given project name
readme digitalocean           Open root documentation file: DIGITALOCEAN.md
readme security               Open root documentation file: SECURITY.md
readme aws                    Open root documentation file: AWS.md
readme license                Open root documentation file: LICENSE.txt
readme raspberry_pi           Open root documentation file: RASPBERRY_PI.md
readme makefile_ops           Open root documentation file: MAKEFILE_OPS.md
#+end_stdout

** Create SSH config and Docker Context
:PROPERTIES:
:EXPORT_FILE_NAME: ssh-config-and-docker-context
:END:

To remotely control your Docker host from your workstation, you need
two additional configs:

 * SSH Host config in =~/.ssh/config=.
 * Docker Context config via =docker context create ...=.

Both of these can be created automatically by running:
 
#+begin_run
d context new
#+end_run

This will prompt you if you really want to proceed:

#+begin_stdout
? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y
#+end_stdout

You can choose to create a new SSH config, or use an existing one:

#+begin_stdout
? You must specify the SSH config entry to use  
  I already have an SSH host entry in ~/.ssh/config that I want to use
> I want to make a new SSH host entry in ~/.ssh/config
[↑↓ to move, enter to select, type to filter, ESC to cancel]
#+end_stdout

Enter the short one word name for the SSH Host entry:

#+begin_stdout
? Enter the new SSH context name (short host name) : foo
#+end_stdout

Enter the fully qualified DNS name of the Docker host:

#+begin_stdout
? Enter the fully qualified SSH Host DNS name : foo.example.com
#+end_stdout

It will propose to create a new SSH config entry that looks like this:

#+begin_stdout
## Here is the new SSH config entry:
Host foo
     Hostname foo.example.com
     User root
     ControlMaster auto
     ControlPersist yes
     ControlPath /tmp/ssh-%u-%r@%h:%p
? Do you want to append this config to ~/.ssh/config? (y/N) y
#+end_stdout

It will ask you if you want to immediately switch the active Docker
context:

#+begin_stdout
? Do you want to switch to the new foo context now? (y/N) y
foo
Current context is now "foo"
#+end_stdout

*** List all Docker contexts and switch the active one

#+begin_run
d context
#+end_run

#+begin_stdout
? Select the Docker context to use  
  deb
> foo
  step-ca
[↑↓ to move, enter to select, type to filter, ESC to cancel]

Current context is now "foo"
#+end_stdout

** Install Docker on your remote host
:PROPERTIES:
:EXPORT_FILE_NAME: install-docker-on-remote-host
:END:

The base Debian image only has a few basic commands preinstalled. You
must now install the Docker packages and enable the service:

#+attr_shortcode: :title Choose the active Docker context
#+begin_run
d context
#+end_run

#+begin_run
d install-docker
#+end_run

#+attr_shortcode: :style tip
#+begin_notice
=d install-docker= will install Docker *on the remote VPS*, according
to your active docker context.
#+end_notice

*** Test that the context works from your workstation

#+begin_run
docker run hello-world
#+end_run

#+begin_run
docker ps
#+end_run

** Main config for d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: main-config-for-d.rymcg.tech
:EXPORT_HUGO_WEIGHT: 2010
:END:

*** Select your active Docker context

#+begin_run
d context
#+end_run

Each Docker context has a separate config file (=.env_{CONTEXT}=),
stored in the root d.rymcg.tech directory
(=~/git/vendor/enigmacurry/d.rymcg.tech=), so you must actively select
your current context before you can configure it.

*** Configure d.rymcg.tech for the current Docker context

#+begin_run
d make - config
#+end_run

This will create a config file for your current Docker context, and
name it =.env_{CONTEXT}= (eg. =.env_prod=). You must run this for each
new Docker context you create, so that each context has its own config
file.

The interactive config will ask you to enter the =ROOT_DOMAIN=
variable, which needs to be the root domain that you want to apply to
your Docker host.

#+begin_stdout
ROOT_DOMAIN: Enter the root domain for this context (eg. d.example.com)
: prod.example.com
#+end_stdout

The root domain serves as the example root domain for all application
default configs.

* Install Traefik Proxy
:PROPERTIES:
:EXPORT_FILE_NAME: install-traefik-proxy
:EXPORT_HUGO_WEIGHT: 2020
:END:

Traefik Proxy is a core service that acts as a gateway for all of the
other applications installed on your Docker host. Everything that is
served behind Traefik Proxy can take advantage of automatic TLS
certificates (ACME), perform user authentication (mTLS, OAuth2, HTTP
Basic), apply sentry authorization (user account filtering), and IP
address filtering middlewares. Based on all of this criteria, Traefik
Proxy ultimately decides whether to route incoming requests to the
backend service containers, or to block it and return an error.

** Configure Traefik Proxy

#+begin_run
d make traefik config
#+end_run

This creates a config for Traefik on your active Docker context. The
configuration is driven by a text wizard menu system.

#+begin_stdout
? Traefik config main menu:  
> Create system user on Docker host
  Configure entrypoints (including dashboard)
  Configure Certificate Authorities (CA)
  Configure ACME (Let's Encrypt or Step-CA)
  Configure TLS certificates and domains (make certs)
  Configure middleware (including auth)
v Configure error page template
[↑↓ to move, enter to select, type to filter, ESC to cancel]
#+end_stdout

Use your arrow keys to select a menu item and press the =Enter= key.
To cancel, press the =ESC= key.

Once complete, it will have created and configured your
=.env_{CONTEXT}= file for you.

*** Create system user on Docker host

This option will create a new username on the Docker host, called
=traefik=. This is necessary to reserve a unique UID for traefik to
run as on the system. Run this first before anything else.

*** Configure entrypoints

Traefik uses various entrypoints to allow requests on certain TCP
ports. By default, only port 80 and 443 are enabled. You can enable
extra entrypoints through this menu, which may be necessary for any
application that doesn't use the standard =websecure= entrypoint (port
443).

By default, the Traefik Dashboard is not enabled. To enable it, you
must select it via this menu option, and set a username / password. It
is only ever exposed to localhost, or through an SSH tunnel, never to
the public network, but it is still best to leave it turned off if you
don't need it.

*** Configure Certificate Authorities (CA)

If you're planning on running a public server, using TLS certificates
from Let's Encrypt, you can skip this option.

You only need to run this if you wish to modify the TLS certificate
trust store to accomodate a "self-signed" Step-CA authority.

*** Configure ACME (Let's Encrypt or Step-CA)

Choose this option to configure ACME, which makes requesting and
renewing TLS certificates an easy and automatic process.

#+begin_stdout
? Which ACME provider do you want to use?  
> Let's Encrypt (ACME)
  Step-CA (ACME)
  Disable ACME
  Cancel / Go back
#+end_stdout

For most installs, you should choose =Let's Encrypt (ACME)=. This is
the only option that will create valid TLS certificates for public
websites.

If you want to run private services, you may want to consider using
=Step-CA= instead, as it does not rely upon any external platform like
Let's Encrypt does.

Finally, if you want to setup TLS certificates manually, you can
choose =Disable ACME=.

**** Configure Let's Encrypt environment

#+begin_stdout
? Which LE environment do you want to use?  
> Production (recommended!)
  Staging (untrusted / testing)
#+end_stdout

#+attr_shortcode: :style tip
#+begin_notice
Always choose the =Production= environment, unless you really know
what you're doing. =Production= is the only environment that produces
valid (trusted) TLS certificates.
#+end_notice

**** Choose type of ACME challenge

#+begin_stdout
? Which type of ACME challenge should be used?  
> TLS-ALPN-01 (default for public servers, easy, but no wildcard certs)
  DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs)
#+end_stdout

#+attr_shortcode: :style tip
#+begin_notice
For your first install, choose =TLS-ALPN-01=, it is the easiest method
to use for public servers.

If you want to use wildcard DNS records, you must choose the more
advanced method =DNS-01=, and setup your DNS platform for programmatic
access with an API token.
#+end_notice


**** Configure ACME email address (optional)

You don't have to provide your email address, but if you do, Let's
Encrypt can email you about configuration issues, like certitficates
about to expire.

*** Configure TLS certificates and domains

d.rymcg.tech uses explicit certificate requests configured centrally,
on the traefik project:

#+begin_stdout
? Configure Traefik TLS certificates  
> Manage all certificates.
  Create a new certificate.
  Done / Go back
#+end_stdout

**** Manage all certificates

This will show you all the certificate requests that have been defined
and allow you to manage each one. It will be blank to start out with.

**** Create a new certificate

Use this to define all the certificates you need for all your
applications.

 * Set certificate main domain (CN)

Each certificate needs a main name (CN), which should be the main
domain name of the certificate.

: prod.example.com

#+attr_shortcode: :style info
#+begin_notice
Each certificate may also contain several other domain names, known as
SANs (Subject Alternative Names). You can use this to list as many
additional domain names that you want to be listed on the same
certificate.
#+end_notice

*** Configure middleware
*** Configure error page template
*** Configure wireguard VPN
*** Install Traefik

To install Traefik (on your active Docker context), you can simply
choose the =Reinstall Traefik= option in the menu, or you can run that
step all by itself from the command line at any time:

#+begin_run
d make traefik install
#+end_run

You should always reinstall Traefik after changing any configuration
setting.

* Whoami
:PROPERTIES:
:EXPORT_FILE_NAME: whoami
:EXPORT_HUGO_WEIGHT: 2030
:END:

[[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/whoami#readme][Whoami]] is a very simple application, but you can learn a lot from it.
After you install Traefik, whoami should be the very first application
that you install. It can help you test whether or not your Traefik
installation is functioning properly.

*You should study the configuration of whoami*, as it is used as a
template for all the other apps provided by d.rymcg.tech. Because of
its simplicity, it reduces the complexity of its core components.
Whoami can be a good base template for creating your own d.rymcg.tech
enabled applications.

#+attr_shortcode:
#+begin_toc
table of contents
#+end_toc

** What is Whoami?

Whoami is a web application that simply outputs the request headers
that it receives itself (reflecting them back to the requesting
client):

#+begin_run
## Use your own whoami URL here once you install it:
curl https://whoami.example.com
#+end_run

#+begin_stdout
Name: default
Hostname: 38704012c4b3
IP: 127.0.0.1
IP: ::1
IP: 172.19.0.2
RemoteAddr: 172.19.0.1:34610
GET / HTTP/1.1
Host: whoami.example.com
User-Agent: curl/7.88.1
Accept: */*
Accept-Encoding: gzip
X-Forwarded-For: 10.93.23.114
X-Forwarded-Host: whoami.example.com
X-Forwarded-Port: 443
X-Forwarded-Proto: https
X-Forwarded-Server: docker
X-Real-Ip: 10.93.23.114
#+end_stdout

This output is useful for end-to-end testing, to verify that the
application is capable of serving requests, and that all of the
configuration is correct.

** Quickstart

Create a new config:

#+begin_run
d make whoami config
#+end_run

The first question the config asks for is =WHOAMI_TRAEFIK_HOST= which
should be the fully qualified domain name that the whoami app will use
for its URL:

#+begin_stdout
WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com)
​: whoami.prod.rymcg.tech
#+end_stdout

Optional authentication can be configured:

#+begin_stdout
? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)?  
> No
  Yes, with HTTP Basic Authentication
  Yes, with Oauth2
  Yes, with Mutual TLS (mTLS)
#+end_stdout

For now, choose =No=, to disable authentication. We'll get back to
that later.

Install whoami:

#+begin_run
d make whoami install
#+end_run

Open whoami:

#+begin_run
d make whoami open
#+end_run

Or just open your web browser to the URL =https://{WHOAMI_TRAEFIK_HOST}=
 
** Features

[[https://github.com/traefik/whoami?tab=readme-ov-file#whoami][See the upstream whoami documentation and feature list here.]]

In addition to the features that whoami provides, there are several
features that d.rymcg.tech provides through its own configuration and
Traefik middlewares:

 * Running multiple separately-configured instances (Instantiation).
 * Traefik sentry authorization per instance (mTLS, OAuth2, HTTP Basic auth).
 * Source IP address filtering (blocking) per instance.

** Configuration
 
*** Default config file (.env-dist)

The default configuration file is named =.env-dist=. This config file is
used as a template, which is copied whenever you configure a new
instance of the application.

#+attr_shortcode: :style tip
#+begin_notice
The =.env-dist= file should not be edited normally. It should always
contain the /default/ configuration. Each instance will make its own
copy of this, and it is inside the copy that you have the opportunity
to change those defaults per instance (=.env_{CONTEXT}_{INSTANCE}=).
#+end_notice

Every application instance has a unique config file, and the =config=
target automatically creates one if necessary.

*** Configure whoami

#+begin_run
d make whoami config
#+end_run

#+attr_shortcode: :style info
#+begin_notice
The =config= target configures the specific .env file of the instance:
=.env_{CONTEXT}_{INSTANCE}=. Since we didn't specify an instance name,
the instance name is =default=. If your Docker context is named
=prod=, then the full instance config file is named
=.env_prod_default=.
#+end_notice

#+attr_shortcode: :style warning
#+begin_notice
You should not share the =.env_{CONTEXT}_{INSTANCE}= files. They
should not be commited to the git repository. They are listed in the
=.gitignore= file, so you should only have one copy of these files,
living on your workstation. If these configs are important to you, you
should make an encrypted backup.

Run =d make - backup-env= to make a GPG encrypted backup file of all
your .env files.

Theres nothing particularly important inside the whoami .env files,
but this is a general warning, as many apps will store their sensitive
API keys or passwords in this file.
#+end_notice

**** Configure multiple whoami instances

#+attr_shortcode: :style tip
#+begin_notice
Most times you only need one instance of a given app, so you don't
need to set an instance name, and the name =default= will be used
automatically.
#+end_notice

If you want to configure multiple instances, run =d make whoami
instance= for each one. You can configure unique names for each
instance, and they will each have their own .env file:
=.env_{CONTEXT}_{INSTANCE}=.

=d make whoami instance= starts a sub-shell so that all commands will
run on that instance now by default. Press =Ctrl-D= to exit the
sub-shell, and it will go back to the original default instance (named
=default=).

*** WHOAMI_TRAEFIK_HOST
The first question the config asks for is =WHOAMI_TRAEFIK_HOST= which
is the fully qualified domain name that the whoami app should use for
its URL:

#+begin_stdout
WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com)
​: whoami.prod.rymcg.tech
#+end_stdout
﻿
The default name uses the =ROOT_DOMAIN= variable you set as part of the
main d.rymcg.tech config, which is also named after our current Docker
context (=prod=). Realistically, the =WHOAMI_TRAEFIK_HOST= may be set
to any valid domain name, you just need to setup the DNS for it (to
point to the IP address of the Docker host).

*** Sentry authorization

Another question it asks you is about sentry authorization:

#+begin_stdout
? Do you want to enable sentry authorization in front of this app (effectively making the entire site private)?  
> No
  Yes, with HTTP Basic Authentication
  Yes, with Oauth2
  Yes, with Mutual TLS (mTLS)
#+end_stdout

Sentry authorization is a collection of middlewares that are deployed
in front of your application to allow specific users entry into your
app, while denying others, based on a variety of authentication
methods. *It does not implement any fine-grained permissions in the
application itself*, but it does filter who can come in the front
door. It provides the application with the verified username of the
authenticated clients via the =X-Forwarded-User= HTTP header. Any
application may implement additional fine-grained permissions based on
this trusted header field.

To configure sentry authorization, you can choose any of these
choices:

 * If you select =No=, then sentry authorization will be turned off.
   The =X-Forwarded-User= header field will always be blank. Any
   client will be able to access the application without
   authenticating (however the application may still perform
   authentication by itself).
 * If you select =Yes, with HTTP Basic Authentication=, the
   application will require all clients to enter a username/password
   into a dialog presented by the web browser. Clients who enter an
   incorrect username or password will not be able to view the page.
   The =X-Forwarded-User= header field will be set to the username of
   the authenticated user.
 * If you select =Yes, with OAuth2=, the application will require all
   clients to authenticate with another OAuth2 compatible application,
   which may be a self-hosted [[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/forgejo#readme][Forgejo]] instance, or it can be an
   external service like GitHub. Access is granted only to those users
   who are listed in the corresponding Traefik authorization group
   that the application is configured for. The =X-Forwarded-User=
   header field will be set to the email address of the user's
   verified account.
 * If you select =Yes, with mTLS=, the application will require all
   clients to authenticate with a client mTLS certificate. Access is
   granted only to those certificate names that are listed in the
   application's config. The =X-Forwarded-User= header field will be
   set to the Common Name (CN) of the client certificate with the
   prefix =CN== (eg. =CN=client1.example.com=)

*** Edit the config file by hand

Once the config script has finished, the config file may be inspected
to verify valid settings:

#+begin_run
d make whoami config-edit
#+end_run

This will automatically open the whoami config file for the current
context/instance in your default text editor (eg. set
=EDITOR=/usr/bin/emacs= in your =~/.bashrc= file), and you may make
any changes, and save the file again.

You can also open the file manually, the path is
=~/git/vendor/enigmacurry/d.rymcg.tech/whoami/.env_{CONTEXT}_{INSTANCE}=.

*** Configuration variables

**** WHOAMI_TRAEFIK_HOST

This sets the fully qualified domain name of the application.

**** WHOAMI_INSTANCE

This sets the name of the whoami instance. If left blank, the default
name is =default=.

**** WHOAMI_IP_SOURCERANGE

This sets the acceptable IP addresses ranges for incoming requests. It
is a comma separated list of [[https://en.wikipedia.org/wiki/CIDR#CIDR_notation][CIDR formatted netmasks]].

Here are some example settings:
 
 * =WHOAMI_IP_SOURCERANGE=0.0.0.0/0= - allow any access from any IP address.
 * =WHOAMI_IP_SOURCERANGE=0.0.0.0/32= - allow NO access from any IP address.
 * =WHOAMI_IP_SOURCERANGE=192.168.1.0/24,10.3.4.0/24= - allow access
   ONLY from two different /24 networks (512 addresses in two ranges, comma separated):
   * =192.168.1.0= to =192.168.1.255=
   * =10.3.4.0= to =10.3.4.255=

**** WHOAMI_HTTP_AUTH



If this is blank, sentry authorization with HTTP Basic Authentication
will be disabled (default). Otherwise, this should set the [[https://doc.traefik.io/traefik/middlewares/http/basicauth/][Traefik
BasicAuth]] authorized users list. Don't attempt to edit this field by
hand, as the syntax is very complex. Always use the =d make whoami
config= tool to set it correctly.

**** WHOAMI_OAUTH2

If this is blank, or set to =false=, then sentry authorization with
OAuth2 will be disabled (default). If set to =true= then it will be
enabled.

You must separately install [[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/traefik-forward-auth#readme][Traefik Forward Auth]]

**** WHOAMI_OAUTH2_AUTHORIZED_GROUP

If =WHOAMI_OAUTH2=true=, then =WHOAMI_OAUTH2_AUTHORIZED_GROUP= must be
set, which is the name of the authorization group that should be
allowed access.

#+attr_shortcode: :style tip
#+begin_notice
Authorization groups are set separately in the Traefik config:

#+begin_run
d make traefik config
#+end_run

 * Choose the menu =Configure middleware (including auth)=.

 * Choose the sub-menu =OAuth2 sentry authorization (make sentry)=.

 * Create a new authorization group lists and add authorized email
addresses.

 * Reinstall Traefik

 * In the whoami config, set =WHOAMI_OAUTH2_AUTHORIZED_GROUP= to the
name of the group you created.
#+end_notice

**** WHOAMI_MTLS_AUTH

If this is blank, or set to =false=, then sentry authorization with
mTLS will be disabled (default). If set to =true= then it will be
enabled.

**** WHOAMI_MTLS_AUTHORIZED_CERTS

If =WHOAMI_MTLS_AUTH=true=, then =WHOAMI_MTLS_AUTHORIZED_CERTS= must
be set, which is the list of the certificates names (CN) that should
be allowed.

Wildcards are allowed, so a good setting could be like
=*.clients.example.com= to allow any client subdomain of
=clients.example.com=.

** Install whoami

Once the configuration has been verified, you can install the
application:

#+begin_run
d make whoami install
#+end_run

*** Open whoami in your web browser

Once installed, the application should be ready to view in your web browser:

#+begin_run
d make whoami open
#+end_run

This will automatically open your default web browser to the URL of
the installed whoami application. If you want to do so manually, just
go to the same URL as you configured for =WHOAMI_TRAEFIK_HOST=.

*** View the logs

It may be necessary to inspect the applicaiton logs, which you can do
so as follows:

#+begin_run
d make whoami logs
#+end_run
