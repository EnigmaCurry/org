#+hugo_base_dir: ../hugo
#+hugo_section: /d.rymcg.tech
#+hugo_weight: auto
#+hugo_paired_shortcodes: %notice badge button %children %index
#+STARTUP: align

* Self-hosting Docker with d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :linkTitle Self-hosting Docker
:EXPORT_HUGO_WEIGHT: 200
:END:

This book describes how to get started with self-hosting your own
Docker server, using the tools provided by [[https://d.rymcg.tech][d.rymcg.tech]].

#+attr_shortcode: :icon code-branch :style primary :href https://github.com/EnigmaCurry/d.rymcg.tech#readme
#+begin_button
d.rymcg.tech
#+end_button

#+begin_index
index
#+end_index

* Introduction
:PROPERTIES:
:EXPORT_FILE_NAME: introduction
:END:


** What is self-hosting?

Self-hosting is the practice of hosting network applications (web /
internet / LAN / etc), using your own server hardware, or at least on
virtual machines that you fundamentally control (ie. you have root
access). As a preparedness skill, the self-hoster prioritizes the use
of open source software, as it becomes an inalienable toolset to
bootstrap infrastructure in the wilderness.

You can apply self-hosting a little bit, or a lot. On the one hand,
you could post all of your content on Facebook (obviously, this is
/not/ self-hosting), and on the other hand you could build all your
servers yourself, from parts, and run them in your basement, on your
own network, bootstrapping everything. For most people though,
self-hosting means to use a Raspberry Pi at home, or a cloud computing
provider that offers you a generic Linux VPS (virtual private server)
on the public internet, to configure in any way you wish, but still
letting the cloud provider handle the hardware and network side of
things for a monthly fee.

Demarcate your own level of abstraction. Test that your operations
work in a generic way, portable to any other provider at the same
level of abstraction. Try running it entirely at home, at least for
development purposes. Don't get locked into a single vendor. Use open
source software, or software you built yourself. This is self-hosting.

** What is Docker?

[[https://www.docker.com/][Docker]] is a software platform for running containers on Linux.
Containers let you install and run software in an isolated and generic
way. It solves the problems of [[https://en.wikipedia.org/wiki/Dependency_hell]["dependency hell"]] and [[https://donthitsave.com/comic/2016/07/15/it-works-on-my-computer]["But it works on
my computer!"]], for all Linux distributions. Containers are created
from images that include /all/ of their dependencies, including the
operating system to support it. The only thing a container does /not/
include, is the Linux kernel, which is shared from the host with all
the containers running on the same host. This abstraction makes it
work the same way on all computers, regardless of Linux distribution
(assuming an up to date kernel). Docker maintains persistent volumes
for each container, so that they may mount it into their own virtual
filesystem, and thus storing all of its important data into the
volume. You may upgrade, or even delete these containers, and as long
as you keep the volume(s), you can simply reprovision the same images
(even on new hardware), and the containers will load all of its same
data from before.

** What is a container?

Although it is possible to run desktop software inside of a Docker
container, 99% of the time a Docker container is created to run a
/service/, assumed to run on a server, assumed to be serving remote
clients. Generally, a container is designed only to run a single
service. For example: /A/ web server, /a/ chat server, /a/ DNS server,
/a/ python server you write, etc. Multiple instances of the same image
can run as separate containers, and they can even share volumes, if
you want (though generally not).

Containers are related to a different technology that you might
already be familar with: Virtual Machines. However, there are several
fundamental differences between containers and virtual machines, and
so it is useful to describe them here as a comparison:

| Feature           | Container                                                                                                                  | Virtual Machine                                                       |
|-------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------|
| Kernel            | Containers share a kernel with the host                                                                                    | VMs runs their own kernel                                             |
| Hardware          | Containers share hardware with the host, but with the addition of a permissions model to access it                         | VMs use hardware virtualization features                              |
| Memory            | Containers share memory with the host                                                                                      | VMs use a fixed size virtual hardware memory space                    |
| Disk              | Containers share storage system with the host (volumes live under =/var/lib/docker/= by default)                           | VMs use a fixed size (but expandable) virtual hard disk image         |
| Network           | Containers support Host level networking, or can do NAT                                                                    | NAT or bridge network, not host level                                 |
| Execution model   | Containers are just a regular Linux processes, run under a given user account                                              | VMs run their own kernel and init (systemd)                           |
| Init process      | Containers don't need an init process, Docker runs the containers process (CMD) directly                                   | VMs run their own kernel and init (systemd)                           |
| Process isolation | Containers run as as regular Linux processes, which have a capabilities system to limit privileges                         | VMs are like a separate machine, and a have a separate process space  |
| Root filesystem   | Containers inherit a root filesystem from their image, which contain all the application files, and the OS, minus a kernel | VMs are run from (linked) virtual disk images                         |
| Volumes           | Containers automatically mount volumes provided from Docker. Docker maintains the lifecycle of these volumes.              | VMs can have multiple virtual disks, or manually mount remote volumes |

Containerization uses features of the Linux kernel, (specifically,
namespaces and cgroups). For the purposes of this book, the term
"container" will always imply that it is running on a Linux host; it
is inseparable from the host kernel, and it can't work without it!
(You may be aware that you can install a product called "Docker
Desktop" on Windows or MacOS. This product installs a Linux virtual
machine on your host OS and runs Docker inside it, and then it
installs the docker client on the host OS, so it appears seamless.)

In a general context, there are other OS containers, like Windows
containers, however they are on the fringe, and will not be discussed
in this book. Containers imply Linux.

Docker is a good platform to pick for self-hosting containers, because
it's a mature open source project, and it works on virtually any Linux
computer or VPS. Docker is server focussed, and therefore ideal for
self-hosting. Docker is easy to get started with, even if you're a
beginner.

** What is Docker Compose?

Docker uses a client-server API pattern of control. You install the
Docker daemon on a server machine, and this machine is called the
Docker Host. Usually you interact with the API through the command
line =docker= tool. Docker provides primitive commands for running
single containers directly, with =docker run=. However, for larger
projects that need more than one container (eg. a webserver + a
database) and need to be able to talk to one another, =docker run= is
not the best tool to use.

=docker compose= is a command that operates your containers from a
project level abstraction. =docker compose= lets you define all the
containers and volumes that you need for a given project, in a
declarative way, in a =docker-compose.yaml= file.

With =docker compose= you can start/stop/delete all the project
containers together, as a single unit.

** What is d.rymcg.tech?

[[https://github.com/EnigmaCurry/d.rymcg.tech][d.rymcg.tech]] is a collection of docker compose projects for various
open source server applications, but it can also be used as a template
for your own services. It has an integrated frontend proxy ([[https://doc.traefik.io/traefik/][Traefik
Proxy)]], including sentry authorization middleware (mTLS, OAuth2, or
HTTP Basic auth) and IP address filtering. It is a framework for
packaging your own applications, and managing several container
instances at the same time, each with seprate configs in .env files.

d.rymcg.tech focuses on the config rules of the [[https://12factor.net/config][12-factor principle]].
All of the configuration for a container should be specified as
environment variables, which Docker loads from a standard =.env= file.
All of the data for a container should live inside a [[https://docs.docker.com/storage/volumes/][Docker Volume]]
(not a bind mount), and so the lifecycle of the volume is maintained
by Docker directly.

*d.rymcg.tech is designed to run on a workstation, not the docker
host*. The Docker server API is accessed remotely over SSH. Only your
personal workstation should be used to issue =docker= commands that
affect the server, they should never be run on the server itself. It's
important to keep the server as bare bones and hands off as possible.
The server's only job is to /run/ containers. The job of /configuring/
them is always performed from a remote workstation. Once the server is
setup, you won't normally need to even login to the server console
ever again. By controlling the server from your workstation, you can
manage the server in a clean fashion. You can even create a new server
from scratch, in no time. All of the important configuration stays on
your workstation (and are backed up in a git repository).


* Register a domain name
:PROPERTIES:
:EXPORT_FILE_NAME: register-a-domain-name
:END:

To host a web service, one of the first things you will need is to
register your domain name. This will be the domain name used for all
of your service links, and it is what your users will need to type
into their browsers (or click on) to visit your pages.

Domain names are a scarce resource. Because of their scarcity, you
must pay for your domain registrations, doing so in 1 year increments.
If domain names were free, all the good ones would be taken by now, but
because they cost money, there are still some good enough ones left to
be had. In return for your fee, you receive exclusive use of your
domain name for the period that you paid for. You can pre-pay for
several years in advance, or for just one year at a time. You must
remember to renew your domains for every year, lest they expire and no
longer resolve to your services, and you lose control of the domain,
possibly forever.

** Domain names for private servers

If your Docker server won't be a public server, (eg. running a private
Docker server at home), it is still recommended that you use a valid
internet domain name, with public DNS servers, because you will still
need this in order to create valid TLS certificates from [[https://letsencrypt.org/][Let's
Encrypt]]. However, having valid working TLS is not /required/ for
development purposes (but certainly nice to have!), so you may choose
to make up your own fake domain name instead, and forgo TLS, or you
can setup [[https://github.com/EnigmaCurry/d.rymcg.tech/tree/master/step-ca#readme][Step-CA]] for off-grid TLS. In either case, you will still
need to setup DNS, and this is explained in the next section.

** Register an Internet domain name

You can buy (rent) a domain name from lots of places. For
documentation purposes, we will use [[https://www.gandi.net][Gandi.net]], but these instructions
will be similar regardless of the domain provider you pick.

 * Sign up for an account at [[https://www.gandi.net/][Gandi.net]]
 * Once signed in, from your dashboard, click =Register=.
 * Search for any domain name you like, eg. =your-name.com=.
 * Add your domain to the shopping cart, go to checkout, and complete
   your purchase.
 * Once you have purchased the domain, it should show up in your
   =Dashboard=, under the =Domain= tab.
 * Leave this browser tab open, you will return to it in the next
   chapter.

* Setup public DNS
:PROPERTIES:
:EXPORT_FILE_NAME: setup-dns
:END:

A DNS server maps your domain (and subdomain) names to the various IP
addresses of your servers. DNS is required for your users to be able
to type your domain name =prod.example.com= and have it resolve to the
IP address that is required to contact your Docker server.

Now that you have registered a domain name, you need to tell your
registrar where your DNS server is. Usually you will use the DNS
server that your cloud provider gives you, but you may choose any DNS
provider you like. If you are creating a private server, you may still
want to choose a public DNS server, but using private IP addresses
ranges for the records. You can also setup a local/private DNS server,
but this will be discussed later.

For the purposes of ACME (automatic TLS certificate issuing/renewals),
your DNS server/provider will need to support [[https://go-acme.github.io/lego/dns/#dns-providers][one of the APIs
supported by the go-lego project]]. Find out what API tokens or other
settings your provider may need by by finding your provider in the
list on that page.

For documentation purposes, this chapter will assume you are using
Gandi.net as your domain registrar, and that you want to use
DigitalOcean.com as your domain's public DNS server (and [[https://go-acme.github.io/lego/dns/digitalocean/][digitalocean
is supported by go-lego]]), but these instructions will be similar
regardless of the supported provider you pick.

** Configure your domain's DNS server on Gandi.net

 * Login to your [[https://admin.gandi.net][gandi.net]] dashboard.
 * Click the =Domain= tab.
 * Find your domain name in the list and click on it.
 * Click on the =Nameservers= tab.
 * Click on the edit button to create new =External nameservers=.
 * Delete all existing nameservers that may exist.
 * Add the following nameservers, specific to DigitalOcean:
   
   * =ns1.digitalocean.com=
   * =ns2.digitalocean.com=
   * =ns3.digitalocean.com=

Once changed, you can verify the setting from your workstation, using
the =whois= command:

: whois your-domain.com

The output shows a report for your domain registration, including the
list of the new nameservers.

** Setup public DNS on DigitalOcean.com

 * Signup for an account at [[https://m.do.co/c/069af06b869e][DigitalOcean]], if you haven't already.
 * Login to the [[https://cloud.digitalocean.com/][cloud console]].
 * Click on the =Networking= tab in the menu.
 * Click on the =Domains= tab.
 * Enter your domain name into the box and click =Add Domain=.

DigitalOcean is now in charge of your DNS for your domain. You will
return to this screen later on, when creating individual subdomain
records for your services.

* Create a public Docker server 
:PROPERTIES:
:EXPORT_FILE_NAME: public-docker-server
:END:

This section will guide you to create your own public Docker server,
using a DigitalOcean droplet as an example. In a similar fashion, you
can install Docker on any cloud provider, or dedicated host that you
prefer.

** Choosing a VPS provider

One of the most basic units of cloud computing is the Virtual Private
Server (VPS). A VPS is a (Linux) virtual machine that is provisioned
by a cloud service, and you are given root access to fully administer
it, to install whatever you want on it. VPS generally come with a dedicated
IP address and have a public internet connection, although some VPS
only have NAT, but with dedicated port forwarding.

In this guide you will create a VPS with a DigitalOcean droplet.

You can install Docker on almost any Linux machine, but some are
better than others. DigitalOcean droplets (VPS) are a good choice for
experimenting, because they are billed hourly, and because the service
layer has an integrated firewall, external to the droplet operating
system. Having a firewall that is external (in front of) the VPS is
one of the most important features to look for in a hosting provider.

** Create a DigitalOcean account and setup your SSH key

If you have not yet setup an SSH key on your workstation, [[file:linux-workstation.org][read the
Linux Workstation book]] and do that first.

 * Signup for an account at [[https://m.do.co/c/069af06b869e][DigitalOcean]].
 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Settings= in the menu.
 * Click on the =Security= tab.
 * Click on the =Add SSH Key= button.
 * Paste your public SSH key into the box. (copy your pub key from the
   output of ~ssh-add -L~.)
 * Enter a key name, I recommend this be the name of your workstation
   computer.
 * Finish adding the key, click =Add SSH Key=.

** Create a DigitalOcean firewall template

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Firewalls= tab.
 * Click =Create Firewall=.
 * Enter the name, eg. =basic-docker-public-web=.
 * Enter the following rules:
   * SSH:
     * Type: =SSH=
     * Protocol: =TCP=
     * Port Range: =22=
     * Sources: All IPv4, All IPv6, or a specific static IP address if
       you want to be more secure.
   * HTTP:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =80=
     * Sources: All IPv4, All IPv6.
   * HTTPS:
     * Type: =HTTP=
     * Protocol: =TCP=
     * Port Range: =443=
     * Sources: All IPv4, All IPv6.
   * Wireguard VPN (optional):
     * Type: =Custom=
     * Protocol: =UDP=
     * Port Range: =51820=
     * Sources: All IPv4, All IPv6.
  * Click =Create Firewall=.
 
** Creating a DigitalOcean droplet for a Docker server

DigitalOcean provides a Docker image with which to create a droplet
(DigitalOcean's name for their own VPS product).

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Droplets= in the menu.
 * Click =Create Droplet=.
 * Choose a Region (eg. New York), where the droplet will be created.
 * Underneath the heading =Choose an image=, choose =Debian= (select
   the latest version).
 * Choose a droplet size. 2GB RAM and 50GB disk recommended for medium
   size production installs. (It is tested working on as little as
   512MB ram, [[https://blog.rymcg.tech/blog/linux/zram/][if you enable zram]] and/or create a 1GB swapfile. Do not
   abuse swap space like this in production! However I think its fine
   for development use, but you may occasionally run into low memory
   issues if less than 1GB.)
 * Optional: Add a block storage device, in order to store your Docker
   volumes. (This is useful to store data separate from the droplet
   lifecycle, or to have a larger amount of storage than the droplet
   size gives you for the root filesystem. If your basic droplet size
   is already sufficient, and you perform regular backups, this might
   not be needed.)
 * Select your SSH key for the root user.
 * Set the hostname for the docker server. The name should be short
   and typeable, as it will become a part of the canononical service
   URLs. For this example, we choose =prod=.
 * Verify everything's correct, and then click =Create Dropet=.

** Apply the DigitalOcean droplet firewall

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Find the firewall template you created, and click it.
 * Click on the firewall's =Droplets= tab.
 * Click =Add Droplets= and search for the droplet you created and select it.
 * Click =Add Droplet= to add the firewall to the droplet.

** Create wildcard DNS records for the droplet

For the purposes of documentation, assume you you own the domain
=example.com= and you have created the Docker server named =prod=. You
should replace =example.com= with your actual domain name, and =prod=
with your actual docker instance name/stage.

 * Login to the [[https://cloud.digitalocean.com/][DigitalOcean cloud console]].
 * Click =Networking= in the menu.
 * Click the =Domains= tab.
 * Find the domain you created earlier, and click it.
 * Create an =A= record:
   * Hostname: enter the subdomain name without the domain part (eg.
     =prod=, the name of your docker server, without the
     =.example.com= suffix).
   * Will direct to: select the droplet you created from the list.
   * Click =Create Record=.
 * Create another =A= record, for the wildcard:
   * Hostname: enter the same name as before but prepend =*.= in front
     of it (eg. if the server is named =prod=, create a record for
     =*.prod=, without the =.example.com= suffix).
   * Will direct to: select the same droplet as before.
   * Click =Create Record=.
 * Optional: create additional records on the root domain. If you
   don't want the docker instance name in the subdomain you give to
   people (eg. =www.prod.example.com=), you could create additional
   (non-wildcard) records on the root domain now (eg.
   =www.example.com=, or even just =example.com=). However, it would
   be wasteful to put a wildcard record on the root domain
   (=*.example.com=) because then the domain could only be used with a
   single Docker instance, therefore all records on the root should be
   non-wildcard, and this means you must add them one by one.

Test that your wildcard record actually works. Use the =dig= command
(For Debian/Ubuntu install the =dnsutils= package. For Arch Linux
install =bind-tools=. For Fedora install =bind-utils=.)

Pick some random subdomain off your domain:

: dig laksdflkweieri.prod.example.com

Since you created the wildcard record for =*.prod.example.com= dig
should return your Docker server's IP address in the =ANSWER SECTION=
of the output. You can test all your other records the same way.

If you run into DNS caching problems, verify with the source DNS
server directly:

: dig @ns1.digitalocean.com laksdflkweieri.prod.example.com

** Setup your local workstation

Edit your SSH config file: =~/.ssh/config= (create it if necessary).
Create a new config for a host named =prod= (or whatever you want),
and change it so that the domain name is one that you already created
the DNS record for:

: Host prod
:     Hostname ssh.prod.example.com
:     User root
:     ControlMaster auto
:     ControlPersist yes
:     ControlPath /tmp/ssh-%u-%r@%h:%p

(The name =ssh.prod.example.com= should work automatically if you
setup the wildcard DNS entry (=*.prod.example.com=) created
previously. The ControlMaster, ControlPersist, ControlPath adds SSH
connection multi-plexing, and will make repeated logins/docker
commands faster.)

Now test that you can SSH to your droplet:

: ssh prod uname -a

The first time you login to your droplet, you need to confirm the SSH
pubkey fingerprint; press Enter.

If the connection worked, it should print information about the remote
host operating system:

: Linux debian-dev 6.1.0-9-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.27-1 (2023-05-08) x86_64 GNU/Linux

** Install Docker

The droplet has Debian installed on it, but with only basic packages
installed by default. To install the latest version of Docker, run the
installer script, which configures the upstream package repositories
provided by the Docker organization:

: ssh prod curl -fsSL https://get.docker.com -o install-docker.sh
: ssh prod sh install-docker.sh

** Setup Docker context

Now that Docker is installed, you won't be needing to use ssh directly
again, except to do system maintainance.

Setup the Docker context on your workstation:

: docker context create prod --docker host=ssh://prod

Now you can switch to the new context:

: docker context use prod

With this context active, all =docker= commands you run from your
workstation will take effect on the remote Docker host instead.

Test that the context works:

: ## From your workstation:
: docker run hello-world

** Congratulations

You have now finished installation of a remote Docker host server, on
a Debian based droplet (VPS), and configured it on your workstation as
a remote (SSH) docker context.


* Install d.rymcg.tech tools
:PROPERTIES:
:EXPORT_FILE_NAME: install-d-rymcg-tech
:END:

Install d.rymcg.tech and its dependencies *on your workstation*.

** Install dependencies

: ## Fedora
: dnf install bash gettext openssl git xdg-utils jq sshfs curl inotify-tools httpd-tools make wireguard-tools

: ## Debian
: apt-get install bash build-essential gettext git openssl apache2-utils xdg-utils jq sshfs wireguard curl inotify-tools

: ## Arch Linux
: pacman -S bash base-devel gettext git openssl apache xdg-utils jq sshfs wireguard-tools curl inotify-tools

** Clone d.rymcg.tech repository

: git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \
:    ${HOME}/git/vendor/enigmacurry/d.rymcg.tech
:
: cd ${HOME}/git/vendor/enigmacurry/d.rymcg.tech


** Setup =d.rymcg.tech= command line tool

You must edit your workstation user's =~/.bashrc= file, which modifies
the Bash shell environment config:

: # Put this in ~/.bashrc to enable d.rymcg.tech command line tools:
: export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user
: eval "$(d.rymcg.tech completion bash)"
: # Setup shorter alias for d.rymcg.tech as just 'd'
: __d.rymcg.tech_cli_alias d

Now close and restart your shell (terminal) to load the new config.

* Main config for d.rymcg.tech
:PROPERTIES:
:EXPORT_FILE_NAME: main-config-for-d.rymcg.tech
:END:

Each Docker context has a separate config file (=.env_{CONTEXT}=),
stored in the root d.rymcg.tech directory
(=~/git/vendor/enigmacurry/d.rymcg.tech=).

** Choose your current Docker context

: d context

For continuing our example, choose the =prod= context, or whatever you
named your context.

#+attr_shortcode: note
#+begin_notice
hmm
#+end_notice

** Configure current Docker context

: d make - config

This will create a config file for your current Docker context, and
name it =.env_{CONTEXT}= (eg. =.env_prod=). You must run this for each
new Docker context you create, so that each context has its own config
file.

The interactive config will ask you to enter the =ROOT_DOMAIN=
variable, which needs to be the root domain that you want to apply to
your Docker host.

: ROOT_DOMAIN: Enter the root domain for this context (eg. d.example.com)
: : prod.example.com

The root domain serves as the example root domain for all application
default configs.

* Install Traefik Proxy
:PROPERTIES:
:EXPORT_FILE_NAME: install-traefik-proxy
:END:

** Configure Traefik Proxy

Run on your workstation:

: d make traefik config

The configuration for Traefik is driven by a text wizard menu system.

: ? Traefik config main menu:  
: > Create system user on Docker host
:   Configure entrypoints (including dashboard)
:   Configure Certificate Authorities (CA)
:   Configure ACME (Let's Encrypt or Step-CA)
:   Configure TLS certificates and domains (make certs)
:   Configure middleware (including auth)
: v Configure error page template
: [↑↓ to move, enter to select, type to filter, ESC to cancel]

Use your arrow keys to select a menu item and press the =Enter= key.
To cancel, press the =ESC= key.

*** Create system user on Docker host

This option will create a new username on the Docker host, called
=traefik=. This is necessary to reserve a unique UID for traefik to
run as on the system. Run this first before anything else.

*** Configure entrypoints

Traefik uses various entrypoints to allow requests on certain TCP
ports. By default, only port 80 and 443 are enabled. You can enable
extra entrypoints through this menu, which may be necessary for any
application that doesn't use the standard =websecure= entrypoint (port
443).

By default, the Traefik Dashboard is not enabled. To enable it, you
must select it via this menu option, and set a username / password.

*** Configure Certificate Authorities (CA)

If you're planning on running a public server, using TLS certificates
from Let's Encrypt, you can skip this option.

You only need to run this if you wish to modify the TLS certificate
trust store to accomodate a "self-signed" Step-CA authority.

*** Configure ACME (Let's Encrypt or Step-CA)

Choose this option to configure ACME, which makes requesting and
renewing TLS certificates an easy and automatic process.

: ? Which ACME provider do you want to use?  
: > Let's Encrypt (ACME)
:   Step-CA (ACME)
:   Disable ACME
:   Cancel / Go back

For most installs, you should choose =Let's Encrypt (ACME)=. This is
the only option that will create valid TLS certificates for public
websites.

If you want to run private services, you may want to consider using
=Step-CA= instead, as it does not rely upon any external platform like
Let's Encrypt does.

Finally, if you want to setup TLS certificates manually, you can
choose =Disable ACME=.

**** Configure Let's Encrypt environment

: ? Which LE environment do you want to use?  
: > Production (recommended!)
:   Staging (untrusted / testing)

Always choose the =Production= environment, unless you really know
what you're doing. =Production= is the only environment that produces
valid (trusted) TLS certificates.

**** Choose type of ACME challenge

: ? Which type of ACME challenge should be used?  
: > TLS-ALPN-01 (default for public servers, easy, but no wildcard certs)
:   DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs)

For your first install, choose =TLS-ALPN-01=, it is the easiest method
to use for public servers.

If you want to use wildcard DNS records, you must choose the more
advanced method =DNS-01=, and setup your DNS platform for programmatic
access with an API token.

**** Configure ACME email address (optional)

You don't have to provide your email address, but if you do, Let's
Encrypt can email you about configuration issues, like certitficates
about to expire.

*** Configure TLS certificates and domains

d.rymcg.tech uses explicit certificate requests configured centrally,
on the traefik project:

: ? Configure Traefik TLS certificates  
: > Manage all certificates.
:   Create a new certificate.
:   Done / Go back

**** Manage all certificates

This will show you all the certificate requests that have been defined
and allow you to manage each one. It will be blank to start out with.

**** Create a new certificate

Use this to define all the certificates you need for all your
applications.

***** Set certificate main domain (CN)

Each certificate needs a main name (CN), which should be the main
domain name of the certificate.

: prod.example.com

Each certificate also may contain several other domain names, known as
SANs (Subject Alternative Names). You can use this to list as many
additional domain names that you want to allow for the certificate.

*** Configure middleware
*** Configure error page template
*** Configure wireguard VPN
