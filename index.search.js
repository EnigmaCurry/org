var relearn_search_index = [
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "I know of two places to buy solokeys:\nhttps://solokeys.com/collections/all https://www.crowdsupply.com/solokeys/somu#products What to buy:\nRecommended: Solo 2 USB-A (touch capacitive, but its long and sticks out of the USB port). Recommended: Solo 1 Tap USB-A (durable clicky button, but its long and sticks out of the USB port). Recommended: Somu (semi-permanent flush mount USB-A port, soft touch design). Get the “secure” version, don’t buy the “hacker” version. Buy at least two (and store one as a backup). ",
    "description": "I know of two places to buy solokeys:\nhttps://solokeys.com/collections/all https://www.crowdsupply.com/solokeys/somu#products What to buy:\nRecommended: Solo 2 USB-A (touch capacitive, but its long and sticks out of the USB port). Recommended: Solo 1 Tap USB-A (durable clicky button, but its long and sticks out of the USB port). Recommended: Somu (semi-permanent flush mount USB-A port, soft touch design). Get the “secure” version, don’t buy the “hacker” version. Buy at least two (and store one as a backup).",
    "tags": [],
    "title": "Get your Solokey",
    "uri": "/linux-workstation/sudo-2fa/get-your-solokey/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "This book is primarily about Fedora Atomic Desktop (sway) hosts, but these instructions are generic enough to work on a wide variety of systemd based Linux operating systems, including Fedora Workstation (traditional), Fedora CoreOS, Arch Linux, and Debian (with caveats).\nPackages for Fedora Atomic Desktop hosts Tip Full package installation for Fedora Atomic Desktop hosts are covered in the chapter on Layering packages.\nPackages for Fedora CoreOS [bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top distrobox make Packages for traditional Fedora Workstation hosts Info These are the packages you would need to install on traditional Fedora Workstation (or Server, but not CoreOS nor Atomic hosts)\n[bash]: Run this on your workstation: sudo dnf install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top net-tools Packages for Arch Linux hosts Info For Arch Linux, it is recommended to do a full system update and reboot prior to installing the libvirt packages.\n[bash]: Run this on your workstation: sudo pacman -Syu sudo reboot After reboot, install packages:\n[bash]: Run this on your workstation: sudo pacman -S libvirt iptables-nft dnsmasq qemu-base virt-install \\ sysfsutils bridge-utils ebtables git make which jq \\ dmidecode pkgconf gcc Packages for Debian/Ubuntu hosts Info For Debian (or Ubuntu), it is recommended to do a full system upgrade and reboot prior to installing the libvirt packages.\n[bash]: Run this on your workstation: sudo apt update sudo apt upgrade sudo reboot After reboot, install packages:\n[bash]: Run this on your workstation: sudo apt install --no-install-recommends \\ libvirt-daemon-system virtinst libvirt-clients \\ dnsmasq sysfsutils bridge-utils ebtables git make \\ which jq dmidecode pkgconf gcc curl \\ python3 python-is-python3 ",
    "description": "This book is primarily about Fedora Atomic Desktop (sway) hosts, but these instructions are generic enough to work on a wide variety of systemd based Linux operating systems, including Fedora Workstation (traditional), Fedora CoreOS, Arch Linux, and Debian (with caveats).\nPackages for Fedora Atomic Desktop hosts Tip Full package installation for Fedora Atomic Desktop hosts are covered in the chapter on Layering packages.\nPackages for Fedora CoreOS [bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top distrobox make Packages for traditional Fedora Workstation hosts Info These are the packages you would need to install on traditional Fedora Workstation (or Server, but not CoreOS nor Atomic hosts)",
    "tags": [],
    "title": "Install libvirtd",
    "uri": "/linux-workstation/kvm-libvirt/install-libvirtd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": " Raspberry Pi Sentry Droplet WireGuard VPN d.rymcg.tech Your workstation Your console client Next steps Raspberry Pi Here is my Raspberry Pi 5, which is a small form factor Linux computer, running Raspberry Pi OS and Docker. It has been outfitted with an NVME SSD attached via the expandable PCI-E bus. It has 8GB of RAM and 1TB of fast storage.\nI use this as a tiny web server that I can take anywhere I go.\nIt normally sits in one place for a long time. But sometimes it needs to be picked up and installed in a new place. I need it to be able to get the network up, have it resume all of its previous functions, and even use the same IP address as before. Traveling with this device should be a plug and play experience, with minimal disruption to the clients that expect this server to be online and available. No matter what kind of connection to the Internet it has available, it should be quick to get this server back online.\nSentry Droplet To accomplish this feat, we need to set up another server (to be named sentry) that has a static IP address and is accessible from the public Internet. I use a DigitalOcean droplet (affiliate link helps support this book), which is a type of Virtual Private Server (VPS) and exists in the public cloud. The sentry is always on and anyone in the world can connect to it (via HTTP). However, the sentry does not serve any applications by itself; it only creates the public Traefik proxy (ingress) which forwards incoming connections through a backdoor VPN connection to the Raspberry Pi. The Pi automatically initiates this connection to the sentry whenever it boots and becomes online.\nWireGuard VPN The Raspberry Pi should acquire whatever kind of Internet connection is locally available via DHCP, therefore it won’t have a static IP address initially. Once it’s online, it creates an outbound VPN connection to the sentry via WireGuard. Once connected to the VPN, the Pi is assigned a static private IP address that only the sentry can communicate with.\nThe sentry forwards incoming connections from the Internet to the Raspberry Pi over the WireGuard VPN connection. Traefik is used on both the sentry and Raspberry Pi to create the full public route to each of your services. Traefik supports the following types of routes:\nHTTP Layer 7 (Routes an incoming HTTP request, which is a domain name [TLS SNI], and optional HTTP path, over port 443 to a backend HTTP server based on these criteria) TCP Layer 4 (Routes a unique TCP ADDRESS:PORT combination to a unique backend ADDRESS:PORT combination) UDP Layer 4 - TODO (unimplemented, but doable) This lets you publicly route virtually any service directly to your Raspberry Pi, whether it’s sitting at your desk, or taken to an impromptu getaway location.\nd.rymcg.tech d.rymcg.tech is a configuration manager for Docker, as well as a collection of open source web services and config templates. It contains an extensive configuration wizard for Traefik and an idiomatic command line tool, which makes Docker Compose projects both easy to document, as well as to use.\nYour workstation Traditionally, d.rymcg.tech suggests to install itself on a separate workstation and urges you to never actually login to your Docker server, but rather to exclusively control it remotely from your workstation. This is one of the ways to follow the good DevOps practice, summed up by the metaphor: “Treat your infrastructure like cattle, not like pets.” However, this strategy has the drawback that if you lose access to your workstation, it makes it diffcult to adminster the server (you would have to recreate your .env files on a new workstation, from backup, or from scratch).\nTo avoid this complexity, and to require keeping everything portable in one package, as well as to make it easier to maintain after long periods of inactivity and forgetfulness, we will make an important compromise and an exception to the normal DevOps rule:\nThe Raspberry Pi serves the role of workstation AND server In this book, the configuration tools (d.rymcg.tech) will be installed to the same server that runs Docker, rather than the usual recomendation to do so on a separate workstation. Comingling the roles of server and workstation means you’ve got everything together in one little portable box, and it will make everything easier to get started with. Your portable Pi is therefore a pet Docker server, plus workstation, all in one.\nIf you had a whole fleet of Raspberry Pis to manage, this would be a terrible idea, because you would be missing the centralized workstation to control them all, and you’d have to login to each one of them and configure them directly. However, you will likely start this journey with only one Pi to manage, so this is a good initial compromise to make. If you want to build a proper workstation that can control several servers from one location, read the Linux Workstation book and the main d.rymcg.tech README.\nIf you are going to seriously travel with this device, you should consider installing full disk encryption and requiring remote SSH unlock on boot, but this is an advanced topic that is outside the scope of this book.\nYour console client So, if the workstation is on the Raspberry Pi, you’re still going to need to travel with another computer (e.g., a laptop) and set that up with an SSH key on it, so you can remotely log in to the Pi (unless you want to carry a display and keyboard to plug into it directly).\nEditing files on the Pi Eventually you might need to edit a .env file by hand, and so you need to know how to edit files remotely over SSH, so you have a few options in that regard:\nLearn how to use one of the many terminal mode text editors (Emacs, Vim, nano, etc.) and edit the files through an SSH console directly on the Pi. Setup your personal computer with an editor that works over SSH (Emacs’ TRAMP, VS Code’s Remote SSH, Vim’s Netrw etc.) Edit the files locally and copy the files with scp, rsync, or rclone. Next steps Set up DNS Set up Raspberry Pi Set up Sentry Droplet Set up WireGuard Install apps and services ",
    "description": "Raspberry Pi Sentry Droplet WireGuard VPN d.rymcg.tech Your workstation Your console client Next steps Raspberry Pi Here is my Raspberry Pi 5, which is a small form factor Linux computer, running Raspberry Pi OS and Docker. It has been outfitted with an NVME SSD attached via the expandable PCI-E bus. It has 8GB of RAM and 1TB of fast storage.\nI use this as a tiny web server that I can take anywhere I go.",
    "tags": [],
    "title": "Introduction",
    "uri": "/portable-docker/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "Enable libvirtd service [bash]: Run this on your workstation: sudo systemctl enable --now libvirtd sudo systemctl enable --now libvirt-guests sudo systemctl status --no-pager libvirtd Start the default network [bash]: Run this on your workstation: sudo virsh net-start default sudo virsh net-autostart default Configure /etc/group Add the existing libvirt group to /etc/group, if it isn’t already:\n[bash]: Run this on your workstation: grep \"^libvirt:\" /etc/group || sudo bash -c \"getent group libvirt \u003e\u003e /etc/group\" TODO Extra steps only needed for Debian workstations Warning Debian install is a WIP This doesn’t actually fully work on Debian 12 yet. Debian hosts apparently have an additional requirement to run qemu-bridge-helper (I didn’t need it on Fedora or Arch Linux). However, I couldn’t figure out how to get it to work on Debian 12, because I ran into strange app armor errors. YMMV.\nDebian workstations only On a Debian workstation, creating a config for qemu-bridge-helper was required, and modifying it to run setuid root to prevent user permission error (failed to create tun device: Operation not permitted: Transport endpoint is not connected):\n[bash]: Run this on your workstation: (set -e sudo mkdir -p /etc/qemu echo \"allow virbr0\" | sudo tee /etc/qemu/bridge.conf sudo chmod u+s /usr/lib/qemu/qemu-bridge-helper ) I also had to disable apparmor for libvirtd, otherwise I got permission errors:\n[bash]: Run this on your workstation: sudo truncate --size 0 /etc/apparmor.d/usr.sbin.libvirtd sudo apparmor_parser -R /etc/apparmor.d/usr.sbin.libvirtd ",
    "description": "Enable libvirtd service [bash]: Run this on your workstation: sudo systemctl enable --now libvirtd sudo systemctl enable --now libvirt-guests sudo systemctl status --no-pager libvirtd Start the default network [bash]: Run this on your workstation: sudo virsh net-start default sudo virsh net-autostart default Configure /etc/group Add the existing libvirt group to /etc/group, if it isn’t already: [bash]: Run this on your workstation: grep \"^libvirt:\" /etc/group || sudo bash -c \"getent group libvirt \u003e\u003e /etc/group\"",
    "tags": [],
    "title": "Setup libvirtd",
    "uri": "/linux-workstation/kvm-libvirt/setup-libvirtd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "This will create a new user account on your workstation named libvirt-admin. This user will be used as the owner for all the VM disk images, config files, and for running the libvirt (qemu) processes that run your VM.\nThis separation from the normal account you use is important to limit the privileges that you have over the VM infrastructure. Your normal account should be able to SSH into the VM and have full root privleges inside the VM. But your normal account should not have access to the underlying VM disk image files, nor its configuration. Access to all VM administrative tasks must be done through sudo to control the libvirt-admin account.\nCreate libvirt-admin user [bash]: Run this on your workstation: VM_ADMIN=libvirt-admin sudo useradd -m ${VM_ADMIN} -s /bin/bash -G libvirt Extra steps for Debian workstations Tip On a Debian workstation, adding the user to the kvm group was also required:\n[bash]: Run this on your workstation: sudo gpasswd -a ${VM_ADMIN} kvm Configure systemd for the libvirt-admin user [bash]: Run this on your workstation: sudo loginctl enable-linger ${VM_ADMIN} sudo su ${VM_ADMIN} -c \\ \"echo export XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN}) \u003e ~/.bashrc\" Copy your public SSH key into the libvirt-admin home directory Tip If you don’t have an SSH key yet, run ssh-keygen -t ed25519.\nSet SSH_KEY variable to point to your public SSH key file:\n[bash]: Set temporary environment variables SSH_KEY=~/.ssh/id_ed25519.pub [bash]: Run this on your workstation: TMP_SSH=$(mktemp) cat ${SSH_KEY} \u003e ${TMP_SSH} chmod a+r ${TMP_SSH} sudo su ${VM_ADMIN:-libvirt-admin} -c \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_SSH} ~/libvirt/user-ssh.pub\" ",
    "description": "This will create a new user account on your workstation named libvirt-admin. This user will be used as the owner for all the VM disk images, config files, and for running the libvirt (qemu) processes that run your VM.\nThis separation from the normal account you use is important to limit the privileges that you have over the VM infrastructure. Your normal account should be able to SSH into the VM and have full root privleges inside the VM.",
    "tags": [],
    "title": "Create VM admin",
    "uri": "/linux-workstation/kvm-libvirt/dedicated-vm-user/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": "Before you can configure any hardware, you need to set up the domain name service (DNS) of your domain.\nIndex Register a domain name Add the domain to DigitalOcean DNS Generate DigitalOcean API token for ACME challenge ",
    "description": "Before you can configure any hardware, you need to set up the domain name service (DNS) of your domain.\nIndex Register a domain name Add the domain to DigitalOcean DNS Generate DigitalOcean API token for ACME challenge ",
    "tags": [],
    "title": "Set up DNS",
    "uri": "/portable-docker/set-up-dns/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up DNS",
    "content": "To host a web service, one of the first things you will need is to register your domain name (e.g., example.com). This will be the domain name used for all of your service links, and it is what your users will need to type into their web browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments. If domain names were free, all the good ones would be taken by now, but because they cost money, there are still some good enough ones left to be had. In return for your fee, you receive exclusive use of the domain name for the period that you paid for. You “own” the domain name, and its configuration, but you need to keep paying a registrar to keep the record active (so its more like renting). You can pre-pay for several years in advance, or just pay for one year at a time. If you stop paying, and the records expire, they will no longer resolve to your services, and you may lose control of the domain, possibly forever.\nRegister an Internet domain name You can buy (rent) a domain name from lots of places. For documentation purposes, we will use Gandi.net, but these instructions will be similar regardless of the domain provider you pick.\nSetup on Gandi.net Sign up for an account at Gandi.net Once signed in, from your dashboard, click Register. Search for any domain name you like, e.g., your-name.com. Add your domain to the shopping cart, go to checkout, and complete your purchase. Once you have purchased the domain, it should show up in your Dashboard, under the Domain tab. Leave this browser tab open, you will return to it in the next chapter. Transfer DNS to DigitalOcean Choose a supported DNS provider This book uses DigitalOcean as the DNS provider in all examples, but you may choose a different provider if you prefer, but it needs to be supported by go-acme LEGO.\nSetup on Gandi.net Login to your gandi.net dashboard. Click the Domain tab. Find your domain name in the list and click on it. Click on the Nameservers tab. Click on the edit button to create new External nameservers. Delete all existing nameservers that may exist. Add the following nameservers, specific to DigitalOcean: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Wait a few minutes for the change to take effect, then you can verify the setting from your workstation using the whois command:\n[bash]: Run this on your workstation: whois example.com (stdout) Domain Name: example.com Registrar WHOIS Server: whois.gandi.net Name Server: ns1.digitalocean.com Name Server: ns2.digitalocean.com Name Server: ns3.digitalocean.com The output shows a report for your domain registration including the list of the new nameservers.\nIf you don’t have whois installed, you can use the web version provided by google.",
    "description": "To host a web service, one of the first things you will need is to register your domain name (e.g., example.com). This will be the domain name used for all of your service links, and it is what your users will need to type into their web browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments.",
    "tags": [],
    "title": "Register a domain name",
    "uri": "/portable-docker/set-up-dns/register-domain/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up DNS",
    "content": "The Domain Name System is how you can associate one of your sub-domains with an actual IP address on the Internet.\nChoose a supported DNS provider This book uses DigitalOcean as the DNS provider in all examples, but you may choose a different provider if you prefer, but it needs to be supported by go-acme LEGO.\nSign up for a DigitalOcean account (using this referral link helps support this site), and follow along to set up your domain’s DNS.\nAdd your domain name Login to the DigitalOcean console. Click on Networking in the left hand menu. Select the Domains tab. Enter your domain name, and click Add Domain. Wait a few minutes for the setting to take effect, then you can verify the domain name is added:\n[bash]: Run this on your workstation: dig -t ns example.com (if you don’t have dig installed, you can also use the web version provided by google, enter the domain name, and select NS.)\n(stdout) ;; ANSWER SECTION: example.com. 2400 IN NS ns1.digitalocean.com. example.com. 2400 IN NS ns3.digitalocean.com. example.com. 2400 IN NS ns2.digitalocean.com. The number in the second column is the TTL (Time To Live) which is the number of seconds that the record is cached in the queried DNS server. If you jump the gun and check this too quickly before the changes takes effect, you may need to wait for this TTL to reset.",
    "description": "The Domain Name System is how you can associate one of your sub-domains with an actual IP address on the Internet.\nChoose a supported DNS provider This book uses DigitalOcean as the DNS provider in all examples, but you may choose a different provider if you prefer, but it needs to be supported by go-acme LEGO.\nSign up for a DigitalOcean account (using this referral link helps support this site), and follow along to set up your domain’s DNS.",
    "tags": [],
    "title": "Add the domain to DigitalOcean DNS",
    "uri": "/portable-docker/set-up-dns/create-digitalocean-api-token/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH Solokey authentication Get your Solokey Solokey v2 Solokey v1 Sudo with Solokey SSH with Solokey Application users DigitalOcean CLI (doctl) KVM / libvirt Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config Firewall ",
    "description": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH Solokey authentication Get your Solokey Solokey v2 Solokey v1 Sudo with Solokey SSH with Solokey Application users DigitalOcean CLI (doctl) KVM / libvirt Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config Firewall ",
    "tags": [],
    "title": "Linux Workstation",
    "uri": "/linux-workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard and a display (although a workstation could also be a VPS that you SSH into, this book will focus on physical workstations).\nHistorically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really matter anymore, and any computing device can become a workstation. The only important distinction for a workstation is the role that it serves, and how you configure and use it on a daily basis.\nThe role of a workstation is very different than that of a server. A workstation’s only purpose is to serve you, during the moments that you are interfacing with its physical keyboard/display. A workstation is usually connected to a network, but only as a client (terminal, web browser, etc.), not as a server. (Of course, you may bend this rule if you like, to make your computer a server-workstation, or “Sworkstation”, but it is cleaner, and more secure, to use separate [virtual] machines for all servers, even for development purposes.)\nThis book will describe my preferred method for setting up a new computer, for use as a personal Linux workstation. It will also show you how to bend the rules a bit, and create a few virtual machines (VM) for running local development servers (Docker), or even public, production-lite, and/or LAN party services.\nIndex Fedora Sway Atomic Requirements ",
    "description": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard and a display (although a workstation could also be a VPS that you SSH into, this book will focus on physical workstations).\nHistorically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really matter anymore, and any computing device can become a workstation.",
    "tags": [],
    "title": "Introduction",
    "uri": "/linux-workstation/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Set PIN You should set a device PIN for the solokey, so that it cannot be used if it is stolen.\nIdentify the device name (/dev/hidrawX):\n[bash]: Run this on your workstation: fido2-token -L This probably shows the device as /dev/hidraw0:\n(stdout) /dev/hidraw0: ...... Set the PIN for the device (/dev/hidraw0):\n[bash]: Run this on your workstation: fido2-token -C /dev/hidraw0 Steps to update the Solokey (v2) Install solo2-cli Tip solo2-cli is only required if you need to update your device.\nFind the latest version of solo2-cli\n[bash]: Set temporary environment variables SOLO2_VERSION=0.2.2 PLATFORM=x86_64-unknown-linux-gnu [bash]: Run this on your workstation: (set -e curl -L -o solo2 \\ https://github.com/solokeys/solo2-cli/releases/download/v${SOLO2_VERSION}/solo2-v${SOLO2_VERSION}-${PLATFORM} sudo install solo2 /usr/local/bin/ rm -f solo2 ) Identify solokey [bash]: Run this on your workstation: solo2 list (stdout) Solo 2 xxxxxxxxxxx (CTAP+PCSC, firmware 2:20220822.0, locked) Install udev rules [bash]: Run this on your workstation: curl https://raw.githubusercontent.com/solokeys/solo2-cli/main/70-solo2.rules | \\ sudo tee /etc/udev/rules.d/solokey2.rules sudo udevadm trigger Update solokey [bash]: Run this on your workstation: solo2 update Tip You may need to run sudo solo2 update if the udev rules aren’t working correctly.",
    "description": "Set PIN You should set a device PIN for the solokey, so that it cannot be used if it is stolen.\nIdentify the device name (/dev/hidrawX):\n[bash]: Run this on your workstation: fido2-token -L This probably shows the device as /dev/hidraw0:\n(stdout) /dev/hidraw0: ...... Set the PIN for the device (/dev/hidraw0):\n[bash]: Run this on your workstation: fido2-token -C /dev/hidraw0 Steps to update the Solokey (v2) Install solo2-cli Tip solo2-cli is only required if you need to update your device.",
    "tags": [],
    "title": "Solokey v2",
    "uri": "/linux-workstation/sudo-2fa/solo-v2/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": " Index Build your Raspberry Pi Install Raspberry Pi OS Set up networking Set up SSH Install Docker Install d.rymcg.tech Install Traefik Install Whoami ",
    "description": " Index Build your Raspberry Pi Install Raspberry Pi OS Set up networking Set up SSH Install Docker Install d.rymcg.tech Install Traefik Install Whoami ",
    "tags": [],
    "title": "Set up Raspberry Pi",
    "uri": "/portable-docker/set-up-raspberry-pi/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": "These are the parts you will need to source for this build (purchase price ~$240 USD):\nRaspberry Pi 5 motherboard The Raspberry Pi 5 is often sold in kits, but you can also buy the motherboard separately. If buying a pre-made kit, make sure it includes an NVME shield to plug in an NVME SSD. Otherwise, this can be purchased separately:\nGeeekpi / 52Pi case, heatsink, NVME shield, and power supply This kit comes with the NVME shield, which is an adapter (hat) to install on top of the Raspberry Pi 5 motherboard. This allows you to plug in a full size NVME SSD into the Raspberry Pi’s PCI-E bus. The metal case fits the extended height neccessary to fit the NVME shield and SSD inside. The kit also includes the required heatsink for the motherboard, a power supply, and the flat ribbon cable (not shown) that connects the shield to the motherboard’s PCI-E port.\nSandisk SD card (32GB) The SD card is used as the root filesystem for Raspberry Pi OS (formerly named Raspbian). The capacity of the card doesn’t need to be very big, as you won’t be storing very much data on this.\nBooting from the SD-card is a bit slower than NVME, but the advantage of it is that you can simply swap SD-cards, and temporarily use the pi for a different purpose, all without disrupting access to your NVME storage.\nSD-cards are more prone to failure than NVME, especially if you write too much data to them, so this is minimized as much as possible. /tmp will be mounted on tmpfs, and /var/log will run on log2ram, which are both stored in RAM, so the only writes that should happen on the SD-card should be OS updates.\nSD-card adapter The micro SD-card comes with a full size SD-card adapter, but you may also need a USB adapter, in order to write the image.\nSamsung 990EVO NVME SSD The NVME SSD is much faster, and far more reliable, than the SD-card. This device will be used exclusively for the Docker storage system (mounted at /var/lib/docker). This is where all of your container images will be built/downloaded, and where the volumes holding your app data will live.\nNVME heatsink You should purchase separately an NVME heatsink to go on the top of your NVME drive, and there is a little bit of room left in the case to fit one.\nPutting everything together Read the directions that come with the Geeekpi / 52Pi case, the rest of this list is just a summary. Install the heatsink to the Pi 5 motherboard. Attach one end of the ribbon cable to the PCI-E port and lock it into place. Attach the other end of the ribbon cable to the NVME shield and lock it into place. Install the NVME shield on top of the Pi motherboard, plugging into the GPIO ports, and using the taller risers to sandwich things together. Install the motherboard into the bottom part of the case, using the smaller risers to support the motherboard from below. Install the NVME SSD into the NVME shield. Screw on the top part of the case. Install the SD-card into the slot on the bottom edge. Pi 5 heatsink and risers installed Ribbon cable and GPIO pins connect NVME shield to Pi motherboard NVME SSD installed in the NVME shield and motherboard secured in the bottom part of case top part of the case screwed on top and SD-card installed The fully assembled Raspberry Pi 5 (NVME heatsink not shown) ",
    "description": "These are the parts you will need to source for this build (purchase price ~$240 USD):\nRaspberry Pi 5 motherboard The Raspberry Pi 5 is often sold in kits, but you can also buy the motherboard separately. If buying a pre-made kit, make sure it includes an NVME shield to plug in an NVME SSD. Otherwise, this can be purchased separately:\nGeeekpi / 52Pi case, heatsink, NVME shield, and power supply This kit comes with the NVME shield, which is an adapter (hat) to install on top of the Raspberry Pi 5 motherboard.",
    "tags": [],
    "title": "Build your Raspberry Pi",
    "uri": "/portable-docker/set-up-raspberry-pi/build-your-pi/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": " The best way to install Raspberry Pi OS onto an SD-card, is to use the rpi-imager program from another computer. This allows you to set up the user account, network settings, and SSH credentials all from the imager software.\nDownload the Raspberry PI Imager or install rpi-imager from your package manager.\nRun rpi-imager.\nClick on the menu labled Rasperry Pi Device.\nChoose your model of raspberry pi. Click on the menu labeled Operating System\nChoose Raspberry PI OS (other) Choose Raspberry PI OS Lite (64-bit). Click on the menu labeled Storage.\nChoose the Storage device to install to. You may need to change the ownership of the device (e.g., I had to do sudo chown ryan /dev/sdb first). Click Next.\nClick Edit Settings.\nOn the General tab:\nEnter the hostname Enter a username and password (This book uses the username pi). Optionally set up the Wi-Fi (I just use ethernet instead). Set locale settings. I set mine to UTC. On the Services tab:\nClick Enable SSH Choose Allow pulbic-key authentication only If you don’t have an SSH key yet, read the SSH chapter of the Linux Workstation book. Paste the list of your SSH public keys into the box. (Find them on your workstation by running ssh-add -L or look in ~/.ssh/id_ed25519.pub) The SSH key is important to protect, as this is the only way to remotely SSH into the Raspberry Pi On the Options tab:\nUnselect Enable telemetry unless you’re into that sort of thing. Click Yes to the question Would you like to apply OS custom settings.\nConfirm you would like to write to the SD-card and wait for it to complete.\nOnce complete, unplug the SD-card, put it into the raspberry pi, plug in the ethernet, and power it on.\nFind the local IP address of the Pi on your LAN Once the Pi is powered on, and is connected to your LAN, you need to figure out what its IP address is. There are a number of ways to do that:\nIf your network has configured multicast DNS (mDNS), you can find the IP address by the hostname you set in the imager (e.g., pi5), appended with the domain .local: [bash]: Run this on your workstation: ping -c3 pi5.local From any Linux computer attached to the same LAN, run arp -a to find and list local devices. Try doing this before and after you turn on the Pi, and then spot the difference. [bash]: Run this on your workstation: arp -a If you have a central LAN router + DHCP server, check the console of the router for the newly added device. Plug a monitor into the (micro) HDMI port of the Raspberry Pi, and the IP address will be printed to the console when it boots. Create SSH config on your workstation You should try to connect to the Raspberry Pi from another computer (which from now is to be refered to as your “workstation”).\nTo do so, you will need to create an SSH config on your workstation, containing the temporary local IP address of the Raspberry Pi. This config is somewhat temporary, and once DNS is set up later on, it can be replaced with a permanent hostname config.\n[bash]: Run this on your workstation: cat \u003c\u003cEOF \u003e\u003e ~/.ssh/config Host pi User pi Hostname X.X.X.X ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p EOF Replace X.X.X.X with the local IP address assigned to the Raspberry Pi.\nTest that the SSH connection works:\n[bash]: Run this on your workstation: ssh pi The first time you connect, it will ask you to confirm the remote host ssh key, you should simply type yes to trust whatever it says, and it will trust it automatically from now on.\nIf the connection is successful, you should now be logged into the remote shell console of the Raspberry Pi.\nSet up Log2Ram You can increase the expected lifespan of your SD card by installing log2ram\nRun this on the Raspberry Pi echo \"deb [signed-by=/usr/share/keyrings/azlux-archive-keyring.gpg] http://packages.azlux.fr/debian/ bookworm main\" | sudo tee /etc/apt/sources.list.d/azlux.list sudo wget -O /usr/share/keyrings/azlux-archive-keyring.gpg https://azlux.fr/repo.gpg sudo apt update sudo apt install log2ram After installing log2ram, reboot the pi:\nRun this on the Raspberry Pi sudo reboot After reboot, you will find /var/log/ is mounted as type log2ram:\n(stdout) ryan@pi5:~ $ df -h Filesystem Size Used Avail Use% Mounted on ... log2ram 128M 14M 115M 11% /var/log Format and mount SSD storage Identify the device name of the NVME SSD: Run this on the Raspberry Pi sudo fdisk -l | grep -A5 nvme (stdout) Disk /dev/nvme0n1: 931.51 GiB, 1000204886016 bytes, 1953525168 sectors Disk model: Samsung SSD 990 EVO 1TB Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes This shows the device is named /dev/nvme0n1.\nPartition the device Run this on the Raspberry Pi sudo parted /dev/nvme0n1 --script mklabel gpt sudo parted /dev/nvme0n1 --script mkpart primary ext4 0% 100% Create filesystem Run this on the Raspberry Pi sudo mkfs.ext4 /dev/nvme0n1p1 Mount the filesystem Run this on the Raspberry Pi sudo mkdir -p /var/lib/docker echo \"/dev/nvme0n1p1 /var/lib/docker ext4 defaults 0 3\" | sudo tee -a /etc/fstab sudo systemctl daemon-reload sudo mount /var/lib/docker Verify the mounted storage Run this on the Raspberry Pi df -h /var/lib/docker (stdout) Filesystem Size Used Avail Use% Mounted on /dev/nvme0n1p1 916G 28K 870G 1% /var/lib/docker This shows the correct partition /dev/nvme0n1p1 mounted at the correct path /var/lib/docker and showing the correct size of the NVME SSD (916G; it’s always a bit smaller than advertised.)",
    "description": "The best way to install Raspberry Pi OS onto an SD-card, is to use the rpi-imager program from another computer. This allows you to set up the user account, network settings, and SSH credentials all from the imager software.\nDownload the Raspberry PI Imager or install rpi-imager from your package manager.\nRun rpi-imager.\nClick on the menu labled Rasperry Pi Device.\nChoose your model of raspberry pi. Click on the menu labeled Operating System",
    "tags": [],
    "title": "Install Raspberry Pi OS",
    "uri": "/portable-docker/set-up-raspberry-pi/install-raspbian/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": " Wi-Fi You may have already configured the Wi-Fi in the rpi-imager options, but if not, you can do so after its been installed.\nRun this on the Raspberry Pi sudo raspi-config Enter System Options. Enter S1 Wireless LAN. Choose your current country. Enter the SSID (Wi-Fi network name) you wish to connect to. Enter the network passphrase Configure DNS By default, DNS is handled via DHCP, which will probably work in the majority of cases. However, you may wish to hardcode specific DNS servers instead:\nRun this on the Raspberry Pi echo -e \"nameserver 1.1.1.1\" | sudo tee /etc/resolv.conf sudo chattr +i /etc/resolv.conf chattr +i prevents DHCP from overwriting this file in the future.\nLinks The Raspberry Pi Guide - For scientists and anyone else - this shares how to configure many different network scenarios, including a direct ethernet cable between your workstation and the pi, useful when you can’t find an ethernet LAN with DHCP. Official Raspberry Pi Networking guide ",
    "description": "Wi-Fi You may have already configured the Wi-Fi in the rpi-imager options, but if not, you can do so after its been installed.\nRun this on the Raspberry Pi sudo raspi-config Enter System Options. Enter S1 Wireless LAN. Choose your current country. Enter the SSID (Wi-Fi network name) you wish to connect to. Enter the network passphrase Configure DNS By default, DNS is handled via DHCP, which will probably work in the majority of cases.",
    "tags": [],
    "title": "Set up networking",
    "uri": "/portable-docker/set-up-raspberry-pi/set-up-networking/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": "The Docker context is controlled exclusively through SSH, as the root user. This requires setting up some keys to allow the pi user to access the root user’s account.\nAlthough you will not need to interact with the root user’s shell directly, the pi user will be granted full access to root via SSH.\nDocker == root == pi SSH is used here almost like sudo. The pi user should be treated with the same respect as the root user, as it will be granted full root access through SSH (to localhost).\nCreate a new SSH key You need to create a new SSH key for the pi user.\nUnencrypted SSH keys are used for convenience To connect to the Docker context requires that your SSH key be already decrypted.\nThere’s only two ways to do that:\nCreate an unencrypted SSH key, so that no passphrase is ever required. -or-\nSet up an ssh-agent to decrypt and load the unencrypted key into resident memory, so that your key can be used without requiring a passphrase. For the sake of convenience, this guide will use the first method, and create a new unencrypted SSH key, living in the pi user’s home directory: /home/pi/.ssh/id_ed25519. The security of this key depends upon the physical and network security of the device (including SD-card). Any user gaining entry to the pi user’s account will have access to the key, and no passphrase is required to use the key.\nIf you wish to enhance the security of your SSH key, please read the Arch Wiki article on SSH keys, which covers generating secure SSH keys, setting a passphrase, and setting up an ssh-agent with Keychain.\nYou may also protect the integrity of the SD-card (at rest) with full disk encryption and remote unlock via SSH.\nCreate a new SSH key (without a passphrase):\nRun this on the Raspberry Pi ssh-keygen -t ed25519 -N \"\" -f ~/.ssh/id_ed25519 Authorize the key of the pi user to connect as root All interaction with Docker is done over SSH as the root user, so for the pi user to control Docker, they need to be able to SSH to localhost as the root user.\nAdd the pi user’s key to the root user’s /root/.ssh/authorized_keys file:\nRun this on the Raspberry Pi cat ~/.ssh/id_ed25519.pub | sudo tee -a /root/.ssh/authorized_keys Create a config named pi in your ~/.ssh/config:\nRun this on the Raspberry Pi cat \u003c\u003cEOF \u003e\u003e ~/.ssh/config Host pi User root Hostname localhost ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p EOF Test the connection is working:\nRun this on the Raspberry Pi ssh pi whoami Accept the key fingerprint it offers:\n(stdout) The authenticity of host 'localhost (::1)' can't be established. ED25519 key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx. This key is not known by any other names. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes If it worked, you should see the output of whoami which should print the username root (which is the user configured by SSH).",
    "description": "The Docker context is controlled exclusively through SSH, as the root user. This requires setting up some keys to allow the pi user to access the root user’s account.\nAlthough you will not need to interact with the root user’s shell directly, the pi user will be granted full access to root via SSH.\nDocker == root == pi SSH is used here almost like sudo. The pi user should be treated with the same respect as the root user, as it will be granted full root access through SSH (to localhost).",
    "tags": [],
    "title": "Set up SSH",
    "uri": "/portable-docker/set-up-raspberry-pi/set-up-ssh/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": "Install Docker On the pi, install docker: Run this on the Raspberry Pi curl -sSL https://get.docker.com | sh Test docker is working: Run this on the Raspberry Pi sudo docker run hello-world If working, you should see a Hello from Docker! message and some other help info. Tip Normally, you shouldn’t use sudo docker. In the next section you will create a Docker context for the pi user to use directly.\nSet up Docker context (SSH) d.rymcg.tech requires the use of a Docker context via SSH, rather than the default socket context.\nCreate a new docker context, named pi, using the SSH config you had just created (also called pi):\nRun this on the Raspberry Pi docker context create pi --docker \"host=ssh://pi\" Switch to use the new SSH context as the default:\nRun this on the Raspberry Pi docker context use pi Now, when you run any docker command, it will use the SSH context:\nRun this on the Raspberry Pi docker info | grep -iE \"(Name|Context)\" This should print the proper context: pi.\nIf it worked, the pi user is now fully equipped to run any docker comamnd as root.",
    "description": "Install Docker On the pi, install docker: Run this on the Raspberry Pi curl -sSL https://get.docker.com | sh Test docker is working: Run this on the Raspberry Pi sudo docker run hello-world If working, you should see a Hello from Docker! message and some other help info. Tip Normally, you shouldn’t use sudo docker. In the next section you will create a Docker context for the pi user to use directly.",
    "tags": [],
    "title": "Install Docker",
    "uri": "/portable-docker/set-up-raspberry-pi/install-docker/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": "Install dependencies Run this on the Raspberry Pi sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y bash build-essential gettext \\ git openssl apache2-utils xdg-utils jq sshfs \\ wireguard curl inotify-tools w3m Clone the git repository Run this on the Raspberry Pi git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \\ ${HOME}/git/vendor/enigmacurry/d.rymcg.tech cd ${HOME}/git/vendor/enigmacurry/d.rymcg.tech Configure Bash shell integration Configure the pi user’s ~/.bashrc file:\nRun this on the Raspberry Pi cat \u003c\u003c'EOF' \u003e\u003e ~/.bashrc export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user eval \"$(d.rymcg.tech completion bash)\" __d.rymcg.tech_cli_alias d EOF Once finished, logout of the Pi and log back in.\nNow you should have a new alias named d that controls the d.rymcg.tech toolset. Check out the main help screen:\nRun this on the Raspberry Pi d (stdout) ## Main d.rymcg.tech sub-commands - Optional arguments are printed in brackets [OPTIONAL_ARG] cd [SUBDIR] Enter a sub-shell and go to the ROOT_DIR directory (or given subdirectory) make [PROJECT] [ARGS ...] Run a `make` command for the given d.rymcg.tech project name context View or set the current Docker context new-context Create a new Docker context tmp-context Use a temporary Docker context in a sub-shell config Configure the current Docker context ssh [COMMAND ...] Run command or shell on active docker context SSH host completion Setup TAB completion in your shell install Install an app interactively install-docker Install Docker Engine on the host status Show status of all installed services audit Print security audit of running containers ## Documentation sub-commands: help Show this help screen list List available d.rymcg.tech projects (not including external projects, unless you symlink them into ROOT_DIR) readme Open the main d.rymcg.tech README.md in your browser readme [PROJECT] Open the README.md for the given project name readme digitalocean Open root documentation file: DIGITALOCEAN.md readme security Open root documentation file: SECURITY.md readme aws Open root documentation file: AWS.md readme license Open root documentation file: LICENSE.txt readme raspberry_pi Open root documentation file: RASPBERRY_PI.md readme makefile_ops Open root documentation file: MAKEFILE_OPS.md Run the main config Run this on the Raspberry Pi d config Follow the interactive prompts to finish configuration Install script-wizard (stdout) This utility can automatically install a required helper tool called script-wizard. See https://github.com/enigmacurry/script-wizard Do you wish to automatically install script-wizard into `_scripts/script-wizard`? (Y/n): y script-wizard is required dependency that can be downloaded and installed automatically. script-wizard makes interactive input and selection wizards in Bash a lot nicer.\nAcknowledge the detected Docker context (stdout) ? This will make a configuration for the current docker context (pi). Proceed? (Y/n) y Choose the root domain name for this server (stdout) ROOT_DOMAIN: Enter the root domain for this context (e.g., d.example.com) : d.example.com Instead of d.example.com you should type the actual domain name (or subdomain name) that you want to use as the root domain for all of your services on this server.\nFor example, if you entered example.com, you will later install apps (e.g., whoami) with subdomains like whoami.example.com. Choosing a deeper subdomain has the benefit of being able to share a single root domain name amongst several Docker instances, therefore with the example of d.example.com the service would be deployed like whoami.d.example.com, and a second Docker instance could use d2.example.com, with services like whoami.d2.example.com.\nChoose to save generated passwords.json files by default (stdout) Every time you configure HTTP Basic Authentication, you are asked if you wish to save the cleartext passwords into passwords.json (in each project directory). If you were to press Enter without answering the question, the default answer is No (displayed as y/N). You may change the default response to Yes (displayed as Y/n). ? Do you want to save cleartext passwords in passwords.json by default? (y/N) y This question is in regards to the integrated HTTP Basic Auth setting, which allows you to store the plain text credentials in the file named passwords.json in the various project directories. This is a convenience feature, but you may not want it. Its not really a security concern, because the same password is also availalbe in the .env file for the project anyway, so go ahead an enable it.",
    "description": "Install dependencies Run this on the Raspberry Pi sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y bash build-essential gettext \\ git openssl apache2-utils xdg-utils jq sshfs \\ wireguard curl inotify-tools w3m Clone the git repository Run this on the Raspberry Pi git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \\ ${HOME}/git/vendor/enigmacurry/d.rymcg.tech cd ${HOME}/git/vendor/enigmacurry/d.rymcg.tech Configure Bash shell integration Configure the pi user’s ~/.bashrc file:\nRun this on the Raspberry Pi cat \u003c\u003c'EOF' \u003e\u003e ~/.bashrc export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.",
    "tags": [],
    "title": "Install d.rymcg.tech",
    "uri": "/portable-docker/set-up-raspberry-pi/install-d-rymcg-tech/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up DNS",
    "content": " Choose a supported DNS provider This book uses DigitalOcean as the DNS provider in all examples, but you may choose a different provider if you prefer, but it needs to be supported by go-acme LEGO.\nDNS is also a part of the TLS certificate request process with Let’s Encrypt (via ACME DNS-01 challenge). Traefik interacts with Let’s Encrypt on your behalf, automatically requesting TLS certificates to be created for your services. To allow this, you will need to procure a DigitalOcean Personal Access Token, which grants programatic control of your DigitalOcean account’s DNS settings:\nLogin to the DigitalOcean console. Click on API in the left hand menu, near the bottom of the list. On the Tokens tab, click Generate New Token. Enter a descriptive name indicating the owner of the token (e.g., a subdomain), and its purpose (e.g., ACME): pi5.example.com ACME. Set the expiration period you want to use. Use No expire if you just want to set it and forget it, otherwise you will need to update the token periodically. Select Custom Scopes so you can choose the fine-grained permissions. The only permission that needs to be selected is domain. Click Generate Token. Copy the generated token to a temporary buffer/notepad. You will need to reference this token in the next section, when it asks for the DO_AUTH_TOKEN variable. You will also need to generate an API token for the sentry droplet.\nCreate the second token named sentry.example.com ACME or similar. Set a Custom scope = domain. Copy this token to the same temporary buffer/notepad as before, you’ll need it when setting up the sentry droplet. Tip You could reuse the same API token on both Pi and sentry, but its reccomended to create a unique token for each host.",
    "description": "Choose a supported DNS provider This book uses DigitalOcean as the DNS provider in all examples, but you may choose a different provider if you prefer, but it needs to be supported by go-acme LEGO.\nDNS is also a part of the TLS certificate request process with Let’s Encrypt (via ACME DNS-01 challenge). Traefik interacts with Let’s Encrypt on your behalf, automatically requesting TLS certificates to be created for your services.",
    "tags": [],
    "title": "Generate DigitalOcean API token for ACME challenge",
    "uri": "/portable-docker/set-up-dns/create-digitalocean-api-token-for-acme-challenge/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": " Traefik is the application proxy (HTTP / TCP / UDP) that is the entrypoint, and router, for all of your web services. Traefik facilitates automatic TLS certificate requests via Let’s Encrypt, and handles transport security for all of your applications. Traefik is configured to support several authentication + sentry authorization mechanisms, including: HTTP Basic Auth, OAuth2, mutual TLS, and IP address filtering.\nBasic Traefik config Run this on the Raspberry Pi d make traefik config This presents the interactive configuration menu for Traefik:\n(stdout) ############################################################ ### pi ### ############################################################ ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) [↑↓ to move, enter to select, type to filter, ESC to cancel] You can use the up and down arrow keys to choose the selection, and you may type to narrow the list. Select the Config entry and press the Enter key.\nTraefik Config Don’t wander off The Traefik configuration is extensive. This section will only show you how to configure Traefik for a basic install. Many of the menu options will be skipped for the time being. Follow these instructions exactly, and don’t go wandering through the other menus just yet.\n(stdout) During first time setup, you must complete the following tasks: - Create Traefik user. - Configure TLS certificates and ACME (optional). - Install traefik. Traefik must be re-installed to apply any changes. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ? Traefik Configuration: \u003e Traefik user Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template v Logging level [↑↓ to move, enter to select, type to filter, ESC to cancel] Traefik user Select the Traefik user option to create the traefik user on the host.\nEntrypoints (including dashboard) The following entrypoints are defined by default:\n(stdout) Entrypoint Listen_address Listen_port Protocol Upstream_proxy ---------- -------------- ----------- -------- -------------- web 0.0.0.0 80 tcp websecure 0.0.0.0 443 tcp You will need to reconfigure the websecure entrypoint, to enable the Proxy Protocol:\n(stdout) ? Traefik entrypoint config Show enabled entrypoints \u003e Configure stock entrypoints Configure custom entrypoints ? Select entrypoint to configure: dashboard : Traefik dashboard (only accessible from 127.0.0.1:8080 and requires HTTP basic auth) web : HTTP (unencrypted; used to redirect requests to use HTTPS) \u003e websecure : HTTPS (TLS encrypted HTTP) web_plain : HTTP (unencrypted; specifically NOT redirected to websecure; must use different port than web) mqtt : MQTT (mosquitto) pub-sub service ssh : SSH (forgejo) git (ssh) entrypoint v xmpp_c2s : XMPP (ejabberd) client-to-server entrypoint \u003e Do you want to enable the websecure entrypoint? Yes Set TRAEFIK_WEBSECURE_ENTRYPOINT_ENABLED=true TRAEFIK_WEBSECURE_ENTRYPOINT_HOST: Enter the host ip address to listen on (0.0.0.0 to listen on all interfaces) (e.g., 0.0.0.0) : 0.0.0.0 TRAEFIK_WEBSECURE_ENTRYPOINT_PORT: Enter the host port to listen on (e.g., 443) : 443 ? Is this entrypoint downstream from another trusted proxy? No, clients dial directly to this server. (Turn off Proxy Protocol) \u003e Yes, clients are proxied through a trusted server. (Turn on Proxy Protocol) TRAEFIK_WEBSECURE_ENTRYPOINT_PROXY_PROTOCOL_TRUSTED_IPS: Enter the comma separated list of trusted upstream proxy servers (CIDR) : 10.13.16.1/32 Press ESC two times to get back to the traefik config menu.\nConfigure ACME (stdout) ? Traefik Configuration: Traefik user Entrypoints (including dashboard) \u003e TLS certificates and authorities Middleware (including sentry auth) Advanced Routing (Layer 7 / Layer 4 / Wireguard) Error page template v Logging level ? Traefik TLS config: Configure certificate authorities (CA) \u003e Configure ACME (Let's Encrypt or Step-CA) Configure TLS certificates (make certs) ? Which ACME provider do you want to use? \u003e Let's Encrypt (ACME) Step-CA (ACME) Disable ACME Cancel / Go back ? Which LE environment do you want to use? \u003e Production (recommended!) Staging (untrusted / testing) Which type of ACME challenge should be used? TLS-ALPN-01 (default for public servers, easy, but no wildcard certs) \u003e DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs) TRAEFIK_ACME_CA_EMAIL: Enter your email address (not required; blank to skip) : TRAEFIK_ACME_DNS_PROVIDER: Enter the LEGO code for your DNS Provider (eg. digitalocean) : digitalocean TRAEFIK_ACME_DNS_VARNAME_1: Enter the 1st DNS provider variable name (eg. DO_AUTH_TOKEN) : DO_AUTH_TOKEN TRAEFIK_ACME_DNS_VARNAME_2: Enter the 2nd DNS provider variable name (or leave blank) : Now to enter the values for the custom DNS API variables: DO_AUTH_TOKEN: Enter the value for DO_AUTH_TOKEN (e.g., your-actual-digitalocean-token-here) : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Request TLS certificates (stdout) ? Traefik TLS config: Configure certificate authorities (CA) Configure ACME (Let's Encrypt or Step-CA) \u003e Configure TLS certificates (make certs) ? Configure Traefik TLS certificates Manage all certificates. \u003e Create a new certificate. Done / Go back Next enter the domain names you want listed on this certificate:\nd.example.com *.d.example.com (stdout) Enter the main domain (CN) for this certificate (e.g., `d.rymcg.tech` or `*.d.rymcg.tech`) : d.example.com Now enter additional domains (SANS), one per line: Enter a secondary domain (enter blank to skip) : *.d.example.com Enter a secondary domain (enter blank to skip) : It will continue asking you to enter additional SANS domains until you enter a blank response, so just press Enter on the blank line.\nCertificate summary (stdout) Main domain: pi5.example.com Secondary (SANS) domains: *.pi5.example.com Finally a summary of the certificate request is printed.\nPress the ESC key three times to go back to the main menu. Error page template You can customize the Traefik error page template by selecing a custom theme:\n(stdout) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) Advanced Routing (Layer 7 / Layer 4 / WireGuard) \u003e Error page template Logging level Access logs ? Select an error page theme (https://github.com/tarampampam/error-pages#-templates) ^ hacker-terminal cats lost-in-space app-down connection \u003e matrix orient Since this theme is only used for the 404s and other errors coming from Traefik directly (and not for any errors coming from the apps themselves), the choice here is not purely aesthetic: as long as you choose unique error page template themes for each Traefik server instance (e.g., pi, sentry), you will gain extra debugging knowledge of knowing which Traefik instance is returning a particular error.\nInstall Traefik (stdout) ############################################################ ### pi ### ############################################################ ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) [↑↓ to move, enter to select, type to filter, ESC to cancel] On the main menu, select Install (make install).\nWait for the Traefik service to be installed, and then you will be returned to the main menu.\nPress the Esc key to quit the Traefik configuration.\nVerify Traefik status You can check to see that Traefik has started:\nRun this on the Raspberry Pi d make traefik status You should see two services running: traefik and traefik-error-pages, both in state running:\n(stdout) NAME ENV IMAGE STATE traefik-error-pages-1 .env_pi_default tarampampam/error-pages:2.25.0 running traefik-traefik-1 .env_pi_default traefik-traefik running ",
    "description": "Traefik is the application proxy (HTTP / TCP / UDP) that is the entrypoint, and router, for all of your web services. Traefik facilitates automatic TLS certificate requests via Let’s Encrypt, and handles transport security for all of your applications. Traefik is configured to support several authentication + sentry authorization mechanisms, including: HTTP Basic Auth, OAuth2, mutual TLS, and IP address filtering.\nBasic Traefik config Run this on the Raspberry Pi d make traefik config This presents the interactive configuration menu for Traefik:",
    "tags": [],
    "title": "Install Traefik",
    "uri": "/portable-docker/set-up-raspberry-pi/install-traefik/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up Raspberry Pi",
    "content": " What is Whoami? Install Set up temporary DNS override Open whoami in the web browser View the logs What is Whoami? Whoami is a web application that simply outputs the request headers that it receives (reflecting them back to the requesting client):\nRun this later after you install it: curl https://whoami.example.com (stdout) Name: default Hostname: 38704012c4b3 IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:34610 GET / HTTP/1.1 Host: whoami.example.com User-Agent: curl/7.88.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 198.51.100.1 X-Forwarded-Host: whoami.example.com X-Forwarded-Port: 443 X-Forwarded-Proto: https X-Forwarded-Server: docker X-Real-Ip: 198.51.100.1 This output is useful for end-to-end testing, to verify that the application is capable of serving requests, and that all of the configuration is correct. Traefik middlewares may also add additional headers to incoming requests, and so whoami is a nice way to verify that those are working too. Finally, the connection test will confirm whether or not the TLS certificate is installed correctly.\nInstall Create a new config:\n[bash]: Run this on your workstation: d make whoami config The first question the config asks for is WHOAMI_TRAEFIK_HOST which should be the fully qualified domain name that the whoami app will use for its URL:\n(stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (e.g., whoami.example.com) ​: whoami.d.example.com Optional authentication can be configured:\n(stdout) ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) For now, choose No, to disable authentication.\nInstall whoami:\n[bash]: Run this on your workstation: d make whoami install Set up temporary DNS override The whoami service is not public yet, it is currently only accessible from the same local network (LAN). For testing purposes, you need to set a temporary local DNS override in the Raspberry Pi’s /etc/hosts file:\nRun this on the Raspberry Pi echo \"127.0.1.1 whoami.d.example.com\" | sudo tee -a /etc/hosts Replace whoami.d.exmaple.com with the same domain name you set for WHOAMI_TRAEFIK_HOST.\nOpen whoami in the web browser Run this on the Raspberry Pi d make whoami open Tip The open target uses the xdg-open tool to automatically open your preferred web browser to the given application’s URL. Since you are connected to the Raspberry Pi’s text console over SSH, you are limited to text-mode browsers. w3m will be used in this instance to display the page. To quit w3m, press q, then y.\n(stdout) Name: default Hostname: c3ce89b0fceb IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:50156 GET / HTTP/1.1 Host: whoami.d.example.com User-Agent: w3m/0.5.3+git20230121 Accept: text/html, text/*;q=0.5, image/*, application/* Accept-Encoding: gzip, compress, bzip, bzip2, deflate Accept-Language: en;q=1.0 X-Forwarded-For: 127.0.0.1 X-Forwarded-Host: whoami.d.example.com X-Forwarded-Port: 443 X-Forwarded-Proto: https X-Forwarded-Server: pi5 X-Real-Ip: 127.0.0.1 ≪ ↑ ↓ Viewing[SSL] \u003c\u003e If you see output like printed above, you have confirmed that Whoami and Traefik are functioning correctly. The status bar of w3m shows Viewing[SSL] which confirms that TLS is successfully working.\nYou can further verify the TLS certificate is issued correctly:\nRun this on the Raspberry Pi openssl s_client -connect whoami.example.com:443 ",
    "description": "What is Whoami? Install Set up temporary DNS override Open whoami in the web browser View the logs What is Whoami? Whoami is a web application that simply outputs the request headers that it receives (reflecting them back to the requesting client):\nRun this later after you install it: curl https://whoami.example.com (stdout) Name: default Hostname: 38704012c4b3 IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:34610 GET / HTTP/1.1 Host: whoami.example.com User-Agent: curl/7.",
    "tags": [],
    "title": "Install Whoami",
    "uri": "/portable-docker/set-up-raspberry-pi/install-whoami/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": " This book serves as your guide to installing Docker on a small portable Linux device (e.g., Raspberry Pi) and deploying some web service containers on it.\nYou’ll also create and configure a public cloud server (e.g., a DigitalOcean droplet) whose sole purpose is to host a VPN (WireGuard) and public gateway (Traefik), enabling the Raspberry Pi to securely connect from any location.\nThrough the encrypted tunnel established by this connection, the Pi can publish services to the Internet even when operating behind a restrictive firewall, such as public Wi-Fi, mobile hotspots, or carrier-grade NAT. As long as you can get unblocked outgoing Internet access, you can self-host a roaming public server from anywhere!\nd.rymcg.tech Chat with us on Matrix Index Introduction Set up DNS Register a domain name Add the domain to DigitalOcean DNS Generate DigitalOcean API token for ACME challenge Set up Raspberry Pi Build your Raspberry Pi Install Raspberry Pi OS Set up networking Set up SSH Install Docker Install d.rymcg.tech Install Traefik Install Whoami Set up sentry Droplet Launch DigitalOcean droplet Configure the droplet on the Pi Configure d.rymcg.tech for the sentry Configure WireGuard VPN Configure sentry wireguard server Configure Raspberry Pi WireGuard client Install web services Immich Yourls ",
    "description": "This book serves as your guide to installing Docker on a small portable Linux device (e.g., Raspberry Pi) and deploying some web service containers on it.\nYou’ll also create and configure a public cloud server (e.g., a DigitalOcean droplet) whose sole purpose is to host a VPN (WireGuard) and public gateway (Traefik), enabling the Raspberry Pi to securely connect from any location.\nThrough the encrypted tunnel established by this connection, the Pi can publish services to the Internet even when operating behind a restrictive firewall, such as public Wi-Fi, mobile hotspots, or carrier-grade NAT.",
    "tags": [],
    "title": "Portable Docker: Build and Deploy Anywhere with WireGuard Tunneling",
    "uri": "/portable-docker/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": " Index Launch DigitalOcean droplet Configure the droplet on the Pi Configure d.rymcg.tech for the sentry ",
    "description": " Index Launch DigitalOcean droplet Configure the droplet on the Pi Configure d.rymcg.tech for the sentry ",
    "tags": [],
    "title": "Set up sentry Droplet",
    "uri": "/portable-docker/set-up-cloud-sentry/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up sentry Droplet",
    "content": "Set up your SSH key on DigitalOcean How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Settings in the menu. Click on the Security tab. Click on the Add SSH Key button. Paste your public SSH key into the box. (copy the contents of ~/.ssh/id_ed25519.pub.) Enter a key name, I recommend this be the same as the hostname of your raspberry pi. Finish adding the key, click Add SSH Key. Create a DigitalOcean firewall template How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Click the Firewalls tab. Click Create Firewall. Enter the name, e.g., ssh-web-https-wireguard. Enter the following rules: SSH: Type: SSH Protocol: TCP Port Range: 22 Sources: All IPv4, All IPv6, or a specific static IP address if you want to be more secure. HTTP: Type: HTTP Protocol: TCP Port Range: 80 Sources: All IPv4, All IPv6. HTTPS: Type: HTTP Protocol: TCP Port Range: 443 Sources: All IPv4, All IPv6. WireGuard VPN: Type: Custom Protocol: UDP Port Range: 51820 Sources: All IPv4, All IPv6. ICMP: Optional to allow ping response Type: ICMP Click Create Firewall. Create the DigitalOcean droplet How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Droplets in the menu. Click Create Droplet. Choose a Region (e.g., New York), where the droplet will be created. Underneath the heading Choose an image, choose Debian (select the latest version). Choose a droplet size. For a wireguard proxy by itself, 1GB should be fine. 2GB RAM and 50GB disk recommended for medium size production installs with some apps installed on the droplet itself. (It is also tested working on as little as 512MB ram, if you enable zram and/or create a 1GB swapfile. Do not abuse swap space like this in production! However I think its fine for development use, but you may occasionally run into low memory issues if less than 1GB.) Select the SSH key uploaded from the pi user to use as the root user on the droplet. Set the hostname for the docker server. The name should be short and typeable, as it will become a part of the canononical service URLs. For this example, we choose sentry. Verify everything’s correct, and then click Create Dropet. Apply the DigitalOcean droplet firewall How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Find the firewall template you created, and click it. Click on the firewall’s Droplets tab. Click Add Droplets and search for the droplet you created and select it. Click Add Droplet to add the firewall to the droplet. Create wildcard DNS records for the droplet How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Click the Domains tab. Find the domain you created earlier, and click it. Create an A record for the sentry: Hostname: enter the subdomain name without the domain part (e.g., sentry, the name of your docker server, without the .example.com suffix). Will direct to: select the droplet you created from the list. Click Create Record. Create another A record, for the wildcard of the sentry: Hostname: enter the same name as before but prepend *. in front of it (e.g., if the server is named sentry, create a record for *.sentry, without the .example.com suffix). Will direct to: select the same droplet as before. Click Create Record. Create another A record, for the Raspberry Pi: Hostname: e.g., pi5.example.com. Will direct to to: select the same droplet as before. Click Create Record. Create another A record, for the wildcard of the Raspberry Pi: Hostname: e.g., *.pi5.example.com. Will direct to to: select the same droplet as before. Click Create Record. Create any more A records that you may need. Test DNS Test that your wildcard record actually works. Use the dig command (For Debian/Ubuntu install the dnsutils package. For Arch Linux install bind-tools. For Fedora install bind-utils.)\nPick some random subdomain off your domain:\n[bash]: Run this on your workstation: dig laksdflkweieri.sentry.example.com (stdout) ;; ANSWER SECTION: laksdflkweieri.sentry.example.com. 3600 IN A 153.114.12.78 Since you created the wildcard record for *.sentry.example.com dig should return your Docker server’s IP address in the ANSWER SECTION of the output. You can test all your other records the same way.\nIf you run into DNS caching problems, verify with the source DNS server directly:\n[bash]: Run this on your workstation: dig @ns1.digitalocean.com laksdflkweieri.sentry.example.com Next steps Install Docker Configure VPN ",
    "description": "Set up your SSH key on DigitalOcean How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Settings in the menu. Click on the Security tab. Click on the Add SSH Key button. Paste your public SSH key into the box. (copy the contents of ~/.ssh/id_ed25519.pub.) Enter a key name, I recommend this be the same as the hostname of your raspberry pi. Finish adding the key, click Add SSH Key.",
    "tags": [],
    "title": "Launch DigitalOcean droplet",
    "uri": "/portable-docker/set-up-cloud-sentry/launch-digitalocean-droplet/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up sentry Droplet",
    "content": "You now need to be able to control the droplet’s root user from the Raspberry Pi’s pi user. Create a new SSH config entry for the sentry (replace sentry.example.com with your own droplet’s DNS name):\nAppend to the SSH config on the Pi Run this on the Raspberry Pi cat \u003c\u003cEOF \u003e\u003e ~/.ssh/config Host sentry User root Hostname sentry.example.com ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p EOF Test the connection from the Pi to the sentry Run this on the Raspberry Pi ssh sentry whoami The first time you connect, you must confirm the host fingerprint (type yes):\n(stdout) The authenticity of host 'sentry' can't be established. ED25519 key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'pi5' (ED25519) to the list of known hosts. On the final line, it will print the output of the command you requested, which should print the username root :\n(stdout) root Create a new Docker context for the sentry Run this on the Raspberry Pi d context new (stdout) ? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y ? You must specify the SSH config entry to use \u003e I already have an SSH host entry in ~/.ssh/config that I want to use I want to make a new SSH host entry in ~/.ssh/config ? Choose an existing SSH Host config pi \u003e sentry \u003e Do you want to switch to the new sentry context now? Yes Install Docker on the sentry Run this on the Raspberry Pi d install-docker (stdout) ? This will install Docker on the host of your remote Docker context.. Proceed? Yes Test the docker context is functional Run this on the Raspberry Pi docker info | grep Context (stdout) Context: sentry Switch between Docker contexts You should now have two configured Docker contexts on your Pi:\npi sentry You can switch between these two contexts using d context. The currently selected context specifies which Docker server is currently being operated on.",
    "description": "You now need to be able to control the droplet’s root user from the Raspberry Pi’s pi user. Create a new SSH config entry for the sentry (replace sentry.example.com with your own droplet’s DNS name):\nAppend to the SSH config on the Pi Run this on the Raspberry Pi cat \u003c\u003cEOF \u003e\u003e ~/.ssh/config Host sentry User root Hostname sentry.example.com ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p EOF Test the connection from the Pi to the sentry Run this on the Raspberry Pi ssh sentry whoami The first time you connect, you must confirm the host fingerprint (type yes):",
    "tags": [],
    "title": "Configure the droplet on the Pi",
    "uri": "/portable-docker/set-up-cloud-sentry/set-up-docker-context/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Set up sentry Droplet",
    "content": "Ensure you use the correct Docker context Run this on the Raspberry Pi d context use sentry Run the main config The main config must be run for each new context you create:\n(stdout) \u003e This will make a configuration for the current docker context (sentry). Proceed? Yes ROOT_DOMAIN: Enter the root domain for this context (e.g., d.example.com) : sentry.example.com Run this on the Raspberry Pi d make - config Install Traefik This is a very similar process as when you installed Traefik on the Raspberry Pi:\nRun this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) Create the traefik user:\n(stdout) ? Traefik Configuration: \u003e Traefik user Configure ACME:\n(stdout) ? Traefik TLS config: Configure certificate authorities (CA) \u003e Configure ACME (Let's Encrypt or Step-CA) Configure TLS certificates (make certs) Choose Let’s Encrypt:\n(stdout) ? Which ACME provider do you want to use? \u003e Let's Encrypt (ACME) Step-CA (ACME) Disable ACME Cancel / Go back Choose the Production environment:\n(stdout) ? Which LE environment do you want to use? \u003e Production (recommended!) Staging (untrusted / testing) Choose the DNS-01 challenge type:\n(stdout) ? Which type of ACME challenge should be used? TLS-ALPN-01 (default for public servers, easy, but no wildcard certs) \u003e DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs) Find the provider code of your supported DNS provider here: https://go-acme.github.io/lego/dns/#dns-providers TRAEFIK_ACME_DNS_PROVIDER: Enter the LEGO code for your DNS Provider (e.g., digitalocean) : digitalocean Enter the variable name literal DO_AUTH_TOKEN:\n(stdout) TRAEFIK_ACME_DNS_VARNAME_1: Enter the 1st DNS provider variable name (e.g., DO_AUTH_TOKEN) : DO_AUTH_TOKEN TRAEFIK_ACME_DNS_VARNAME_2: Enter the 2nd DNS provider variable name (or leave blank) : Enter a blank for the second var name, because there isn’t one.\nNow enter the variable value for DO_AUTH_TOKEN (this should actually be the secret personal access token that you generate on DigitalOcean):\n(stdout) Now to enter the values for the custom DNS API variables: DO_AUTH_TOKEN: Enter the value for DO_AUTH_TOKEN (e.g., your-actual-digitalocean-token-here) : dop_v1_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Create a new TLS certificate:\n(stdout) ? Traefik TLS config: Configure certificate authorities (CA) Configure ACME (Let's Encrypt or Step-CA) \u003e Configure TLS certificates (make certs) ? Configure Traefik TLS certificates Manage all certificates. \u003e Create a new certificate. Done / Go back Enter the main domain (CN) for this certificate (e.g., `d.rymcg.tech` or `*.d.rymcg.tech`) : sentry.example.com Now enter additional domains (SANS), one per line: Enter a secondary domain (enter blank to skip) : *.sentry.example.com Enter a secondary domain (enter blank to skip) : Main domain: sentry.example.com Secondary (SANS) domains: *.sentry.example.com Install Traefik Press ESC three times to go back to the main menu.\nInstall Traefik:\n(stdout) ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) When done, press ESC to quit the Traefik config program.\nInstall whoami Run this on the Raspberry Pi d make whoami config (stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (e.g., whoami.example.com) : whoami.sentry.example.com ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) Run this on the Raspberry Pi d make whoami install Whoami on the sentry This instance of whoami runs on the droplet, and it is only to test the connectivity of the public droplet itself. We still have not yet exposed the whoami running on the Raspberry Pi publicly.\nWait a few minutes for the TLS certificate to generate Test the whoami instance You can open the page in w3m:\n[bash]: Run this on your workstation: d make whoami open Or test it with curl:\n[bash]: Run this on your workstation: curl https:://whoami.sentry.example.com Note that if the TLS certificate has not been issued yet, you will get this error from curl (and a similar error in w3m):\n(stdout) curl: (60) SSL certificate problem: self-signed certificate More details here: https://curl.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. Simply wait a bit longer for the TLS cert to issue, or check the logs for errors (d make traefik logs service=traefik). You can also tell curl to ignore the error:\n[bash]: Run this on your workstation: ## This is insecure, but fine for testing: curl -k https://whoami.sentry.example.com A valid whoami response page looks like similar to this:\n(stdout) Name: default Hostname: 52a9750ecaa4 IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:56082 GET / HTTP/1.1 Host: whoami.sentry.example.com User-Agent: curl/7.88.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: X.X.X.X X-Forwarded-Host: whoami.sentry.example.com X-Forwarded-Port: 443 X-Forwarded-Proto: https X-Forwarded-Server: sentry X-Real-Ip: X.X.X.X Next steps Configure the WireGuard VPN ",
    "description": "Ensure you use the correct Docker context Run this on the Raspberry Pi d context use sentry Run the main config The main config must be run for each new context you create: (stdout) \u003e This will make a configuration for the current docker context (sentry). Proceed? Yes ROOT_DOMAIN: Enter the root domain for this context (e.g., d.example.com) : sentry.example.com Run this on the Raspberry Pi d make - config Install Traefik This is a very similar process as when you installed Traefik on the Raspberry Pi:",
    "tags": [],
    "title": "Configure d.rymcg.tech for the sentry",
    "uri": "/portable-docker/set-up-cloud-sentry/configure-d-rymcg-tech-for-sentry/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": " Index Configure sentry wireguard server Configure Raspberry Pi WireGuard client ",
    "description": " Index Configure sentry wireguard server Configure Raspberry Pi WireGuard client ",
    "tags": [],
    "title": "Configure WireGuard VPN",
    "uri": "/portable-docker/configure-wireguard-tunnel/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Configure WireGuard VPN",
    "content": " Ensure you use the correct context Run this on the Raspberry Pi d context use sentry Reconfigure Traefik to enable WireGuard server Run this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ? Traefik routes Configure layer 7 TLS proxy Configure layer 4 TCP/UDP proxy \u003e Configure wireguard VPN ? Should this Traefik instance connect to a wireguard VPN? No, Traefik should use the host network directly. \u003e Yes, and this Traefik instance should start the wireguard server. Yes, but this Traefik instance needs credentials to connect to an outside VPN. ? Should Traefik bind itself exclusively to the VPN interface? \u003e No, Traefik should work on all interfaces (including the VPN). Yes, Traefik should only listen on the VPN interface. TRAEFIK_VPN_HOST: Enter the public Traefik VPN hostname (e.g., vpn.example.com) : sentry.example.com TRAEFIK_VPN_SUBNET: Enter the Traefik VPN private subnet (no mask) (e.g., 10.13.16.0) : 10.13.16.0 TRAEFIK_VPN_ADDRESS: Enter the Traefik VPN private IP address (e.g., 10.13.16.1) : 10.13.16.1 TRAEFIK_VPN_PORT: Enter the Traefik VPN TCP port number (e.g., 51820) : 51820 Enter the Traefik VPN peers list : pi Press ESC three times to back out of the main menu and quit the program.\nReconfigure Traefik to add a Layer 7 route to the Raspberry Pi Run this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ? Traefik routes \u003e Configure layer 7 TLS proxy Configure layer 4 TCP/UDP proxy Configure wireguard VPN \u003e Do you want to enable the layer 7 TLS proxy? Yes ? Layer 7 TLS Proxy: List layer 7 ingress routes \u003e Add new layer 7 ingress route Remove layer 7 ingress routes Disable layer 7 TLS Proxy Enter the public domain (SNI) for the route: : whoami.pi5.example.com Enter the destination IP address to forward to: : 10.13.16.2 Enter the destination TCP port to forward to: : 443 ## ## See https://www.haproxy.org/download/2.0/doc/proxy-protocol.txt \u003e Do you want to enable Proxy Protocol for this route? Yes ## Layer 7 TLS Proxy is ENABLED. ## Configured Layer 7 Routes: Entrypoint Destination_address Destination_port Proxy_protocol ---------- ------------------- ---------------- -------------- whoami.pi5.example.com 10.13.16.2 443 2 Press ESC multiple times to back out to the main menu. On the main menu, select Install, to re-install Traefik:\n(stdout) ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) Find the wireguard peer config You can check the wireguard service is now started:\nRun this on the Raspberry Pi d make traefik show-wireguard-peers (stdout) ## /config/peer_pi/peer_pi.conf [Interface] Address = 10.13.16.2 PrivateKey = 2E1vQHCS5JuaoRrt21GO0bYVrafOhplrGNFqoFBivEY= ListenPort = 51820 DNS = 10.13.16.1 [Peer] PublicKey = AZiNh/5sk71QTy6Rk0ygzIUsSGAX8/s3EeGN6lT9oj0= PresharedKey = tEIW8FuxR6I+Qu79bORatbD+JgNPeigNvc9V18f7to8= Endpoint = sentry.example.com:51820 AllowedIPs = 10.13.16.0/24 Copy the output you see into a tempory buffer / notepad, you will need to copy this information in the next chapter.",
    "description": "Ensure you use the correct context Run this on the Raspberry Pi d context use sentry Reconfigure Traefik to enable WireGuard server Run this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ?",
    "tags": [],
    "title": "Configure sentry wireguard server",
    "uri": "/portable-docker/configure-wireguard-tunnel/configure-sentry-wireguard-server/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Configure WireGuard VPN",
    "content": " Ensure you use the correct Docker context Run this on the Raspberry Pi d context use pi Reconfigure Traefik to enable WireGuard client Run this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ? Traefik routes Configure layer 7 TLS proxy Configure layer 4 TCP/UDP proxy \u003e Configure wireguard VPN ? Should this Traefik instance connect to a wireguard VPN? No, Traefik should use the host network directly. Yes, and this Traefik instance should start the wireguard server. \u003e Yes, but this Traefik instance needs credentials to connect to an outside VPN. ? Should Traefik bind itself exclusively to the VPN interface? \u003e No, Traefik should work on all host interfaces (including the VPN). Yes, Traefik should only listen on the VPN interface. TRAEFIK_VPN_CLIENT_INTERFACE_ADDRESS: Enter the wireguard client Interface Address (e.g., 10.13.16.2) : 10.13.16.2 TRAEFIK_VPN_CLIENT_INTERFACE_PRIVATE_KEY: Enter the wireguard PrivateKey (ends with =) : 2E1vQHCS5JuaoRrt21GO0bYVrafOhplrGNFqoFBivEY= TRAEFIK_VPN_CLIENT_INTERFACE_LISTEN_PORT: Enter the wireguard listen port (e.g., 51820) : 51820 TRAEFIK_VPN_CLIENT_PEER_PUBLIC_KEY: Enter the Peer PublicKey (ends with =) : AZiNh/5sk71QTy6Rk0ygzIUsSGAX8/s3EeGN6lT9oj0= TRAEFIK_VPN_CLIENT_PEER_PRESHARED_KEY: Enter the Peer PresharedKey (ends with =) : tEIW8FuxR6I+Qu79bORatbD+JgNPeigNvc9V18f7to8= TRAEFIK_VPN_CLIENT_PEER_ENDPOINT: Enter the Peer Endpoint (host:port) : sentry.example.com:51820 TRAEFIK_VPN_CLIENT_PEER_ALLOWED_IPS: Enter the Peer AllowedIPs (e.g., 10.13.16.1/32) : 10.13.16.1/32 Reinstall Traefik Press ESC twice to go back to the main menu, then re-install:\n(stdout) ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) Once reinstalled, press ESC to quit the config tool.\nTest VPN connectivity Check the logs:\nRun this on the Raspberry Pi d make traefik logs service=wireguard (stdout) wireguard-client-1 | 2024-09-28T08:42:09.445201647Z **** All tunnels are now active **** Enter the wireguard client shell to test networking parameters:\nRun this on the Raspberry Pi d make traefik shell service=wireguard-client Show the connected wireguard peers:\nRun this in the WireGuard Client shell wg Look for the last handshake time The output of wg should show the peer and the latest handshake time, for example:\nlatest handshake: 45 seconds agoIf you do not see a handshake time, then there is some kind of problem connecting to the WireGuard server that you need to resolve.\nPing the WireGuard server (10.13.16.1):\nRun this in the WireGuard Client shell ping -c3 10.13.16.1 When you are done using the shell press Ctrl-D or type exit to quit.\nCheck that whoami is available publicly In the last chapter you created a layer 7 route for the URL https://whoami.pi5.example.com. Now that your wireguard connection is active on both ends, this service should now be available publicly.",
    "description": "Ensure you use the correct Docker context Run this on the Raspberry Pi d context use pi Reconfigure Traefik to enable WireGuard client Run this on the Raspberry Pi d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ?",
    "tags": [],
    "title": "Configure Raspberry Pi WireGuard client",
    "uri": "/portable-docker/configure-wireguard-tunnel/configure-raspberry-pi-wireguard-client/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker",
    "content": " Index Immich Yourls ",
    "description": " Index Immich Yourls ",
    "tags": [],
    "title": "Install web services",
    "uri": "/portable-docker/install-web-services/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Install web services",
    "content": "Configure Immich Run this on the Raspberry Pi d context use pi d make immich config (stdout) IMMICH_TRAEFIK_HOST: Enter the Immich domain name (e.g., immich.example.com) : immich.pi5.example.com ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) ? Select the hardware acceleration to use for machine learning \u003e CPU ... ? Select the hardware acceleration to use for transcoding \u003e CPU ... ? Select whether you want Immich to upload images to a bind mount on the host or to a named Docker volume bind mount \u003e Docker volume Run this on the Raspberry Pi d make immich install wait Wait for the services to start and report themselves as healthy:\n(stdout) Waiting until all services are started and become healthy ... All services healthy. Add a new route on the sentry (droplet) Run this on the Raspberry Pi d context use sentry d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ? Traefik routes \u003e Configure layer 7 TLS proxy Configure layer 4 TCP/UDP proxy Configure wireguard VPN ? Layer 7 TLS Proxy: List layer 7 ingress routes \u003e Add new layer 7 ingress route Remove layer 7 ingress routes Disable layer 7 TLS Proxy Enter the public domain (SNI) for the route: : immich.pi5.example.com Enter the destination IP address to forward to: : 10.13.16.2 Enter the destination TCP port to forward to: : 443 \u003e Do you want to enable Proxy Protocol for this route? Yes ## Layer 7 TLS Proxy is ENABLED. ## Configured Layer 7 Routes: Entrypoint Destination_address Destination_port Proxy_protocol ---------- ------------------- ---------------- -------------- immich.pi5.example.com 10.13.16.2 443 2 whoami.pi5.example.com 10.13.16.2 443 2 Press ESC three times to go back to the main menu, and re-install Traefik:\n(stdout) ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) After installation, press ESC to quit the config tool.\nFinish The app is now deployed at the URL you configured: https://immich.pi5.example.com\nImmediately secure the admin account You should immediately open the URL in your web browser: https://immich.pi5.example.com and complete the initial configuration to secure the admin user account.",
    "description": "Configure Immich Run this on the Raspberry Pi d context use pi d make immich config (stdout) IMMICH_TRAEFIK_HOST: Enter the Immich domain name (e.g., immich.example.com) : immich.pi5.example.com ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) ? Select the hardware acceleration to use for machine learning \u003e CPU .",
    "tags": [],
    "title": "Immich",
    "uri": "/portable-docker/install-web-services/immich/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Portable Docker \u003e Install web services",
    "content": "Configure Yourls Run this on the Raspberry Pi d context use pi d make yourls config Follow the prompts to configure the domain name and admin user authentication.\n(stdout) YOURLS_TRAEFIK_HOST: Enter the YOURLS domain name (e.g., yourls.example.com) : yourls.pi5.forwarding.network ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) YOURLS_USER: Enter the admin username for your YOURLS instance : admin YOURLS_PASS: Enter the password for 'admin' : 528e0e36fc170 Choose your own a secure passphrase!\nRun this on the Raspberry Pi d make yourls install wait Wait for the services to start and report themselves as healthy:\n(stdout) Waiting until all services are started and become healthy ... All services healthy. Add a new route on the sentry (droplet) Run this on the Raspberry Pi d context use sentry d make traefik config (stdout) ? Traefik: \u003e Config Install (make install) Admin Exit (ESC) ? Traefik Configuration: ^ Entrypoints (including dashboard) TLS certificates and authorities Middleware (including sentry auth) \u003e Advanced Routing (Layer 7 / Layer 4 / WireGuard) Error page template Logging level Access logs ? Traefik routes \u003e Configure layer 7 TLS proxy Configure layer 4 TCP/UDP proxy Configure wireguard VPN ? Layer 7 TLS Proxy: List layer 7 ingress routes \u003e Add new layer 7 ingress route Remove layer 7 ingress routes Disable layer 7 TLS Proxy Enter the public domain (SNI) for the route: : yourls.pi5.example.com Enter the destination IP address to forward to: : 10.13.16.2 Enter the destination TCP port to forward to: : 443 \u003e Do you want to enable Proxy Protocol for this route? Yes ## Layer 7 TLS Proxy is ENABLED. ## Configured Layer 7 Routes: Entrypoint Destination_address Destination_port Proxy_protocol ---------- ------------------- ---------------- -------------- yourls.pi5.example.com 10.13.16.2 443 2 Press ESC three times to go back to the main menu, and re-install Traefik:\n(stdout) ? Traefik: Config \u003e Install (make install) Admin Exit (ESC) After installation, press ESC to quit the config tool.\nFinish Immediately secure the admin account You should immediately open the URL in your web browser: https://yourls.pi5.example.com/admin and complete the initial configuration to finsh installation.",
    "description": "Configure Yourls Run this on the Raspberry Pi d context use pi d make yourls config Follow the prompts to configure the domain name and admin user authentication. (stdout) YOURLS_TRAEFIK_HOST: Enter the YOURLS domain name (e.g., yourls.example.com) : yourls.pi5.forwarding.network ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) YOURLS_USER: Enter the admin username for your YOURLS instance : admin YOURLS_PASS: Enter the password for 'admin' : 528e0e36fc170 Choose your own a secure passphrase!",
    "tags": [],
    "title": "Yourls",
    "uri": "/portable-docker/install-web-services/yourls/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Using Org-mode and Emacs Navigating Org-mode files Editing Org-mode files Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Using Org-mode and Emacs Navigating Org-mode files Editing Org-mode files Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Publishing with org-mode",
    "uri": "/publishing-with-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": "Configure VM [bash]: Set temporary environment variables NAME=coreos-dev OS_VARIANT=fedora-coreos-stable CPUS=1 MEMORY=2048 DISK_SIZE=25 IP_ADDRESS=192.168.122.5 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') ISO_MEDIA=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-40-1.14.iso Write config file into libvirt user directory [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export ISO_MEDIA=${ISO_MEDIA} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \\ \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" \\ --live --config --parent-index 0 ",
    "description": "Configure VM [bash]: Set temporary environment variables NAME=coreos-dev OS_VARIANT=fedora-coreos-stable CPUS=1 MEMORY=2048 DISK_SIZE=25 IP_ADDRESS=192.168.122.5 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') ISO_MEDIA=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-40-1.14.iso Write config file into libvirt user directory [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export ISO_MEDIA=${ISO_MEDIA} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.",
    "tags": [],
    "title": "Configure VM with .iso boot",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/configure-vm/index.html"
  },
  {
    "breadcrumb": "",
    "content": " Info This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nBooks Linux Workstation Portable Docker: Build and Deploy Anywhere with WireGuard Tunneling Publishing with org-mode LICENSE Site features Navigation This website is presented as a book of books, so you can read everything from beginning to end. Use your keyboard left/right arrow keys to flip through the pages.\nKeyboard navigation If you are using a touch screen interface, use the arrow buttons at the top right of the page.\nTurn page buttons Table of contents The menu bar on the left contains the index of all the books, with the titles as top level headings. On smaller screens, you may need to expand this menu using the top left hamburger menu.\nHamburger menu shown on small screens only At the top left of every page (and just to the right of the sidebar), there is a button to show the outline of the current page.\nPage level table of contents Theme This website uses the Zen Light/Dark theme by default, which tracks your operating system and/or browser preference for light or dark mode. You can change the desired theme in the lower left menu, below the table of contents.\nChange theme Search Use the search box in the left hand menu to search all of the books on the site.\nSearch all books Blocks Shell command blocks Throughout these books, you will find literal command blocks that you should copy and paste to run in your Bash shell.\nCommands that are to be run on your primary workstation are in blue:\n[bash]: Run this on your workstation: whoami hostname Each code block is intended to be run as a whole (don’t copy individual lines). Click the Copy to clipboard button on the right hand side of every code block (it only shows up when your mouse cursor is hovering over it.)\nCopy entire block to clipboard Paste the copied command block into your terminal, edit it as necessary, and then press Enter to run it.\nYou will also sometimes see the example output that a command prints:\n(stdout) ryan toolbox Pay attention to the color and the title of the box to provide important context. Commands that are to be run on a different machine, or in a container, etc. are usually orange:\nRun this inside the container foo: whoami hostname (stdout) root foo Config blocks Temporary shell variables are used to carry common config values across multiple command blocks. You can copy and paste them just like you do when running a command, but they are used only for configuration before running another command:\n[bash]: Set temporary environment variables COLOR=orange FOOD=\"milk chocolate covered raisins\" Subsequent code blocks can reference these temporary variables:\n[bash]: Run this on your workstation: echo \"Favorite color : ${COLOR}\" echo \"Favorite food : ${FOOD}\" (stdout) Favorite color : orange Favorite food : milk chocolate covered raisins Edit file blocks Sometimes it’s easiest to edit a file by hand. These green blocks invite you to edit the given file, with your preferred text editor:\nEdit this file: /tmp/foo.txt this text goes into /tmp/foo.txt Use Bash 5.1+ [bash]: Run this on your workstation: $ bash --version | head -1 (stdout) GNU bash, version 5.2.26(1)-release The commands written in this book are tested with Bash version 5.2:\nBracketed Paste Since Bash 5.1, an important feature has been turned on by default: bracketed paste. This lets you copy and paste multi-line commands, from this web page, into your terminal, and edit the entire command directly on the command line, before anything is run. It gives you a chance to read, and edit, the entire command block that you paste, to be sure its all correct, before you run it. When you’re ready, you press the Enter key, and then the whole block is run. To cancel, press Ctrl-C.\nWhen you paste a block into Bash, it is automatically highlighted in inverse color. This should indicate to you that the command has not yet been run. You can edit the entire multiline code block, but you need to be careful, do not press the up or down arrow keys, because this will cancel the command and begin searching your command history instead. Use the linear left/right movement keys for readline mode: Left / Right arrow keys to move the cursor one character at a time. Ctrl + Left/Right arrow keys, move by words at a time. Ctrl-A moves the cursor to the very beginning of the block. Ctrl-E moves the cursor to the very end of the block. Ctrl-K will “kill” the text after the cursor. To cancel the command before running it, press Ctrl-C. To run the reviewed command, press Enter. Before Bash 5.1, unless you specifically turned this feature on, commands that you paste would be run immediately, which is such an insecure anti-feature for a default setting!\nWarning If you need to be running an old version of Bash, you should at least turn on bracketed paste:\n[bash]: Run this on your workstation: ## Only necessary for Bash \u003c 5.1: echo \"bind 'set enable-bracketed-paste on'\" \u003e\u003e ~/.bashrc bind 'set enable-bracketed-paste on' ",
    "description": "Info This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nBooks Linux Workstation Portable Docker: Build and Deploy Anywhere with WireGuard Tunneling Publishing with org-mode LICENSE Site features Navigation This website is presented as a book of books, so you can read everything from beginning to end. Use your keyboard left/right arrow keys to flip through the pages.",
    "tags": [],
    "title": "book.rymcg.tech",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).\nRead the Linux Workstation chapter for setting up Emacs.\nPlease note that your package manager may container an old version of Hugo that is incompatible with the Relearn theme. You can install the latest version of Hugo from the Hugo GitHub releases page.\nFor example, to download the X86_64 release of hugo v0.123.8:\n[bash]: Run this on your workstation: ## Do this if your package manager installs an old incompatible version of Hugo: HUGO_VERSION=0.123.8 cd ~/Downloads wget https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.tar.gz tar xfvz hugo_extended_${HUGO_VERSION}_linux-amd64.tar.gz sudo install hugo /usr/local/bin/hugo You will also need to clone the git source of this website to your workstation:\n[bash]: Run this on your workstation: git clone https://github.com/EnigmaCurry/org.git ~/git/vendor/enigmacurry/org ",
    "description": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).",
    "tags": [],
    "title": "Dependencies",
    "uri": "/publishing-with-org-mode/dependencies/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Create USB installation media Download Fedora Sway Atomic.iso Temporarily using another Linux workstation, write the .iso image to a USB drive:\nRun this on the computer that will write the USB sudo dd if=~/Downloads/Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your actual device name. If you don’t know the device name, run this:\n[bash]: Run this on your workstation: lsblk | grep disk (stdout) NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 1.8T 0 disk sdb 8:16 0 64G 0 disk You can probably make the identification of the device based upon the reported size, but if not, you can compare the list with the device plugged in, and again after unplugging it, and see which device is missing.\nDouble check the filename of the .iso file that you downloaded, it may have changed.\nTip If you are borrowing a Windows computer, then download a program like unetbootin to write the .iso to the USB.\nBoot the installer Boot the target workstation computer using the USB drive. It will boot into the Anaconda install wizard. Just follow the prompts to install it, it should be straight forward, and it is exactly the same as any other Fedora / Redhat install.\nTips:\nButtons may be in an unexpected position. Sometimes they are found in the bottom right corner, other times in the upper left corner. The installation summary page marks all the installaton items that you still need to configure. You can visit them in any order. Click the items that show an orange alert text, and do what it says. Choosing installation destination: Use the entire disk for the OS install (ie. choose Delete All partitions / Reclaim Space). On a secure workstation, it is considered unsafe to dual boot any another operating system. If you want to run Windows, or play games, use a separate computer for that. Enable whole disk encryption and choose a secure passphrase. Especially for laptop computers that you may travel with, this an important thing to do to keep your files safe at rest. Create a user account, and check the box Add administrative privileges to this user account (wheel group membership). Disable the root account. You will use a normal user account and sudo. Once all options are configured, click Begin Installation. Once the installer finishes, click Finish Installation. Reboot, remove the USB, enter your encryption passphrase to boot, and then log in to your new system.\nLogin and initial config Once you’re logged in, you need to perform these initial steps.\nNetwork Manager If you are connected to wired ethernet, likely your network is already active due to DHCP.\nIf you need to configure WiFi, find the NetworkManager applet in the top right corner of the default Sway desktop. Click on it, and drop down into the menu called Available networks and choose your WiFi access point.\nOpen a terminal Press Win+Enter to open a terminal window.\nSet Hostname By default, the hostname of the new workstation is fedora. If you want to change it, now is a good time:\n[bash]: Run this on your workstation: HOST=foo sudo hostnamectl set-hostname ${HOST} Close the terminal, press Ctrl+D. Open a new terminal, press Win+Enter. The new hostname should be reflected in the Bash prompt.\n(stdout) [ryan@foo ~]$ Open other apps like web browsers Press Win+D to open the drun menu. Type firefox and press Enter. To close a window, press Win+Shift+Q. ",
    "description": "Create USB installation media Download Fedora Sway Atomic.iso Temporarily using another Linux workstation, write the .iso image to a USB drive:\nRun this on the computer that will write the USB sudo dd if=~/Downloads/Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your actual device name. If you don’t know the device name, run this:\n[bash]: Run this on your workstation: lsblk | grep disk (stdout) NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 1.",
    "tags": [],
    "title": "Install Linux (Fedora Atomic)",
    "uri": "/linux-workstation/install/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "description": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "tags": [],
    "title": "Building locally",
    "uri": "/publishing-with-org-mode/building-locally/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from. The default is to boot the newly upgraded image.\nThe above will not upgrade to a new release version, eg. Fedora 39 to Fedora 40. It will only update the packages for the currently installed release.\nTo find the list of all released versions, run :\n[bash]: Run this on your workstation: ostree remote refs fedora | grep \"$(uname -m)/sericea$\" Upgrade to the new release (eg. 40):\n[bash]: Run this on your workstation: rpm-ostree rebase fedora:fedora/40/x86_64/sericea Let it finish downloading the new image, and then reboot again.",
    "description": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from.",
    "tags": [],
    "title": "Upgrading",
    "uri": "/linux-workstation/upgrading/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "See the Fedora docs for Adding Layered Packages.\nWarning On a Fedora Atomic host, you should only layer packages as a last resort. You should prefer running apps from a container (toolbox) instead. Layering packages should be reserved only for those applications that need to interact with the system in a way that using containers would be inconvenient or impossible.\nLayer packages with rpm-ostree To create efficient layers, and to lessen the burden of several reboots, you should try to install everything in one go, using as few layers as possible. Here is a list of packages you might want to add all together as one layer:\n[bash]: Run this on your workstation: sudo rpm-ostree install wdisplays qemu-kvm libvirt virt-manager \\ virt-viewer virt-install libvirt-daemon-config-network \\ libvirt-daemon-kvm libguestfs-tools python3-libguestfs virt-top \\ net-tools gvfs-smb gvfs-archive gvfs-nfs gvfs-fuse gvfs-mtp \\ distrobox file-roller thunar-volman pamu2fcfg pam-u2f fido2-tools Info Many of the subsequent chapters rely on these dependencies, so you should definitely install them if you are following this book completely.\nTip Fedora Atomic Sway edition (Sericea) already includes a lot of packages layered on top of the core Fedora Atomic. So before you install new things, check what comes preinstalled.\nSystem reboot is required to load new packages Everytime you install packages with rpm-ostree, you must reboot your system to load them:\n[bash]: Run this on your workstation: sudo systemctl reboot Examples of applications you might want to layer File explorer (thunar) plugins for archives and removeable drives. Virtual filesystem plugins (gvfs). Container tools (Distrobox). Virtual Machine tools (Qemu and libvirt). Basic network tools (net-tools arp) Web browsers are fickle. Although they mostly work inside toolbx containers just fine, Sericea includes Firefox in its base layer as a native app, and that seems to work great. However, I have also tested Chromium inside of a toolbx container without issue. For use cases where Chromium needs to have native USB access, you might not want to run it in a container.\nCheck the list of layers: [bash]: Run this on your workstation: sudo rpm-ostree status The top layer should list the LayeredPackages in your new layer.\nReboot.\nReset all layers back to stock Warning This will reset all the layered packages back to the stock image. This may be useful if you are trying to clean up from lots of testing.\nAll package layers will be destroyed!\nYour user home directories (/var/home/) and system configuration (/etc/) are not affected.\n[bash]: Run this on your workstation: sudo rpm-ostree reset sudo rpm-ostree cleanup -r sudo systemctl reboot ",
    "description": "See the Fedora docs for Adding Layered Packages.\nWarning On a Fedora Atomic host, you should only layer packages as a last resort. You should prefer running apps from a container (toolbox) instead. Layering packages should be reserved only for those applications that need to interact with the system in a way that using containers would be inconvenient or impossible.\nLayer packages with rpm-ostree To create efficient layers, and to lessen the burden of several reboots, you should try to install everything in one go, using as few layers as possible.",
    "tags": [],
    "title": "Layering packages",
    "uri": "/linux-workstation/layering-packages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "description": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "tags": [],
    "title": "Publishing with GitHub pages",
    "uri": "/publishing-with-org-mode/publish-with-github-pages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this. You must set all of the following details:\nThe unique name of the remote (eg. book) The hostname of the SFTP server (eg. sftp.example.com) The SFTP username, password, or SSH key, and whether to use the SSH agent (recommended!) The connection details are saved in your clone config file (eg. ~/.config/rclone/rclone.conf)\nThe included Makefile has a variable at the top called PUBLISH_RCLONE_REMOTE (default book). Make sure this is the same as the name of the rclone remote you configured (edit the Makefile if it is not).\nOnce everything is configured, simply run make publish to publish your site to the SFTP remote.\nYour webserver document root needs to be configured to use the same path that the SFTP server is configured for.\nIf you don’t have a webserver or SFTP server, you can use the following from d.rymcg.tech:\nSFTP server Nginx webserver ",
    "description": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this.",
    "tags": [],
    "title": "Publishing with SFTP",
    "uri": "/publishing-with-org-mode/publish-with-sftp/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": " Index Sway Firefox Toolbox Emacs SSH ",
    "description": " Index Sway Firefox Toolbox Emacs SSH ",
    "tags": [],
    "title": "Config",
    "uri": "/linux-workstation/config/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Solokeys are physical hardware authentication (U2F / FIDO2) devices, that you plug into a USB port, which stores a secret key that can be used as primary or secondary authentication factors (2FA), with websites (Webauthn), and machines (sudo and SSH).\nThere are two versions of solokey now, v1 and v2, and they require separate toolchains. The instructions diverge here depending on which hardware revision you have.\nIndex Get your Solokey Solokey v2 Solokey v1 Sudo with Solokey SSH with Solokey ",
    "description": "Solokeys are physical hardware authentication (U2F / FIDO2) devices, that you plug into a USB port, which stores a secret key that can be used as primary or secondary authentication factors (2FA), with websites (Webauthn), and machines (sudo and SSH).\nThere are two versions of solokey now, v1 and v2, and they require separate toolchains. The instructions diverge here depending on which hardware revision you have.\nIndex Get your Solokey Solokey v2 Solokey v1 Sudo with Solokey SSH with Solokey ",
    "tags": [],
    "title": "Solokey authentication",
    "uri": "/linux-workstation/sudo-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "Here are some tips on using Org-mode and Emacs.\nRead the Org manual Many of these tips are found in the Org Manual.\nIndex Navigating Org-mode files Editing Org-mode files ",
    "description": "Here are some tips on using Org-mode and Emacs.\nRead the Org manual Many of these tips are found in the Org Manual.\nIndex Navigating Org-mode files Editing Org-mode files ",
    "tags": [],
    "title": "Using Org-mode and Emacs",
    "uri": "/publishing-with-org-mode/org-mode-emacs/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "With strong authentication for sudo taken care of by Solokey, we can separate permissions for privileged data access, by creating additional user accounts.\nOne use case for this can be to control access to command line programs that store sensitive API tokens, via sudo.\nIndex DigitalOcean CLI (doctl) ",
    "description": "With strong authentication for sudo taken care of by Solokey, we can separate permissions for privileged data access, by creating additional user accounts.\nOne use case for this can be to control access to command line programs that store sensitive API tokens, via sudo.\nIndex DigitalOcean CLI (doctl) ",
    "tags": [],
    "title": "Application users",
    "uri": "/linux-workstation/app-users/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example Org / Hugo content",
    "uri": "/publishing-with-org-mode/examples/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.\nIt can contain any additional markup you want.",
    "description": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.",
    "tags": [],
    "title": "Example Org Blocks",
    "uri": "/publishing-with-org-mode/examples/org-blocks/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nInfo Fedora Sway Atomic is the new name for Fedora Sericea. You may still see valid references to Sericea, especially in the Fedora repository URLs.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.\nThe “Atomic” part refers to rpm-ostree, which was originally used by the CoreOS team to build an operating system that is built entirely to support containers. The root file system of an Atomic host is mounted read-only, and the packages are distributed in an image, rather than installed individually. This makes updating (or rolling back) the system far easier, and makes for a more stable environment. There is no need to replace packages one-by-one, you just download the new image provided by the distro, and then reboot the system to use it.\nThe base image includes all the typical things everyone needs: coreutils, a display manager, web browser, terminal apps etc. However, the base image is still pretty bare bones. Except for a few directories, the root filesystem is immutable, so the process of installing packages might be a bit different than what you are familar with.\nIf you want to install something that isn’t in the base image, you have a few different options:\nPodman or Docker containers (including toolbox and distrobox). Since containers use their own image, they are separate from the root image, and can be freely created and destroyed separately (no reboot).\nFlatpak is a type of application container that includes all of its dependencies, and it is sandboxed/isolated from the host system, therefore they can be installed/managed separately from the base image.\nUse rpm-ostree to create a new image layer. This extends the root atomic layer with extra packages that you want to install natively (not in a container). It bundles all of the requested packages into a new layer, and this is laid on top of the root atomic layer. The machine must boot the combined layers as one image, so therefore you must reboot the machine each time you install new packages this way.\nFor almost everything, I use Podman containers via toolbox and/or distrobox and these can even include graphical applications. Flatpak doesn’t appeal to me. For a few things that cannot be installed in a container, I have added them as an rpm-ostree layer.",
    "description": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nInfo Fedora Sway Atomic is the new name for Fedora Sericea. You may still see valid references to Sericea, especially in the Fedora repository URLs.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.",
    "tags": [],
    "title": "Fedora Sway Atomic",
    "uri": "/linux-workstation/introduction/fedora-sway-atomic/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Using Org-mode and Emacs",
    "content": "Navigating by search One of the easiest ways of navigating an Org document, isn’t even an Org feature. Just search for the text you’re looking for and jump right to it.\nPress C-s (or M-x isearch-forward) Of course, you might not always know the exact text (or it might not be unique enough to take you right there), so its useful to know some other ways of navigating Org documents.\nNavigating by headers Another great way to navigate your Org documents is by traversing the headers. My emacs config sets the default startup visibility to folded, so you can always get back to a folded state:\nPress C-u C-u TAB (or M-x org-set-startup-visibility) Cycle the visibility of the headers (foldedness):\nPress TAB to cycle the folding of the selected header (your cursor has to be on a header). Press C-u TAB to cycle the folding of the headers in the whole buffer (cursor can be anywhere). Press C-u C-u C-u TAB (or =M-x org-show-all) to show the entire buffer unfolded. If you’re in the middle of a paragraph, and want to move to the header of the current section:\nPress s-\u003cup\u003e (or C-c C-p or M-x org-previous-visible-heading) Press it again to go to the section before that, etc. To move to the next section:\nPress s-\u003cdown\u003e (or C-c C-n or M-x org-next-visible-heading) Moving to the next higher heading is very useful:\nPress C-c C-u (or M-x outline-up-heading). From the parent heading you get to see the outline of the outer context of what you’re currently writing about. From here you can press Tab twice to fold all all the sibling sections and get an overview.\nPress C-c C-u TAB TAB. Here are some other header movement commands:\nC-c C-f (M-x org-forward-heading-same-level) C-c C-b (M-x org-backward-heading-same-level) Jumping around (org-goto) You may frequently find yourself needing to jump around in a document, but don’t want to lose your current place.\nPress C-c C-j (or M-x org-goto). Mnemonic “jump”. Immediately press Enter to close the org-goto menu (theres advanced searching functions in there, but you ignore that for now). This will save your current place, allowing you to go find the place you need to temporarily go to.\nWhen you’re done, and you want to go back to to where you were:\nPress C-c \u0026. (or M-x org-mark-ring-goto). One mnemonic for \u0026 is that it is the same syntax for a C pointer reference.\nIndirect Buffers and Narrow To Subtree One of the advantages of Org-mode is you can organize lots of different articles into one big file. This is also a disadvantage when you are trying to focus on just one of them. It is easy to get lost.\nAs an example, open the other book named d.rymcg.tech.org (found in this same directory). Let’s say we want to focus on the chapter named Traefik Proxy.\nPress C-x 4 c. (or M-x clone-indirect-buffer-other-window). You now have two buffers open for the same file: d.rymcg.tech.org (the original) and d.rymcg.tech.org\u003c2\u003e (the clone), and you are automatically switched focus to the newly cloned buffer.\nRename the new buffer to traefik so you don’t get confused:\nPress C-x x r (or M-x rename-buffer). Type the new name: traefik. Now find the chapter you want to focus on:\nNavigate to the chapter heading named * Traefik Proxy, make sure your cursor is now somewhere on this line. Narrow the buffer to the selected subtree:\nPress C-x n s (or M-x org-narrow-to-subtree). You have now completed the process of narrowing the content of this buffer to only the Traefik Proxy article. It is important to know that the traefik buffer is still an indirect clone of the original d.rymcg.tech.org buffer, and they are both simultaneously editing the same underlying file. But now you know how to focus on a bite sized peice of a larger file. Go ahead and create more buffers to work on other parts you frequently need to focus on.\nIf you need to widen the buffer again:\nPress C-x n w (or M-x widen) ",
    "description": "Navigating by search One of the easiest ways of navigating an Org document, isn’t even an Org feature. Just search for the text you’re looking for and jump right to it.\nPress C-s (or M-x isearch-forward) Of course, you might not always know the exact text (or it might not be unique enough to take you right there), so its useful to know some other ways of navigating Org documents.",
    "tags": [],
    "title": "Navigating Org-mode files",
    "uri": "/publishing-with-org-mode/org-mode-emacs/navigating-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it. However, I use my own custom configuration that I replace it with, and you can do the same if you like.\nOpen the default terminal emulator (foot) with the keyboard shortcut: Win+Enter (hold down the “Windows” key on your keyboard, then simultaneously press Enter.)\nMy custom config replaces several of the default configuration files. So you must first get rid of these files, by renaming them with the suffix .orig for posterity:\n[bash]: Run this on your workstation: mv ~/.config ~/.config.orig mv ~/.bashrc ~/.bashrc.orig mv ~/.bash_profile ~/.bash_profile.orig Next, install my customized sway config repository :\n[bash]: Run this on your workstation: git clone https://github.com/enigmacurry/sway-home \\ ~/git/vendor/enigmacurry/sway-home Run the included setup script:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/sway-home ./setup.sh The setup.sh script will make symlinks to the repository files from the same original paths as the files you just moved. It also asks you some questions to help setup your git profile.\nOnce you have finished entering the information setup asks for, press Win+Shift+E, and choose Log Out. Log back in, and this will load the new config files.\nSetup display resolutions and orientation Fedora Sway Atomic ships with kanshi for display setup. Kanshi does not include any GUI for setting it up, so another program called wdisplays is useful.\nYou can configure all of your displays using the wdisplays GUI program, however, the configuration will not persist across login sessions. So what you need to do is set it up how you like it, and then transfer that information into the Kanshi config file so that it sets it up the same way everytime you login.\nFor example, on my test system I have two display port monitors, with outputs named DP-3 and DP-4. These are shown in wdisplays and I have set up the size, position, and DPI scaling exactly how I like it:\nDP-3:\nDP-4:\nOpen the Kanshi config file ~/.config/kanshi/config and copy the information into the config file:\nEdit this file: ~/.config/kanshi/config profile { output DP-3 enable mode 2560x1440 position 3840,0 scale 1 transform normal output DP-4 enable mode 3840x2160 position 1920,360 scale 2 transform normal } Check out man 5 kanshi for more config options. Kanshi is automatically started when sway is, so you can test it by logging out and logging back in.",
    "description": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it.",
    "tags": [],
    "title": "Sway",
    "uri": "/linux-workstation/config/sway/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Using Org-mode and Emacs",
    "content": "Hyperlinks To add hyperlinks to documents, I find it easiest to type the text first, and then add the link.\nType the link text. Navigate point to the last character of the link text. Press C-SPC (Control Spacebar) to mark the position. Navigate point to the first character of the link text. The link text should now be selected. Press C-c o i (or M-x org-insert-link). Enter the hyperlink URL. Absolute URLs should start with https://. Relative URLs can reference the root of the domain with /. Just remember, since all links are going through Hugo, links have to be in the context of what the web browser can find, not all local Org links are valid. ",
    "description": "Hyperlinks To add hyperlinks to documents, I find it easiest to type the text first, and then add the link.\nType the link text. Navigate point to the last character of the link text. Press C-SPC (Control Spacebar) to mark the position. Navigate point to the first character of the link text. The link text should now be selected. Press C-c o i (or M-x org-insert-link). Enter the hyperlink URL. Absolute URLs should start with https://.",
    "tags": [],
    "title": "Editing Org-mode files",
    "uri": "/publishing-with-org-mode/org-mode-emacs/editing-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.rymcg.tech d.rymcg.tech Cancel Math Math with MathJax:\n$$\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ Flowcharts --- title: Example Diagram --- graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{\u0026lt;strong\u0026gt;Decision\u0026lt;/strong\u0026gt;} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] Notices Notice This is a generic notice.\nThis is a bug notice.\nInfo This is an information box.\nTip This is a tip or pointer.\nWarning This is a warning.\nOpenAPI Visualize your API with swagger spec.",
    "description": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.",
    "tags": [],
    "title": "Example Shortcodes",
    "uri": "/publishing-with-org-mode/examples/shortcodes/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar. Select Settings.\nGeneral Settings Select Open previous windows and tabs Turn on Dark mode Turn off Recommend extensions as you browse Turn off Recommend features as you browse Home settings New Windows and Tabs Select Blank Page for both new windows and tabs.\nFirefox Home Content The home content won’t show if you set Blank Page above, but I go ahead and turn off all the home stuff anyway.\nSearch Settings Choose a non-Google default search engine, eg. DuckDuckGo. Turn off all Search Suggestions Delete all the corporate Search Shortcuts other than your preferred one (eg. DuckDuckGo). You can select each one and click Remove or you can press the Delete key. Delete Google, Amazon, Bing, eBay, Wikipedia etc.\nPrivacy \u0026 Security settings Enhanced Tracking Protection, select Strict Set Do Not Track to Always Logins and Passwords Unselect Suggest Firefox relay email masks\nUnselect Show alerts about passwords for breached websites (You already use unique passwords for every website, right??)\nIMPORTANT: select Use a Primary Password Without setting a primary password, any password that firefox saves will be unencrypted! You must set a primary (master) password, and you will need to type it in each time you restart your browser, to unlock the password manager.\nAddress Bar - Firefox Suggest Unselect Search engines\nUnselect Suggestions from the web\nUnselect Suggestions from sponsors\nFirefox Data Collection and Use Unselect everything here.\nHTTPs-Only mode Choose Enable HTTPS-Only Mode in all windows\nDNS over HTTPS Especially if you use a portable laptop, or connect to various WiFi access points, you should choose Max Protection.\nExtensions and Themes From the Settings menu, near the bottom, click Extensions \u0026 Themes.\nThemes Choose a theme you like. For example, click Dark and then click Enable.\nExtensions Go to addons.mozilla.org and install the following extensions:\nDark Reader\nDark reader makes all sites darker, and you can customize each site by clicking on the Dark Reader extension in the menu bar.\nUblock Origin\nDisables almost all ads on all websites. There’s not much to configure here, it basically works out of the box. However, you can customize it per site if you want to enable ads on certain pages.\nNoScript\nBy default, all sites will have javascript disabled. On each site you trust, you can customize the javascript availability by clicking the NoScript extension in the menu bar.\nNo Tabs\nIf you’re using a tiling window manager (Sway), you might consider disabling Firefox tabs, and have every site in its own window instead. This extension does that.\nVimium\nOnce vimium is installed, click the icon in the menu bar and click Enable all hosts permission.\nFirefox Multi-Account Containers\nRead about how to use Firefox Containers. Configure sites you trust to open in specific containers, that way you can save your cookies per container. By default, new sites will always open in temporary ones, and so when you close your browser all the cookies for that site disappears.",
    "description": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar.",
    "tags": [],
    "title": "Firefox",
    "uri": "/linux-workstation/config/firefox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "You will need the following hardware:\nAn x86_64 desktop or laptop computer to install to. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, sudo 2FA, and logging into websites with Webauthn.) ",
    "description": "You will need the following hardware:\nAn x86_64 desktop or laptop computer to install to. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, sudo 2FA, and logging into websites with Webauthn.) ",
    "tags": [],
    "title": "Requirements",
    "uri": "/linux-workstation/introduction/requirements/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Toolbox (Toolbx) is an integral part of Fedora Atomic, being one of the main methods of installing software, it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but it is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie. you can run ps or kill from inside the toolbox, and it will see/affect the host.) Toolbox containers are not sandboxed like normal Docker containers are, but they are a convenience for installing/removing software on Atomic hosts, since the host filesystem is read-only (but read-write inside of a container). The applications you install in the container will live only inside the toolbox.\nThe killer feature of a toolbox is that it lets you try things out, and if you want to start over, you can just delete the toolbox container, and create a new one. You are less likely to mess up the host by playing around inside the toolbox. Just remember that /home is bind mounted to the host, and so if you change or delete things in those directories, they are also affected the same way on the host.\nDev toolbox (Fedora) Let’s create a toolbox to install some of the common development tools we will use on a daily basis.\n[bash]: Run this on your workstation: toolbox create dev This will create a new toolbox container called dev.\nTo enter the toolbox run:\n[bash]: Run this on your workstation: toolbox enter dev This will enter the toolbox container, and now you can install extra software:\nRun this in the dev toolbox sudo dnf install keychain htop gettext libwebp-tools flatpak-xdg-utils sudo dnf groupinstall \"Development Tools\" \"Development Libraries\" sudo ln -s /usr/bin/flatpak-xdg-open /usr/local/bin/xdg-open By default, the container image toolbox selects is the image of Fedora Workstation, based upon the same version as the host (eg. If the host is running Fedora Atomic Sway 40, the toolbox will run Fedora Workstation 40.)\nArch Linux toolbox You are not limited to using the default toolbox image, in fact you can run any container image you want, or even build your own from a Dockerfile. Here is how to build a custom Arch Linux container image:\n[bash]: Run this on your workstation: IMAGE=arch (set -e mkdir -p ~/toolbox/${IMAGE} cat \u003c\u003c 'EOF' \u003e ~/toolbox/${IMAGE}/Dockerfile ## http://book.rymcg.tech/linux-workstation/config/toolbox/#arch-linux-toolbox FROM docker.io/archlinux/archlinux:latest ENV NAME=arch-toolbox VERSION=rolling LABEL com.github.containers.toolbox=\"true\" name=${IMAGE}-toolbox RUN pacman -Syu --noconfirm \\ \u0026\u0026 pacman -S --noconfirm sudo inetutils less \\ git base-devel go \\ noto-fonts noto-fonts-cjk \\ noto-fonts-emoji noto-fonts-extra \\ \u0026\u0026 pacman -Scc --noconfirm \\ \u0026\u0026 echo \"%wheel ALL=(ALL) NOPASSWD: ALL\" \u003e /etc/sudoers.d/toolbox RUN sudo -u nobody git clone https://aur.archlinux.org/yay-bin.git /tmp/yay \\ \u0026\u0026 cd /tmp/yay \\ \u0026\u0026 sudo -u nobody makepkg -s \\ \u0026\u0026 pacman -U --noconfirm yay-bin-*.pkg.tar.zst CMD [\"bash\"] EOF podman build -t ${IMAGE} ~/toolbox/${IMAGE} ) Now you can create a new toolbox based on the new image (both called arch):\n[bash]: Run this on your workstation: toolbox create --image arch arch To enter the Arch Linux container, run:\n[bash]: Run this on your workstation: toolbox enter arch Now that you’re inside the toolbox, you can run any Arch Linux command (consult the Arch Wiki).\nRun this inside the arch toolbox sudo pacman -Syu sudo pacman -S keychain base-devel Managing toolbox containers You can list all of your toolboxes that you’ve created:\n[bash]: Run this on your workstation: toolbox list You can remove existing toolboxes:\n[bash]: Run this on your workstation: toolbox rm --force arch (force is only required if the toolbox is currently running.)\nHost spawn host-spawn is a program you can install inside of a toolbox, to run commands on the host.\nInstall host-spawn inside Fedora container Run this in your toolbox container: sudo dnf install host-spawn Install host-spawn inside Arch Linux container Build and install host-spawn on Arch Linux (set -e BUILD_DIR=~/aur/host-spawn rm -f ${BUILD_DIR}/*.zst mkdir -p ${BUILD_DIR} cat \u003c\u003c 'EOF' \u003e ${BUILD_DIR}/PKGBUILD pkgname=host-spawn-git pkgver=v1.6.0.r0.ge150d2c pkgrel=1 pkgdesc='Run commands on your host machine from inside your flatpak sandbox, toolbox or distrobox containers.' arch=('any') url=\"https://github.com/1player/host-spawn\" license=('MIT-0') source=(\"${pkgname%-git}::git+https://github.com/1player/host-spawn.git\") depends=('go') makedepends=('git') conflicts=(\"${pkgname%-git}\") provides=(\"${pkgname%-git}\") package() { cd \"${pkgname%-git}\" ./build.sh $(uname -m) install -Dm 555 build/host-spawn-$(uname -m) \\ \"${pkgdir}\"/usr/bin/host-spawn } pkgver() { cd \"${pkgname%-git}\" git describe --long --tags | sed 's/\\([^-]*-g\\)/r\\1/;s/-/./g' } sha256sums=('SKIP') EOF cd ${BUILD_DIR} makepkg sudo pacman -U host-spawn-*.zst ) Run host programs Once you install host-spawn inside your container, you can use it to run any host command:\nRun this in your toolbox container: host-spawn toolbox list This will invoke toolbox on the host.\nCreate host program shims Run this in your toolbox container: sudo ln -s /usr/bin/host-spawn /usr/local/bin/toolbox sudo ln -s /usr/bin/host-spawn /usr/local/bin/podman sudo ln -s /usr/bin/host-spawn /usr/local/bin/flatpak This will allow you to run the host programs toolbox, podman and flatpak, from inside the container, without needing to run host-spawn directly.",
    "description": "Toolbox (Toolbx) is an integral part of Fedora Atomic, being one of the main methods of installing software, it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but it is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie.",
    "tags": [],
    "title": "Toolbox",
    "uri": "/linux-workstation/config/toolbox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).\nTo enable this, you need to be running your dev toolbox:\n[bash]: Run this on your workstation: toolbox enter dev Install Emacs:\nRun this inside the toolbox: sudo dnf install emacs Create Emacs script In order to be able to quickly launch Emacs inside the toolbox from the host, you will need a little script installed on the host.\nYou can create this script and put it in /usr/local/bin/emacs. Run this on the host (not in the toolbox), to create it as the root user:\n[bash]: Run this on your workstation: cat \u003c\u003c EOF | sudo tee /usr/local/bin/emacs #!/bin/bash ## Run Emacs in the dev toolbox and pass it any args: toolbox run -c dev emacs $@ EOF sudo chmod a+x /usr/local/bin/emacs Now you can run Emacs from the host, and it will run inside the Toolbox.\nInstall dependencies Most Emacs packages are written in Emacs Lisp, and therefore have no external dependencies. The one exception is for Vterm terminal support, which requires compiling a C library (libvterm). This compilation can be done automatically by Emacs, but it requires you have some tools preinstalled:\nCMake libtool Install the dependencies inside the toolbox:\nrun this inside the toolbox sudo dnf install cmake libtool Remove any existing Emacs config Assuming you want to use my Emacs config, you need to delete any existing config you already have. Also note that Emacs creates a default config the first time it runs, so if you started Emacs already, you may have a config and not even know it.\nHere’s how to remove the existing Emacs config:\n[bash]: Run this on your workstation: rm ~/.emacs ~/.emacs.d -rf Install my Emacs config My Emacs config is on github. Install it with the following script:\n[bash]: Run this on your workstation: REMOTE=https://github.com/EnigmaCurry/emacs.git REPO=${HOME}/git/vendor/enigmacurry/emacs BRANCH=straight (set -e test -d ~/.emacs.d \u0026\u0026 (echo \"~/.emacs.d already exists. Aborting install.\" \u0026\u0026 exit 1) test -d ${REPO} || git clone -b ${BRANCH} ${REMOTE} ${REPO} mkdir ~/.emacs.d \u0026\u0026 ls -1 ${REPO}/*.el | xargs -iXX ln -s XX ~/.emacs.d mkdir ~/.emacs.d/straight \u0026\u0026 ln -s ${REPO}/straight-versions ~/.emacs.d/straight/versions ln -s ${REPO}/snippets ~/.emacs.d/snippets ) Start Emacs to finish the installation The first time Emacs starts, it will install all of the dependencies listed in the main config file ~/.emacs.d/init.el.\nRun:\n[bash]: Run this on your workstation: emacs Wait for everything to install. You may see a blank screen for up to 10 minutes, but you should see some minimal information of the progress in the bottom minibuffer.\nIf it gets stuck at any point, quit and restart it, and it should continue where it left off. If you get any error message, you may want to start Emacs again with debug mode turned on:\n[bash]: Run this on your workstation: emacs --debug-init This will usually give you a more verbose error message which can be helpful in debugging the startup.\nRead the README for my config More notes are available in the README.",
    "description": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).",
    "tags": [],
    "title": "Emacs",
    "uri": "/linux-workstation/config/emacs-on-fedora/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client. Create a server that acts as a bastion or “jump” host, to be a port of entry into a larger private network. SSH is configured to only allow authorized client keys access through the bastion host. Create a server to act as an HTTP (socks) client proxy, to allow remote clients to browse the web, using the server’s IP address as the origin. Remote controlling a Docker server using the docker command line client (SSH Docker Context). SSH is based upon public key cryptography. Both the client and the server need to create their own public/private keypair. Keys can be encrypted on disk (eg. ~/.ssh/id_ecdsa) or they may also be loaded from a USB hardware token. Upon connecting to a remote server for the first time, the client asks the user to validate the server’s public key fingerprint, and then the server’s public key is written into a file called ~/.ssh/known_hosts, which marks the connection as trusted from then on. The server also authorizes the client through a predefined authorized_keys file. If either side rejects the key presented by the other, the connection is unauthorized, and is closed immediately.\nCreate SSH Keys This book recommends the use of hardware authentication tokens, like the Solokey. Traditional SSH keyfiles are also acceptable, but these should be considered as a legacy format, as they are less secure. Finally, plain password authentication (non-key based) is fully deprecated and should never be used.\nSetup Solokey (FIDO2) hardware authentication Plug in your Solokey (or compatible hardware) to the USB port.\nInitialize the hardware with a new SSH key:\n[bash]: Run this on your workstation: ## You only need to do this one time per solokey! ssh-keygen -t ed25519-sk -O resident -O verify-required You will be required to create/enter a PIN for the Solokey.\nTraditional SSH keyfiles The Solokey still has some drawbacks, and cannot be used in all cases. Traditional SSH keyfiles are still useful for automated and unattended clients. Technically, the solokey is supposed to be able to work in a “touchless” mode, by using the -O no-touch-required option, but I never got this to work.\nKey files should be created uniquely for each user and workstation. They should never be shared between multiple users or workstations.\nChoosing the SSH key type It is recommended to use the newer ed25519 key type, which uses the latest encryption standards. Your distribution may still use the older standard rsa by default (which is acceptable). You should explicitly select the key type when creating the keyfile to be sure.\nSome older servers don’t accpet ed25519 keys, and so in those cases you should still create an rsa key as well. Each key type is stored in a different file, so its OK to have multiple types installed on the same machine.\nCreate the new SSH keys Create the rsa key type:\n[bash]: Run this on your workstation: ssh-keygen -t rsa -f ~/.ssh/id_rsa Create the ed25519 key type:\n[bash]: Run this on your workstation: ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 You will be prompted to enter an encryption passphrase for each file, which you should definitely not skip!\nSetup the ssh-agent Because your keyfiles are encrypted with a passphrase, you need to enter the passphrase everytime you use it. This is inconvenient, so you can run ssh-agent to temporarily store your key/identity in memory, and therefore you only need to enter your passphrase once, when you log in. (In the case of the solokey, the key is never held in memory, but you still need to hold the identity of it in the ssh-agent.)\nKeychain is a program that helps you setup the ssh-agent. Install keychain in each of your toolboxes and/or workstations:\nRun this on your Fedora workstations: sudo dnf install keychain Run this on your Debian / Ubuntu workstations: sudo apt install keychain Run this on your Arch Linux workstations: sudo pacman -S keychain To configure keychain, edit your ~/.bashrc file:\nEdit this file: ~/.bashrc ## Put this line in your ~/.bashrc: ## (If you're using my config, this is already in it.) eval $(keychain --eval --quiet) Log out of your desktop session, and log back in. Open your terminal, and you should be automatically prompted to enter your SSH passphrase. Once you have entered the passphrase, the SSH key will remain resident in memory until you log out.\nDouble check that the key has been loaded, run:\nrun this inside your toolbox ssh-add -L The above should print your public key, loaded into the running ssh-agent. Now you should be able to use your key without entering a passphrase. Copy the output and upload it to your services as your authorized key. For servers, put the key into ~/.ssh/authorized_keys. For hosted services, like GitHub, paste the key into your SSH settings page.\nAdd your solokey identity per session Apparently, keychain does not yet know how to load the Solokey automatically. You must add the Solokey to the ssh-agent manually, one time, each time you boot your workstation:\nrun this inside your toolbox ## Do this to load your Solokey into the ssh-agent: ssh-add -K You will be prompted one time to enter your Solokey pin to unlock the key.",
    "description": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client.",
    "tags": [],
    "title": "SSH",
    "uri": "/linux-workstation/config/ssh/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Application users",
    "content": "doctl is the official DigitalOcean command line interface (CLI). It allows you to interact with the DigitalOcean API via the command line.\nYou should create a dedicated user for the doctl application, so that it can securely store the Personal Access Token for the DigitalOcean API. You can then access the privileged doctl command from your normal workstation account via sudo.\nCreate doctl user [bash]: Run this on your workstation: sudo useradd -s /bin/bash -m doctl Install doctl client Following the doctl install guide, install the doctl client directly in the home directory of the doctl user:\n[bash]: Run this on your workstation: DOCTL_VERSION=1.104.0 DOCTL_PLATFORM=linux-amd64 (set -e sudo curl -L -O --output-dir /usr/local/src https://github.com/digitalocean/doctl/releases/download/v${DOCTL_VERSION}/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz sudo tar -C ~doctl/ -x -f /usr/local/src/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz sudo ~doctl/doctl completion bash | sudo tee /etc/profile.d/doctl_completion.sh ) Create app alias for normal user account In your normal workstation account, create this alias in your ~/.bashrc (or ~/.bashrc.local) to make it more convenient to run doctl via sudo:\nEdit this file: ~/.bashrc ## DigitalOcean client (dotcl): DOCTL_SUDO=\"sudo -u doctl\" if command -v host-spawn \u003e/dev/null; then if [ -n \"${TOOLBOX_CONTAINER}\" ]; then DOCTL_HOME=$(host-spawn getent passwd doctl | cut -d: -f6) DOCTL_SUDO=\"host-spawn ${DOCTL_SUDO}\" else DOCTL_HOME=~doctl fi else DOCTL_HOME=~doctl fi alias doctl=\"${DOCTL_SUDO} ${DOCTL_HOME}/doctl\" ## Bash completion for dotcl: BASH_COMPLETION=/etc/profile.d/bash_completion.sh DOCTL_COMPLETION=/etc/profile.d/doctl_completion.sh test -f ${BASH_COMPLETION} \u0026\u0026 source ${BASH_COMPLETION} test -f ${DOCTL_COMPLETION} \u0026\u0026 source ${DOCTL_COMPLETION} Restart your terminal, and you can now use doctl from your normal account.\nCreate a Personal Access Token Read the offical documentation for creating tokens\nTokens allow programmatic access to the resources owned by a single Team.\nCreate a new Team, or choose an existing one. (If the domain name, or another resource you want to use, is already controlled by an existing team, choose that team). Create the new token for the team. Decide what scopes you want to allow the doctl user to access, or choose Full Access. Copy the token string to the clipboard. Register the client using the token, choose any context name (but it should reference your team name and/or role somehow):\n[bash]: Run this on your workstation: DOCTL_CONTEXT=my_team doctl auth init --context \"${DOCTL_CONTEXT}\" Use the doctl client Read the Self-hosting Docker book and setup a Docker server on DigitalOcean, using doctl.\nRead the doctl command reference.",
    "description": "doctl is the official DigitalOcean command line interface (CLI). It allows you to interact with the DigitalOcean API via the command line.\nYou should create a dedicated user for the doctl application, so that it can securely store the Personal Access Token for the DigitalOcean API. You can then access the privileged doctl command from your normal workstation account via sudo.\nCreate doctl user [bash]: Run this on your workstation: sudo useradd -s /bin/bash -m doctl Install doctl client Following the doctl install guide, install the doctl client directly in the home directory of the doctl user:",
    "tags": [],
    "title": "DigitalOcean CLI (doctl)",
    "uri": "/linux-workstation/app-users/digitalocean/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Install Solokey CLI (v1) tool Create Python environment for solokey [bash]: Run this on your workstation: SOLO_ROOT=~/git/vendor/solokeys (set -e git clone https://github.com/solokeys/solo1-cli \\ ${SOLO_ROOT}/solo1-cli ) Lock Fido2 version to 0.9.1 to fix outstanding bugs Warning Double check if these outstanding bugs are still open:\nhttps://github.com/solokeys/solo1-cli/issues/151 https://github.com/solokeys/solo1-cli/discussions/156 Both of these are related to Fido2 v1.0.0. If you lock the version to the last known good version of 0.9.1, it will work:\n[bash]: Run this on your workstation: sed -i 's/fido2 \u003e= 0.9.1/fido2 == 0.9.1/' ${SOLO_ROOT}/solo1-cli/pyproject.toml Build solo1 key environment [bash]: Run this on your workstation: python -m venv ${SOLO_ROOT}/env ${SOLO_ROOT}/env/bin/pip3 install -e ${SOLO_ROOT}/solo1-cli Create solo alias You can add this alias to your ~/.bashrc or ~/.bashrc.local:\nEdit this file: ~/.bashrc alias solo1=${HOME}/git/vendor/solokeys/env/bin/solo1 Restart your shell to load the new alias.\nUpdate your Solokey (v1) Plug your solokey into the USB port Identify your solokey [bash]: Run this on your workstation: solo1 ls (stdout) :: Solos AABBCC00112233: SoloKeys Solo 4.1.5 Update the firmware Check for the latest release of solo v1 and compare it to the version that is reported by solo ls. If your solokey is not running the latest version, it is recommended to update it.\nEnter bootloader mode:\n[bash]: Run this on your workstation: solo1 program aux enter-bootloader The solokey should now be rapidly flashing to indicate it is in boot loader mode.\nUpdate the firmware:\n[bash]: Run this on your workstation: solo1 key update (stdout) ... Congratulations, your key was updated to the latest firmware version: 4.1.5 Program your Solokey (v1) Reset solokey (recommended first time only) Warning This will wipe all identity from the solokey device!\n[bash]: Run this on your workstation: solo1 key reset Set device PIN [bash]: Run this on your workstation: solo1 key set-pin Tip This will only work if the device does not already have a pin (which is the state it is in after a reset).\nIf you want to change the PIN which was already set:\n[bash]: Run this on your workstation: solo1 key change-pin Verify PIN [bash]: Run this on your workstation: solo1 key verify (stdout) PIN: Please press the button on your Solo key Register valid Valid Solo with firmware from SoloKeys. ",
    "description": "Install Solokey CLI (v1) tool Create Python environment for solokey [bash]: Run this on your workstation: SOLO_ROOT=~/git/vendor/solokeys (set -e git clone https://github.com/solokeys/solo1-cli \\ ${SOLO_ROOT}/solo1-cli ) Lock Fido2 version to 0.9.1 to fix outstanding bugs Warning Double check if these outstanding bugs are still open:\nhttps://github.com/solokeys/solo1-cli/issues/151 https://github.com/solokeys/solo1-cli/discussions/156 Both of these are related to Fido2 v1.0.0. If you lock the version to the last known good version of 0.9.1, it will work:",
    "tags": [],
    "title": "Solokey v1",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Having sudo privileges enabled for your normal workstation user account is both a convenience and a security concern. The Pluggable Authentication Module for Linux (PAM) allows us to strengthen the requirements for using sudo, to include several authentication methods beyond just asking for a password. This chapter will install pam_u2f, which enables PAM authentication via FIDO2/U2F compatible hardware tokens like the Solokey. Each time sudo asks for authentication, it will prompt for a Solokey button press and a password to be entered.\nCREDITS Some of this guide was adapted from these other guides:\nUsing Solokeys with Fedora Using YubiKeys with Fedora Thank you to the Fedora documentation team!\nOpen a root session as an anti-lockout measure To prevent yourself from being locked out of your own system during the setup process, it is recommended to start a new terminal in a root session, and to keep it open. That way if you lock yourself out, you still have a way you can fix it.\n[bash]: Run this on your workstation: ## Open root session and leave it alone in another window .... sudo su Consider adding a root password If you use sudo a lot, you might not actually know the real root password of your system (or one might not even be set). As a backup, you may want to set a secure long random passphrase for the root user and keep it safe (you will rarely need it).\nWarning Reset the root password with a random string:\n[bash]: Run this on your workstation: (set -e LENGTH=26 PASSWORD=$(tr -dc 'A-Za-z0-9!@#$%^\u0026*()[]~+-_=?\u003c\u003e.,;:' \u003c /dev/urandom | head -c ${LENGTH}) echo -e \"\\nSave this ${LENGTH} character long password somewhere safe: ${PASSWORD}\\n\" read -e -p \"Do you want to reset the root password with this value (y/N)? \" answer (test \"${answer,,}\" == \"y\" || test \"${answer,,}\" == \"yes\") \u0026\u0026 \\ sudo sh -c \"echo 'root:${PASSWORD}' | chpasswd \u0026\u0026 echo Done.\" || \\ echo \"Cancelled.\" ) Test that the root password works without using sudo:\n[bash]: Run this on your workstation: su Register Solokeys It is recommended that you register at least two solokeys: a primary key, and a backup key. That way, if you lose one of the keys, you can still use the other one.\nTip Do the next steps as your normal workstation user account, which is the account that should already have sudo privileges.\nCreate a tempory file to capture solo key registrations:\n[bash]: Set temporary environment variables TMP_KEYS=$(mktemp) Plug in the first solokey, then run: [bash]: Run this on your workstation: pamu2fcfg \u003e\u003e ${TMP_KEYS} \u0026\u0026 \\ echo \u003e\u003e ${TMP_KEYS} It may ask you to enter the PIN of the solokey:\n(stdout) Enter PIN for /dev/hidraw1: When the solokey lights up, press the button.\nUnplug the first solokey and repeat the last command for the second solokey.\nUnplug the second solokey and repeat for additional solokeys.\nWhen you’ve written all the keys to ${TMP_KEYS}, reformat and install them into their final destination:\n[bash]: Run this on your workstation: echo \"${USER}:$(cat ${TMP_KEYS} | \\ cut -d \":\" -f 2 | tr '\\n' ':')\" | sed 's/:$//' | \\ sudo tee /etc/u2f_authorized_keys Create custom PAM modules for U2F You will create two new PAM modules: u2f-required and u2f-sufficient. They will both include these required settings:\nThe authfile path to our authorized key list file. The cue literal to show the Please touch the device prompt message for each authentication. (If you omit this, it will print nothing, which can be confusing). The only difference between the two PAM modules is that one is required, and the other is merely sufficient.\nrequired means to enable 2FA: solokey + password required. sufficient means to disable 2FA: solokey OR password is sufficient. [bash]: Run this on your workstation: cat \u003c\u003c EOF | sudo tee /etc/pam.d/u2f-required #%PAM-1.0 auth required pam_u2f.so authfile=/etc/u2f_authorized_keys cue EOF cat \u003c\u003c EOF | sudo tee /etc/pam.d/u2f-sufficient #%PAM-1.0 auth sufficient pam_u2f.so authfile=/etc/u2f_authorized_keys cue EOF Warning The PAM modules you just created (/etc/pam.d/u2f-required and /etc/pam.d/u2f-sufficient) can be used for extending any of the other pam modules found in /etc/pam.d, by adding an appropriate include line at the right place. This can affect many more system authentication methods than just sudo, so be careful, but only sudo will be covered for now.\nConfigure PAM hook for sudo As root, edit the file /etc/pam.d/sudo, and insert a new line directly after the #%PAM-1.0 header. A PAM module follows rules in top down order, as they are listed. Therefore your solokey rule needs to be the first authentication mechanism, and the existing password flow is the second authentication method.\nEdit this file: /etc/pam.d/sudo #%PAM-1.0 auth\tinclude u2f-required auth include system-auth account include system-auth password include system-auth session optional pam_keyinit.so revoke session required pam_limits.so session include system-auth Tip Line 2 (auth include u2f-required) is the only line that was added to this file. Everything else in this file was here originally and is left intact.\nWarning If you change u2f-required to u2f-sufficient, then it will disable 2FA allowing solokey press OR user password as sufficient!\nTest sudo Tip When testing sudo, always open a new terminal for each test. This is to avoid the auth caching mechanism (which is reset for new terminals).\n[bash]: Run this on your workstation: sudo su The PAM system should now ask for you to touch your solokey (or press the button), and afterward prompt for your password.\n(stdout) Please touch the device. [sudo] password for ryan: ",
    "description": "Having sudo privileges enabled for your normal workstation user account is both a convenience and a security concern. The Pluggable Authentication Module for Linux (PAM) allows us to strengthen the requirements for using sudo, to include several authentication methods beyond just asking for a password. This chapter will install pam_u2f, which enables PAM authentication via FIDO2/U2F compatible hardware tokens like the Solokey. Each time sudo asks for authentication, it will prompt for a Solokey button press and a password to be entered.",
    "tags": [],
    "title": "Sudo with Solokey",
    "uri": "/linux-workstation/sudo-2fa/sudo-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Follow the chapter on SSH config.",
    "description": "Follow the chapter on SSH config.",
    "tags": [],
    "title": "SSH with Solokey",
    "uri": "/linux-workstation/sudo-2fa/ssh-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": "Switch to the libvirt user account Info For the rest of this section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: xhost +local:libvirt-admin sudo -u libvirt-admin /bin/bash Tip The xhost line is to allow graphical apps (virt-viewer) from the other user appear on your display. You may need to play with xhost a few times to get it to work. Try xhost + to temporarily allow all hosts to use the DISPLAY (and xhost - afterward to set it back). If you start the VM, and the virt-viewer fails to load, you can just fix it, try it again, and reconnect to an existing VM already running in the background.\nSource the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=coreos-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Download the ISO image: Tip You only need to download each ISO_MEDIA once, they will be cached in ~/libvirt/iso, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/iso curl -LO ${ISO_MEDIA} chmod a-w $(echo ${ISO_MEDIA} | grep -Po \".*/\\K.*$\") ) Create virtual disk Run this as the libvirt-admin user qemu-img create -f qcow2 ~/libvirt/disks/${NAME}.qcow2 ${DISK_SIZE}G Start VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --graphics spice \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --boot cdrom,hd,menu=on \\ --disk ~/libvirt/disks/${NAME}.qcow2 \\ --cdrom ~/libvirt/iso/$(echo ${ISO_MEDIA} | grep -Po \".*/\\K.*$\") Boot Fedora Workstation Live environment Once the VM starts, the virt-viewer window should open and display the virtual console of the VM.\nChoose Start Fedora-Workstation-Live.\nWelcome Wait a minute for the Welcome screen to appear. To use the Live environment, click Not Now.\nPress Alt-F2 to run a command Open the terminal by pressing Alt-F2 and then typing the name of the command: gnome-terminal.\nGnome Terminal Verify network IP address Run this in the Fedora Live environment ip addr show dev enp1s0 | grep inet (stdout) ... inet 192.168.122.5/24 brd 192.168.122.255 scope global dynamic noprefixroute enp1s0 ... Enable remote SSH access Run this in the Fedora Live environment sudo systemctl enable --now sshd Set the live user password Run this in the Fedora Live environment passwd Leave the virt-viewer window alone You’re now done needing to use the graphical console of the live environment, but until you’re done setting things up, you’ll need to leave it running for the time being. For now, just hide the window in another workspace (or minimize the window) but leave it running.\nTip I have noticed that the Live environment is set to go to sleep after a period of inactivity. If it goes to sleep, you may need to move/click the mouse inside the virt-viewer window to wake it up again. There’s probably a great command to disable this, but I don’t know it yet..\nLeave the libvirt-admin shell You’re also done with the libvirt-admin shell for now, press Ctrl-D to leave it. Proceed now, back to using the normal workstation shell.",
    "description": "Switch to the libvirt user account Info For the rest of this section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: xhost +local:libvirt-admin sudo -u libvirt-admin /bin/bash Tip The xhost line is to allow graphical apps (virt-viewer) from the other user appear on your display. You may need to play with xhost a few times to get it to work.",
    "tags": [],
    "title": "Boot VM from .iso",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/install-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": " Tip These commands should be run on your normal workstation account.\nConfigure variables to connect to Live environment [bash]: Set temporary environment variables IP_ADDRESS=192.168.122.5 Copy SSH key to the liveuser [bash]: Run this on your workstation: ssh-copy-id liveuser@${IP_ADDRESS} When prompted, type the password that you set for the liveuser account.\nSSH into Live environment From your normal workstation account, connect to the SSH server of the Fedora Live environment:\n[bash]: Run this on your workstation: ssh liveuser@${IP_ADDRESS} Tip The reset of the commands in this section should be run in the Fedora Live environment.\nCreate Butane Config Butane is an intermediate tool used to generate the Ignition bootstrap file required for CoreOS.\nCreate a YAML config file that includes your public SSH keys:\nRun this in the Fedora Live environment (set -eo pipefail cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e fcos.yaml variant: fcos version: 1.5.0 passwd: users: ​ - name: core ssh_authorized_keys: EOF cat ~/.ssh/authorized_keys | xargs -iXX echo \" - XX\" \u003e\u003e fcos.yaml podman pull quay.io/coreos/butane:release podman run --rm --interactive \\ --security-opt label=disable \\ --volume ${PWD}:/pwd --workdir /pwd \\ quay.io/coreos/butane:release \\ --pretty --strict fcos.yaml \u003e fcos.ign ) Identify the storage device to install on Run this in the Fedora Live environment lsblk (stdout) NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS loop0 7:0 0 2G 1 loop loop1 7:1 0 8G 1 loop ├─live-rw 253:0 0 8G 0 dm / └─live-base 253:1 0 8G 1 dm loop2 7:2 0 32G 0 loop └─live-rw 253:0 0 8G 0 dm / sr0 11:0 1 2.1G 0 rom /run/initramfs/live zram0 251:0 0 956M 0 disk [SWAP] vda 252:0 0 25G 0 disk Tip For the default VM config, you can see the 25G device named vda.\n[bash]: Set temporary environment variables DEVICE=vda Install Fedora CoreOS onto the storage device Run this in the Fedora Live environment sudo podman run --pull=always --privileged --rm \\ -v /dev:/dev -v /run/udev:/run/udev -v .:/data -w /data \\ quay.io/coreos/coreos-installer:release \\ install /dev/${DEVICE} -i fcos.ign Shutdown Fedora Live environment CoreOS is now installed, so you can now shutdown the Fedora Live environment:\nRun this in the Fedora Live environment sudo poweroff This will immediately restart the VM and CoreOS should now boot. If successful you should see the console print the following information:\n(stdout) enp1s0: 192.168.122.5 .... Ignition: user-provided config was applied Ignition: wrote ssh authorized keys file for user: core Close virt-viewer window. Shutdown CoreOS VM [bash]: Set temporary environment variables NAME=coreos-dev [bash]: Run this on your workstation: sudo XDG_RUNTIME_DIR=/var/run/user/$(id -u libvirt-admin) -u libvirt-admin \\ virsh destroy ${NAME} Edit VM config Create an XSLT template that will perform the necessary edits to remove the CD-ROM disk and graphics adapter entries:\n[bash]: Run this on your workstation: cat \u003c\u003c EOF \u003e edit-coreos-vm.xslt.xml \u003cxsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\u003e \u003cxsl:output omit-xml-declaration=\"yes\"/\u003e \u003cxsl:template match=\"node()|@*\"\u003e \u003cxsl:copy\u003e \u003cxsl:apply-templates select=\"node()|@*\"/\u003e \u003c/xsl:copy\u003e \u003c/xsl:template\u003e \u003cxsl:template match=\"bootmenu[@enable='yes']\"/\u003e \u003cxsl:template match=\"boot[@dev='cdrom']\"/\u003e \u003cxsl:template match=\"disk[@device='cdrom']\"/\u003e \u003cxsl:template match=\"channel[@type='spicevmc']\"/\u003e \u003cxsl:template match=\"graphics\"/\u003e \u003cxsl:template match=\"sound\"/\u003e \u003cxsl:template match=\"audio\"/\u003e \u003cxsl:template match=\"redirdev[@type='spicevmc']\"/\u003e \u003cxsl:template match=\"video\"/\u003e \u003c/xsl:stylesheet\u003e EOF Redefine the VM using the edited config:\n[bash]: Run this on your workstation: (set -e virsh dumpxml ${NAME} | xsltproc edit-coreos-vm.xslt.xml - \u003e ${NAME}.xml virsh define ${NAME}.xml ) Enable systemd service to start VM [bash]: Run this on your workstation: sudo systemctl enable --now libvirt@${NAME} sudo systemctl status libvirt@${NAME} Create SSH config Create a Host entry in your ~/.ssh/config file to make connections easy:\nEdit this file: ~/.ssh/config Host coreos-dev Hostname 192.168.122.5 User core ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Remove the old host keys from the live user environment for your ~/.ssh/known_hosts file:\n[bash]: Run this on your workstation: ssh-keygen -R ${IP_ADDRESS} Test logging into the VM from your workstation:\n[bash]: Run this on your workstation: ssh coreos-dev Install Docker Docker comes preinstalled on CoreOS, you just have to enable it:\n[bash]: Run this on your workstation: ssh coreos-dev sudo gpasswd -a core docker ssh coreos-dev sudo systemctl enable --now docker Warning Because of the ControlMaster config, you will need to kill your existing connection to reload the session, and load new groups.\n[bash]: Run this on your workstation: ssh -O exit coreos-dev Then check your groups again, to be sure it includes docker:\n[bash]: Run this on your workstation: ssh coreos-dev groups (stdout) core adm wheel sudo systemd-journal docker Next, follow the Self-Hosting Docker book to setup this VM as a Docker context on your workstation.",
    "description": "Tip These commands should be run on your normal workstation account.\nConfigure variables to connect to Live environment [bash]: Set temporary environment variables IP_ADDRESS=192.168.122.5 Copy SSH key to the liveuser [bash]: Run this on your workstation: ssh-copy-id liveuser@${IP_ADDRESS} When prompted, type the password that you set for the liveuser account.\nSSH into Live environment From your normal workstation account, connect to the SSH server of the Fedora Live environment:",
    "tags": [],
    "title": "Bootstrap CoreOS",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/bootstrap-coreos/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": " Index Configure VM (cloud-init) Create VM (cloud-init) ",
    "description": " Index Configure VM (cloud-init) Create VM (cloud-init) ",
    "tags": [],
    "title": "Cloud-Init VMs",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Cloud-Init VMs",
    "content": "Choose a name [bash]: Set temporary environment variables NAME=debian-dev Choose hardware sizes [bash]: Set temporary environment variables MEMORY=1024 CPUS=2 DISK_SIZE=50 Choose cloud image You can choose any standard cloud image that supports cloud-init.\nDebian 12 [bash]: Set temporary environment variables OS_VARIANT=debian12 CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2 Tip On slighly older versions of libvirt, you may need to set OS_VARIANT differently, but the image should still work:\n[bash]: Set temporary environment variables OS_VARIANT=debian11\nFedora 40 [bash]: Set temporary environment variables OS_VARIANT=fedora40 CLOUD_IMAGE=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Cloud/x86_64/images/Fedora-Cloud-Base-Generic.x86_64-40-1.14.qcow2 Find the default subnet (virbr0) [bash]: Run this on your workstation: ip route | grep virbr0 | cut -d \" \" -f 1 (stdout) 192.168.122.0/24 Configure IP Address and MAC address [bash]: Set temporary environment variables IP_ADDRESS=192.168.122.2 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Tip You need to choose a valid IP_ADDRESS in the range of your subnet, although on every machine I’ve tried this on so far, the default has been 192.168.122.0/24. The MAC address will be randomized to create a static lease.\nCreate static DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Tip You can edit the file manually to do more cleanup. After editing, you must stop (destroy) and restart the network.\n[bash]: Run this on your workstation: sudo virsh net-edit default sudo virsh net-destroy default sudo rm /var/lib/libvirt/dnsmasq/virbr0.status sudo virsh net-start default sudo virsh net-dhcp-leases default Create env file to store main config settings [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export CLOUD_IMAGE=${CLOUD_IMAGE} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export USER_DATA=~/libvirt/cloud-init/${NAME}.yaml EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Tip This will create a new config file in the libvirt-admin user’s home directory ~/libvirt/${NAME}.env.",
    "description": "Choose a name [bash]: Set temporary environment variables NAME=debian-dev Choose hardware sizes [bash]: Set temporary environment variables MEMORY=1024 CPUS=2 DISK_SIZE=50 Choose cloud image You can choose any standard cloud image that supports cloud-init.\nDebian 12 [bash]: Set temporary environment variables OS_VARIANT=debian12 CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2 Tip On slighly older versions of libvirt, you may need to set OS_VARIANT differently, but the image should still work:\n[bash]: Set temporary environment variables OS_VARIANT=debian11\nFedora 40 [bash]: Set temporary environment variables OS_VARIANT=fedora40 CLOUD_IMAGE=https://download.",
    "tags": [],
    "title": "Configure VM (cloud-init)",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/config-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Raw disk VMs",
    "content": "Configure VM with raw disk image [bash]: Set temporary environment variables RAW_DISK=https://download.fedoraproject.org/pub/alt/iot/40/IoT/x86_64/images/Fedora-IoT-raw-40-20240422.3.x86_64.raw.xz NAME=fedora-iot OS_VARIANT=fedora40 MEMORY=2048 CPUS=2 DISK_SIZE=30 IP_ADDRESS=192.168.122.6 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Copy config to libvirt-user account [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export RAW_DISK=${RAW_DISK} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Tip This will create a new config file in the libvirt-admin user’s home directory ~/libvirt/${NAME}.env.",
    "description": "Configure VM with raw disk image [bash]: Set temporary environment variables RAW_DISK=https://download.fedoraproject.org/pub/alt/iot/40/IoT/x86_64/images/Fedora-IoT-raw-40-20240422.3.x86_64.raw.xz NAME=fedora-iot OS_VARIANT=fedora40 MEMORY=2048 CPUS=2 DISK_SIZE=30 IP_ADDRESS=192.168.122.6 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Copy config to libvirt-user account [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export RAW_DISK=${RAW_DISK} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"",
    "tags": [],
    "title": "Configure VM (raw disk)",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/config/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Cloud-Init VMs",
    "content": " Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=debian-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Create the cloud-init config file: Run this as the libvirt-admin user cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e ${USER_DATA} #cloud-config hostname: ${NAME} users: ​ - name: root ssh_authorized_keys: ​ - $(cat ~/libvirt/user-ssh.pub) EOF Download the cloud image: Tip You only need to download each CLOUD_IMAGE once, they will be cached in ~/libvirt/cloud-images, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/cloud-images curl -LO ${CLOUD_IMAGE} chmod a-w $(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*$\") ) Clean up old VMs with the same name: Warning If you already have a VM with the same name, and you want to start again from scratch, you need to clean up from the previous install first:\nRun this as the libvirt-admin user ## To cleanup and REMOVE an old VM named debian-dev: virsh destroy debian-dev virsh managedsave-remove debian-dev virsh undefine debian-dev Create the disk image for the new VM: Warning This is destructive of the existing disk file!\nRun this as the libvirt-admin user (set -e cp ~/libvirt/cloud-images/$(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*\") \\ ~/libvirt/disks/${NAME}.qcow2 chmod u+w ~/libvirt/disks/${NAME}.qcow2 qemu-img resize ~/libvirt/disks/${NAME}.qcow2 +${DISK_SIZE}G echo Created ~/libvirt/disks/${NAME}.qcow2 ) Create the VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --graphics none \\ --console pty,target_type=serial \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --cloud-init user-data=${USER_DATA} \\ --import \\ --disk ~/libvirt/disks/${NAME}.qcow2 Watch the console for any errors As the VM starts up, your terminal will attach to the console output of the VM. This is to monitor any errors that may occur during the bootup, especially relating to cloud-init.\nWait until you see this Login message:\n(stdout) debian-dev login: Disconnect from the VM console To disconnect from the VM console, press the keyboard combination Ctrl+] (meaning to hold the Control key and the right square bracket key at the same time.)\nShutdown the VM Info It is important to shut down the VM the first time after install, otherwise you will get an error about the unejected cloud-init ISO.\nRun this as the libvirt-admin usre virsh shutdown ${NAME} Verify VM is shut down Run this as the libvirt-admin user virsh list --all (stdout) ​ Id Name State ​----------------------------- ​ - debian-dev shut off Before proceeding to the next step, make sure the VM is in the off state.",
    "description": "Info For this entire section you need to perform the VM config as the libvirt-admin user. Login to the shell account of libvirt-admin: [bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file: Run this as the libvirt-admin user NAME=debian-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Create the cloud-init config file: Run this as the libvirt-admin user cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e ${USER_DATA} #cloud-config hostname: ${NAME} users: ​ - name: root ssh_authorized_keys: ​ - $(cat ~/libvirt/user-ssh.",
    "tags": [],
    "title": "Create VM (cloud-init)",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/create-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Raw disk VMs",
    "content": " Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=fedora-iot source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,raw,disks,cloud-init,iso} Download the raw disk: Tip You only need to download each RAW_DISK once, they will be cached in ~/libvirt/raw, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/raw curl -LO ${RAW_DISK} chmod a-w $(echo ${RAW_DISK} | grep -Po \".*/\\K.*$\") ) Create the disk image for the new VM: Warning This is destructive of the existing disk file!\nRun this as the libvirt-admin user (set -e xzcat ~/libvirt/raw/$(echo ${RAW_DISK} | grep -Po \".*/\\K.*\") \\ \u003e ~/libvirt/disks/${NAME}.raw chmod u+w ~/libvirt/disks/${NAME}.raw echo Created ~/libvirt/disks/${NAME}.raw ) Create the VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --graphics vnc,port=5901,listen=127.0.0.1 \\ --console pty,target_type=serial \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --import \\ --disk ~/libvirt/disks/${NAME}.raw,format=raw Watch the console for any errors As the VM starts up, your terminal will attach to the console output of the VM. This is to monitor any errors that may occur during the bootup, especially relating to cloud-init.\nWait until you see this Login message:\n(stdout) debian-dev login: Disconnect from the VM console To disconnect from the VM console, press the keyboard combination Ctrl+] (meaning to hold the Control key and the right square bracket key at the same time.)\nShutdown the VM Info It is important to shut down the VM the first time after install, otherwise you will get an error about the unejected cloud-init ISO.\nRun this as the libvirt-admin usre virsh shutdown ${NAME} Verify VM is shut down Run this as the libvirt-admin user virsh list --all (stdout) ​ Id Name State ​----------------------------- ​ - debian-dev shut off Before proceeding to the next step, make sure the VM is in the off state.",
    "description": "Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=fedora-iot source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,raw,disks,cloud-init,iso} Download the raw disk: Tip You only need to download each RAW_DISK once, they will be cached in ~/libvirt/raw, so they can be be reused.",
    "tags": [],
    "title": "Create VM (raw disk)",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/create-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Idealistically, the introduction declared a “No Sworkstations” rule (No Server-Workstations). Pragmatically, you can bend this rule a bit, by hosting some development servers inside of virtual machines (VM). Hosting VMs on your workstation is convenient for having a portable lab environment. By using virtual machines for all services, we get to maintain our core distinction between the roles of workstation and server.\nThis paradigm is considerably more adhoc than a proper hypervisor operating system like Proxmox. For pure server installs, Proxmox should be preferred. But if you want to have a mixed-mode native workstation, with extra server VMs, in the same portable platform, this setup works really well.\nUsing this config, your workstation will stay relatively pure, because these VMs are isolated from your normal account. They are automatically started on boot, running under a dedicated VM user account (libvirt-admin). You can treat these VMs just like any other remote Linux host. From your normal workstation account, you can access the VM’s root shell, over (local) SSH connection, and you can remotely install Docker on these target VMs.\nThese instructions will cover installing libvirt, and creating a barebones Debian or Fedora VM (but any cloud-init image should work), inside of a private host-only network (No public ports are open by default, but outgoing internet access is allowed). This is mainly for local development/testing purposes only, but near the end of this chapter, you’ll get to decide if you’d like to bend this rule too, and open the VMs up to public (LAN) routes for production-lite roles.\nGuest OS compatibility The following guest Linux distributions, have been tested as working:\n✅ Debian 12 cloud image ✅ Fedora 40 cloud image ✅ Ubuntu 24.04 cloud image These instructions should work for any operating system that is shipped as a “Cloud” image (Cloud-Init image).\nHost workstation compatibility The following host Linux distributions, have been tested as working (only x86_64 tested so far):\n✅ Fedora Atomic Workstation (40) ✅ Fedora Server (40) ✅ Fedora CoreOS (40) ✅ Arch Linux The following host Linux distributions have some issues:\n🚧 Debian (12) hosts are only partially compatible, I have not been able to get the autostart service to run, due to an app armor permission issue, however the VMs do run if you start them manually. Index Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config ",
    "description": "Idealistically, the introduction declared a “No Sworkstations” rule (No Server-Workstations). Pragmatically, you can bend this rule a bit, by hosting some development servers inside of virtual machines (VM). Hosting VMs on your workstation is convenient for having a portable lab environment. By using virtual machines for all services, we get to maintain our core distinction between the roles of workstation and server.\nThis paradigm is considerably more adhoc than a proper hypervisor operating system like Proxmox.",
    "tags": [],
    "title": "KVM / libvirt",
    "uri": "/linux-workstation/kvm-libvirt/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "If you OS is not packaged as a cloud-init enabled image, you can boot a raw disk image instead. The example will install Fedora IoT (40) from raw disk image.\nIndex ",
    "description": "If you OS is not packaged as a cloud-init enabled image, you can boot a raw disk image instead. The example will install Fedora IoT (40) from raw disk image.\nIndex ",
    "tags": [],
    "title": "Raw disk VMs",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example of a deeply …",
    "uri": "/publishing-with-org-mode/examples/deeply/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "Systemd services can provide an easy way to manage the on/off state of the VMs (systemctl start/stop), and can (optionally) start VMs automatically when the host system boots.\nWarning libvirt has its own autostart feature, but we’re not using that, because I couldn’t get it to work in user session mode. Systemd units per VM feels nicer anyway.\nDownload libvirt python interface Tip You should now be in your normal workstation account Bash shell.\n[bash]: Run this on your workstation: (set -e sudo mkdir -p /usr/local/src/ sudo su -c \"cd /usr/local/src \u0026\u0026 git clone https://github.com/EnigmaCurry/virsh-start-stop\" ) CREDITS EnigmaCurry/virsh-start-stop is my own fork of avollmerhaus/virsh-start-stop which has been slightly customized for this configuration. Thank you to avollmerhaus for creating this service manager!\nCreate Unit template This is an instantiable template used for all VM services:\n[bash]: Run this on your workstation: VM_ADMIN=${VM_ADMIN:-libvirt-admin} cat \u003c\u003c EOF | sudo tee /etc/systemd/system/libvirt@.service [Unit] Description=${VM_ADMIN} VM: %i Requires=libvirtd.service After=libvirtd.service [Service] Type=oneshot RemainAfterExit=true User=${VM_ADMIN} Group=libvirt Environment=\"XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})\" ExecStart=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state started ExecStop=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state stopped [Install] WantedBy=default.target EOF Enable each VM service This will instantiate the VM service template, and enable a VM named debian-dev, which will automatically start on workstation boot:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl enable --now libvirt@${NAME} sudo systemctl status libvirt@${NAME} ",
    "description": "Systemd services can provide an easy way to manage the on/off state of the VMs (systemctl start/stop), and can (optionally) start VMs automatically when the host system boots.\nWarning libvirt has its own autostart feature, but we’re not using that, because I couldn’t get it to work in user session mode. Systemd units per VM feels nicer anyway.\nDownload libvirt python interface Tip You should now be in your normal workstation account Bash shell.",
    "tags": [],
    "title": "Systemd services to control VMs",
    "uri": "/linux-workstation/kvm-libvirt/systemd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "By default, all incoming traffic to the VMs must originate from your workstation (or another VM on your workstation) - no traffic is routed to your VMs from any other interface.\nIf you want to break this rule, and allow public routes into these VMs (DNAT port forwarding), you will need to install the libvirt hook that sets up the iptables forwarding rules:\nDownload the port-forwarding hook [bash]: Run this on your workstation: sudo mkdir -p /usr/local/src/ sudo su -c \"cd /usr/local/src \u0026\u0026 git clone https://github.com/EnigmaCurry/libvirt-hook-qemu.git\" CREDITS EnigmaCurry/libvirt-hook-qemu is my own fork of saschpe/libvirt-hook-qemu which has been slightly customized for this configuration. Thank you to Sascha Peilicke for creating this hook!\nInstall the hook files [bash]: Run this on your workstation: sudo mkdir -p /etc/libvirt-dnat-hook sudo cp /usr/local/src/libvirt-hook-qemu/hooks.schema.json /etc/libvirt-dnat-hook Set config variables Set some temporary variables the same as from your config:\n[bash]: Set temporary environment variables NAME=debian-dev IP_ADDRESS=192.168.122.2 Customize the port-forwarding hook Use the example and schema as a reference, then setup the port mapping you want for each VM:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} IP_ADDRESS=${IP_ADDRESS:-192.168.122.2} cat \u003c\u003c EOF | jq | sudo tee /etc/libvirt-dnat-hook/hooks.json { \"${NAME}\": { \"interface\": \"virbr0\", \"private_ip\": \"${IP_ADDRESS}\", \"port_map\": { \"tcp\": [ [2222, 22], [80, 80], [443, 443] ] } } } EOF Tip This example opens the following public ports:\nPublic TCP port 2222 forwards to the VM’s port 22. Public TCP port 80 forwards to the VM’s port 80. Public TCP port 443 forwards to the VM’s port 443. UDP ports need to be in their own section, a sibling of TCP. Each VM needs its own config, mapped at the top level by the VM’s unique name.\nAutostart port-forwarding script on boot I have not figured out how libvirt hooks are supposed to work with user-mode VMs. It seems like when the VM starts, the hook never gets called. So, this section adds another service that triggers the hook manually on boot to setup the port forwarding for each VM.\nCreate DNAT service template [bash]: Run this on your workstation: VM_ADMIN=${VM_ADMIN:-libvirt-admin} cat \u003c\u003c EOF | sudo tee /etc/systemd/system/libvirt-DNAT@.service [Unit] Description=${VM_ADMIN} VM: %i - DNAT port forwarding Requires=libvirt@%i.service Requires=network-online.target After=libvirt@%i.service After=network-online.target [Service] Type=oneshot RemainAfterExit=true Environment=\"XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})\" Environment=\"CONFIG_PATH=/etc/libvirt-dnat-hook\" ExecStart=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i start ExecStop=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i stopped [Install] WantedBy=multi-user.target EOF sudo systemctl daemon-reload Enable DNAT service once per VM you want to expose [bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl enable --now libvirt-DNAT@${NAME}.service sudo systemctl status libvirt-DNAT@${NAME}.service Stopping and/or Disabling the service If you want to disable the port mapping, run:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl disable --now libvirt-DNAT@${NAME}.service Or to temporarily stop the port mapping (until you run start or reboot):\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl stop libvirt-DNAT@${NAME}.service Reboot workstation Once rebooted, test that your port forward rule exists in iptables rules:\n[bash]: Run this on your workstation: sudo iptables-save | grep 2222 (stdout) -A DNAT-debian-dev -d 10.13.13.227/32 -p tcp -m tcp --dport 2222 -j DNAT --to-destination 192.168.122.2:22 -A SNAT-debian-dev -s 192.168.122.2/32 -d 192.168.122.2/32 -p tcp -m tcp --dport 2222 -j MASQUERADE ",
    "description": "By default, all incoming traffic to the VMs must originate from your workstation (or another VM on your workstation) - no traffic is routed to your VMs from any other interface.\nIf you want to break this rule, and allow public routes into these VMs (DNAT port forwarding), you will need to install the libvirt hook that sets up the iptables forwarding rules:\nDownload the port-forwarding hook [bash]: Run this on your workstation: sudo mkdir -p /usr/local/src/ sudo su -c \"",
    "tags": [],
    "title": "Public routes to VMs",
    "uri": "/linux-workstation/kvm-libvirt/public-routes/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": " Info For this section, you are back to using your normal workstation user.\nAppend a new host config into your SSH config (~/.ssh/config):\nEdit this file: ~/.ssh/config Host debian-dev Hostname 192.168.122.2 User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Info Make sure Host and Hostname are set correctly for your VM.\nWith this config, you can now use SSH to control the VM:\n[bash]: Run this on your workstation: ssh debian-dev whoami (stdout) root Install Docker You’re now ready to use your VM as an install target for whatever you want. It is recommended to install Docker, which you can learn about in the volume Self-hosting Docker in the chapter called Setup your workstation.",
    "description": "Info For this section, you are back to using your normal workstation user.\nAppend a new host config into your SSH config (~/.ssh/config):\nEdit this file: ~/.ssh/config Host debian-dev Hostname 192.168.122.2 User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Info Make sure Host and Hostname are set correctly for your VM.\nWith this config, you can now use SSH to control the VM:\n[bash]: Run this on your workstation: ssh debian-dev whoami (stdout) root Install Docker You’re now ready to use your VM as an install target for whatever you want.",
    "tags": [],
    "title": "Setup workstation SSH config",
    "uri": "/linux-workstation/kvm-libvirt/setup-workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply …",
    "content": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Nested …",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "The previous section named Create VM (cloud-init) installed a VM from a cloud-init enabled image (colloquially known as a “cloud image”), which is the streamlined and preferred method of VM installation. However, not all Linux distributions have a cloud image available. You may need to manually install the OS using a traditional graphical installer. Thats what this section is all about.\nAs an example, these are the steps to install a VM using Fedora CoreOS (which does not support cloud-init, nor a traditional installer). You will be using the graphical Fedora Workstation Live .iso image as a temporary OS to bootstrap CoreOS onto a blank virtual disk.\nIndex ",
    "description": "The previous section named Create VM (cloud-init) installed a VM from a cloud-init enabled image (colloquially known as a “cloud image”), which is the streamlined and preferred method of VM installation. However, not all Linux distributions have a cloud image available. You may need to manually install the OS using a traditional graphical installer. Thats what this section is all about.\nAs an example, these are the steps to install a VM using Fedora CoreOS (which does not support cloud-init, nor a traditional installer).",
    "tags": [],
    "title": "Create VM from .iso image",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "description": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "tags": [],
    "title": "Sub-chapter 1",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter1/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 2",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter2/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 3",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter3/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Firewalld Firewalld is an abstraction of nftables (which is an abstraction of netfilter). Firewalld is installed on Fedora systems by default, and it is what is used to configure the system firewall.\nFirewalld rules are grouped into zones. There can be multiple zones, and you may switch between them. There can only be one active zone per network interface.\nDon’t mess with it Warning Fedora Atomic installs a good default zone for workstation use, named public. Theres really nothing more for you to do here. This chapter will mostly discuss things you should NOT change on a workstation, but this is a general guide as to how these things work, and how to modify the rules if the need should arise.\nIf you are running virtual machines, these use a different interface virbr0, and so they use a different zone named libvirt. The VM routes are configured separately. Read the chapter Public routes to VMs.\nDefault Zone Firewalld lets you configure multiple zones, which are segmented realms for different network activity or locations (for example, there are predefined zones for home and work).\nCheck out the default zones of the system:\n[bash]: Run this on your workstation: firewall-cmd --get-active-zones (stdout) libvirt interfaces: virbr0 public (default) interfaces: enp4s0 This shows two active zones, one per interface:\npublic, which it mentions is the default, is attached to the primary network interface enp4s0. libvirt, which is all the libvirt rules defined for VMs, and only listening on the libvirt network interface virbr0. Changing the default zone Tip As long as you don’t need multiple zones, it’s recommended to use the default public zone. But here is how you can switch zones if you need to change it to something else (eg. work):\n[bash]: Run this on your workstation: ZONE=work sudo firewall-cmd --set-default-zone ${ZONE} This change is permanent, until you change it again.\nZone files On Fedora Atomic, there are two directories that contain firewalld zone files:\n/etc/firewalld/zones this is the primary zone directory, and it takes precedence. The directory is empty by default. /usr/lib/firewalld/zones/ this is the secondary read-only default zone directory. The files here are loaded only if the primary zone directory is missing a file with the same name. Public zone Look at the default public zone file:\n[bash]: Run this on your workstation: cat /usr/lib/firewalld/zones/public.xml (stdout) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003czone\u003e \u003cshort\u003ePublic\u003c/short\u003e \u003cdescription\u003eFor use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.\u003c/description\u003e \u003cservice name=\"ssh\"/\u003e \u003cservice name=\"mdns\"/\u003e \u003cservice name=\"dhcpv6-client\"/\u003e \u003cforward/\u003e \u003c/zone\u003e You can find out what these services are by grepping /etc/services:\n[bash]: Run this on your workstation: cat /etc/services | grep -P \"^(dhcpv6-client|ssh|mdns) \" | sort -u (stdout) dhcpv6-client 546/tcp dhcpv6-client 546/udp mdns 5353/tcp # Multicast DNS mdns 5353/udp # Multicast DNS ssh 22/sctp # SSH ssh 22/tcp # The Secure Shell (SSH) Protocol ssh 22/udp # The Secure Shell (SSH) Protocol So that means that the only incoming ports that are allowed are:\nSSH (port 22, but only if you enable the SSH service.) multicast (broadcast) DNS (port 5353) IPV6 link-local DHCP (port 546) Test blocked ports Start a local netcat server on port 5000 (which is blocked by default):\n[bash]: Run this on your workstation: nc -l 5000 Tip Leave the nc server running, and open another terminal window to continue on. When you are done testing, press Ctrl-C to quit nc.\nFrom another machine, on the same network, try connecting to the blocked port 5000 on the workstations LAN ip address:\nRun this on another machine on the same network WORKSTATION=192.168.1.10; nc ${WORKSTATION} 5000 It should immediately exit (return 1), and print nothing, because the port is blocked.\nAdding a temporary rule [bash]: Run this on your workstation: sudo firewall-cmd --add-port=5000/tcp From another machine, on the same network, try connecting to the now open port 5000:\nRun this on another machine on the same network WORKSTATION=192.168.1.10; nc ${WORKSTATION} 5000 This time it should sucessfully connect. You can type some message and then press Enter. You should see the message in the original window running the nc server. If you see the message, you know the port is open.\nThis rule is temporary, and will go away when the system reboots.\nAdding a permanent rule [bash]: Run this on your workstation: sudo firewall-cmd --add-port=5000/tcp --permanent This adds the rule to the permanent config /etc/firewalld/zones/public.xml, and it will survive a system reboot:\nExcerpt from /etc/firewalld/zones/public.xml \u003cport port=“5000” protocol=“tcp”\u003e\nRemove a permanent rule [bash]: Run this on your workstation: sudo firewall-cmd --remove-port=5000/tcp --permanent Adding a new zone [bash]: Run this on your workstation: NEW_ZONE=foo sudo firewall-cmd --permanent --new-zone=${NEW_ZONE} Promoting all temporary rules to permanent rules [bash]: Run this on your workstation: sudo firewall-cmd --runtime-to-permanent Showing all firewall rules To show all the netfilter rules formatted for nftables:\n[bash]: Run this on your workstation: sudo nft list ruleset To show all the netfilter rules formatted for iptables:\n[bash]: Run this on your workstation: sudo iptables-save sudo ip6tables-save Tip nftables and iptables are equivalent interfaces to the same netfilter backend. They show the same rules, just in a different format, depending on your preference.\nHow to query nftables Show all tables [bash]: Run this on your workstation: sudo nft list tables (stdout) table inet firewalld table ip filter table ip nat table ip mangle table ip6 filter table ip6 nat table ip6 mangle Show table chains [bash]: Run this on your workstation: TABLE=filter sudo nft list table ip ${TABLE} Show chain [bash]: Run this on your workstation: TABLE=filter CHAIN=FORWARD sudo nft list chain ip ${TABLE} ${CHAIN} How to query JSON info from nftables Get chain [bash]: Run this on your workstation: CHAIN=filter_IN_public_allow sudo nft -j list ruleset | jq '.nftables[] | select(has(\"chain\")) | select(.chain.name == \"'${CHAIN}'\")' (stdout) { \"chain\": { \"family\": \"inet\", \"table\": \"firewalld\", \"name\": \"filter_IN_public_allow\", \"handle\": 153 } } Get rules per chain [bash]: Run this on your workstation: CHAIN=filter_IN_public_allow sudo nft -j list ruleset | jq '.nftables[] | select(has(\"rule\")) | select(.rule.chain == \"'${CHAIN}'\")' Get destination ports (DNAT) per chain [bash]: Run this on your workstation: CHAIN=filter_IN_public_allow sudo nft -j list ruleset | jq -c '.nftables[] | select(has(\"rule\")) | select(.rule.chain == \"'${CHAIN}'\") | .rule.expr[0] | select(.match.left.payload.field == \"dport\") | .match.right' (stdout) 22 5000 Warning This might need better filtering and account for the “allow” action only.\nRead firewalld script /usr/lib/python3.12/site-packages/firewall/core/nftables.py\nUseful links Netfilter hooks flowchart ",
    "description": "Firewalld Firewalld is an abstraction of nftables (which is an abstraction of netfilter). Firewalld is installed on Fedora systems by default, and it is what is used to configure the system firewall.\nFirewalld rules are grouped into zones. There can be multiple zones, and you may switch between them. There can only be one active zone per network interface.\nDon’t mess with it Warning Fedora Atomic installs a good default zone for workstation use, named public.",
    "tags": [],
    "title": "Firewall",
    "uri": "/linux-workstation/firewall/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:\nThe MIT License (MIT) Copyright (c) 2021 Sören Weber Copyright (c) 2017 Valere JEANTET Copyright (c) 2016 MATHIEU CORNIC Copyright (c) 2014 Grav Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "description": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:",
    "tags": [],
    "title": "LICENSE",
    "uri": "/license/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
