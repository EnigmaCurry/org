var relearn_search_index = [
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "This book is primarily about Fedora Atomic Desktop (sway) hosts, but these instructions are generic enough to work on a wide variety of systemd based Linux operating systems, including Fedora Workstation (traditional), Fedora CoreOS, Arch Linux, and Debian (with caveats).\nPackages for Fedora Atomic Desktop hosts Tip Full package installation for Fedora Atomic Desktop hosts are covered in the chapter on Layering packages.\nPackages for Fedora CoreOS [bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top distrobox make Packages for traditional Fedora Workstation hosts Info These are the packages you would need to install on traditional Fedora Workstation (or Server, but not CoreOS nor Atomic hosts)\n[bash]: Run this on your workstation: sudo dnf install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top net-tools Packages for Arch Linux hosts Info For Arch Linux, it is recommended to do a full system update and reboot prior to installing the libvirt packages.\n[bash]: Run this on your workstation: sudo pacman -Syu sudo reboot After reboot, install packages:\n[bash]: Run this on your workstation: sudo pacman -S libvirt iptables-nft dnsmasq qemu-base virt-install \\ sysfsutils bridge-utils ebtables git make which jq \\ dmidecode pkgconf gcc Packages for Debian/Ubuntu hosts Info For Debian (or Ubuntu), it is recommended to do a full system upgrade and reboot prior to installing the libvirt packages.\n[bash]: Run this on your workstation: sudo apt update sudo apt upgrade sudo reboot After reboot, install packages:\n[bash]: Run this on your workstation: sudo apt install --no-install-recommends \\ libvirt-daemon-system virtinst libvirt-clients \\ dnsmasq sysfsutils bridge-utils ebtables git make \\ which jq dmidecode pkgconf gcc curl \\ python3 python-is-python3 ",
    "description": "This book is primarily about Fedora Atomic Desktop (sway) hosts, but these instructions are generic enough to work on a wide variety of systemd based Linux operating systems, including Fedora Workstation (traditional), Fedora CoreOS, Arch Linux, and Debian (with caveats).\nPackages for Fedora Atomic Desktop hosts Tip Full package installation for Fedora Atomic Desktop hosts are covered in the chapter on Layering packages.\nPackages for Fedora CoreOS [bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top distrobox make Packages for traditional Fedora Workstation hosts Info These are the packages you would need to install on traditional Fedora Workstation (or Server, but not CoreOS nor Atomic hosts)",
    "tags": [],
    "title": "Install libvirtd",
    "uri": "/linux-workstation/kvm-libvirt/install-libvirtd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "Enable libvirtd service [bash]: Run this on your workstation: sudo systemctl enable --now libvirtd sudo systemctl enable --now libvirt-guests sudo systemctl status --no-pager libvirtd Start the default network [bash]: Run this on your workstation: sudo virsh net-start default sudo virsh net-autostart default Configure /etc/group Add the existing libvirt group to /etc/group, if it isn’t already:\n[bash]: Run this on your workstation: grep \"^libvirt:\" /etc/group || sudo bash -c \"getent group libvirt \u003e\u003e /etc/group\" TODO Extra steps only needed for Debian workstations Warning Debian install is a WIP This doesn’t actually fully work on Debian 12 yet. Debian hosts apparently have an additional requirement to run qemu-bridge-helper (I didn’t need it on Fedora or Arch Linux). However, I couldn’t figure out how to get it to work on Debian 12, because I ran into strange app armor errors. YMMV.\nDebian workstations only On a Debian workstation, creating a config for qemu-bridge-helper was required, and modifying it to run setuid root to prevent user permission error (failed to create tun device: Operation not permitted: Transport endpoint is not connected):\n[bash]: Run this on your workstation: (set -e sudo mkdir -p /etc/qemu echo \"allow virbr0\" | sudo tee /etc/qemu/bridge.conf sudo chmod u+s /usr/lib/qemu/qemu-bridge-helper ) I also had to disable apparmor for libvirtd, otherwise I got permission errors:\n[bash]: Run this on your workstation: sudo truncate --size 0 /etc/apparmor.d/usr.sbin.libvirtd sudo apparmor_parser -R /etc/apparmor.d/usr.sbin.libvirtd ",
    "description": "Enable libvirtd service [bash]: Run this on your workstation: sudo systemctl enable --now libvirtd sudo systemctl enable --now libvirt-guests sudo systemctl status --no-pager libvirtd Start the default network [bash]: Run this on your workstation: sudo virsh net-start default sudo virsh net-autostart default Configure /etc/group Add the existing libvirt group to /etc/group, if it isn’t already: [bash]: Run this on your workstation: grep \"^libvirt:\" /etc/group || sudo bash -c \"getent group libvirt \u003e\u003e /etc/group\"",
    "tags": [],
    "title": "Setup libvirtd",
    "uri": "/linux-workstation/kvm-libvirt/setup-libvirtd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": " Index Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) ",
    "description": " Index Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) ",
    "tags": [],
    "title": "Solokey v1",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "This will create a new user account on your workstation named libvirt-admin. This user will be used as the owner for all the VM disk images, config files, and for running the libvirt (qemu) processes that run your VM.\nThis separation from the normal account you use is important to limit the privileges that you have over the VM infrastructure. Your normal account should be able to SSH into the VM and have full root privleges inside the VM. But your normal account should not have access to the underlying VM disk image files, nor its configuration. Access to all VM administrative tasks must be done through sudo to control the libvirt-admin account.\nCreate libvirt-admin user [bash]: Run this on your workstation: VM_ADMIN=libvirt-admin sudo useradd -m ${VM_ADMIN} -s /bin/bash -G libvirt Extra steps for Debian workstations Tip On a Debian workstation, adding the user to the kvm group was also required:\n[bash]: Run this on your workstation: sudo gpasswd -a ${VM_ADMIN} kvm Configure systemd for the libvirt-admin user [bash]: Run this on your workstation: sudo loginctl enable-linger ${VM_ADMIN} sudo su ${VM_ADMIN} -c \\ \"echo export XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN}) \u003e ~/.bashrc\" Copy your public SSH key into the libvirt-admin home directory Tip If you don’t have an SSH key yet, run ssh-keygen -t ed25519.\nSet SSH_KEY variable to point to your public SSH key file:\n[bash]: Customize and set temporary environment variables SSH_KEY=~/.ssh/id_ed25519.pub [bash]: Run this on your workstation: TMP_SSH=$(mktemp) cat ${SSH_KEY} \u003e ${TMP_SSH} chmod a+r ${TMP_SSH} sudo su ${VM_ADMIN:-libvirt-admin} -c \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_SSH} ~/libvirt/user-ssh.pub\" ",
    "description": "This will create a new user account on your workstation named libvirt-admin. This user will be used as the owner for all the VM disk images, config files, and for running the libvirt (qemu) processes that run your VM.\nThis separation from the normal account you use is important to limit the privileges that you have over the VM infrastructure. Your normal account should be able to SSH into the VM and have full root privleges inside the VM.",
    "tags": [],
    "title": "Create VM admin",
    "uri": "/linux-workstation/kvm-libvirt/dedicated-vm-user/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH Solokey authentication Solokey v1 Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) Sudo with Solokey SSH with Solokey Application users DigitalOcean CLI (doctl) KVM / libvirt Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config ",
    "description": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH Solokey authentication Solokey v1 Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) Sudo with Solokey SSH with Solokey Application users DigitalOcean CLI (doctl) KVM / libvirt Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config ",
    "tags": [],
    "title": "Linux Workstation",
    "uri": "/linux-workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "What is self-hosting? Self-hosting is the practice of hosting network applications (web / internet / LAN / etc), using your own server hardware, or at least on virtual machines that you fundamentally control (ie. you have root access). As a preparedness skill, the self-hoster prioritizes the use of open source software, as it becomes an inalienable toolset to bootstrap infrastructure in the wilderness.\nYou can apply self-hosting a little bit, or a lot. On the one hand, you could post all of your content on Facebook (obviously, this is not self-hosting), and on the other hand you could build all your servers yourself, from parts, and run them in your basement, on your own network, bootstrapping everything. For most people though, self-hosting means to use a Raspberry Pi at home, or a cloud computing provider that offers you a generic Linux VPS (virtual private server) on the public internet, to configure in any way you wish, but still letting the cloud provider handle the hardware and network side of things for a monthly fee.\nDemarcate your own level of abstraction. Test that your operations work in a generic way, portable to any other provider at the same level of abstraction. Try running it entirely at home, at least for development purposes. Don’t get locked into a single vendor. Use open source software, or software you built yourself. This is self-hosting.\nWhat is Docker? Docker is a software platform for running containers on Linux. Containers let you install and run software in an isolated and generic way. It solves the problems of “dependency hell” and “But it works on my computer!”, for all Linux distributions. Containers are created from images that include all of their dependencies, including the operating system to support it. The only thing a container does not include, is the Linux kernel, which is shared from the host with all the containers running on the same host. This abstraction makes it work the same way on all computers, regardless of Linux distribution (assuming an up to date kernel). Docker maintains persistent volumes for each container, so that they may mount it into their own virtual filesystem, and thus storing all of its important data into the volume. You may upgrade, or even delete these containers, and as long as you keep the volume(s), you can simply reprovision the same images (even on new hardware), and the containers will load all of its same data from before.\nWhat is a container? Although it is possible to run desktop software inside of a Docker container, 99% of the time a Docker container is created to run a service, assumed to run on a server, assumed to be serving remote clients. Generally, a container is designed only to run a single service. For example: A web server, a chat server, a DNS server, a python server you write, etc. Multiple instances of the same image can run as separate containers, and they can even share volumes, if you want (though generally not).\nContainers are related to a different technology that you might already be familar with: Virtual Machines. However, there are several fundamental differences between containers and virtual machines, and so it is useful to describe them here as a comparison:\nFeature Container Virtual Machine Kernel Containers share a kernel with the host VMs runs their own kernel Hardware Containers share hardware with the host, but with the addition of a permissions model to access it VMs use hardware virtualization features Memory Containers share memory with the host VMs use a fixed size virtual hardware memory space Disk Containers share storage system with the host (volumes live under /var/lib/docker/ by default) VMs use a fixed size (but expandable) virtual hard disk image Network Containers support Host level networking, or can do NAT NAT or bridge network, not host level Execution model Containers are just a regular Linux processes, run under a given user account VMs run their own kernel and init (systemd) Init process Containers don’t need an init process, Docker runs the containers process (CMD) directly VMs run their own kernel and init (systemd) Process isolation Containers run as as regular Linux processes, which have a capabilities system to limit privileges VMs are like a separate machine, and a have a separate process space Root filesystem Containers inherit a root filesystem from their image, which contain all the application files, and the OS, minus a kernel VMs are run from (linked) virtual disk images Volumes Containers automatically mount volumes provided from Docker. Docker maintains the lifecycle of these volumes. VMs can have multiple virtual disks, or manually mount remote volumes Containerization uses features of the Linux kernel, (specifically, namespaces and cgroups). For the purposes of this book, the term “container” will always imply that it is running on a Linux host; it is inseparable from the host kernel, and it can’t work without it! (You may be aware that you can install a product called “Docker Desktop” on Windows or MacOS. This product installs a Linux virtual machine on your host OS and runs Docker inside it, and then it installs the docker client on the host OS, so it appears seamless.)\nIn a general context, there are other OS containers, like Windows containers, however they are on the fringe, and will not be discussed in this book. Containers imply Linux.\nDocker is a good platform to pick for self-hosting containers, because it’s a mature open source project, and it works on virtually any Linux computer or VPS. Docker is server focussed, and therefore ideal for self-hosting. Docker is easy to get started with, even if you’re a beginner.\nWhat is Docker Compose? Docker uses a client-server API pattern of control. You install the Docker daemon on a server machine, and this machine is called the Docker Host. Usually you interact with the API through the command line docker tool. Docker provides primitive commands for running single containers directly, with docker run. However, for larger projects that need more than one container (eg. a webserver + a database) and need to be able to talk to one another, docker run is not the best tool to use.\ndocker compose is a command that operates your containers from a project level abstraction. docker compose lets you define all the containers and volumes that you need for a given project, in a declarative way, in a docker-compose.yaml file.\nWith docker compose you can start/stop/delete all the project containers together, as a single unit.\nWhat is d.rymcg.tech? d.rymcg.tech is a collection of docker compose projects for various open source server applications, but it can also be used as a template for your own services. It has an integrated frontend proxy (Traefik Proxy), including sentry authorization middleware (mTLS, OAuth2, or HTTP Basic auth) and IP address filtering. It is a framework for packaging your own applications, and managing several container instances at the same time, each with seprate configs in .env files.\nd.rymcg.tech focuses on the config rules of the 12-factor principle. All of the configuration for a container should be specified as environment variables, which Docker loads from a standard .env file. All of the data for a container should live inside a Docker Volume (not a bind mount), and so the lifecycle of the volume is maintained by Docker directly.\nd.rymcg.tech is designed to run on a workstation, not the docker host. The Docker server API is accessed remotely over SSH. Only your personal workstation should be used to issue docker commands that affect the server, they should never be run on the server itself. It’s important to keep the server as bare bones and hands off as possible. The server’s only job is to run containers. The job of configuring them is always performed from a remote workstation. Once the server is setup, you won’t normally need to even login to the server console ever again. By controlling the server from your workstation, you can manage the server in a clean fashion. You can even create a new server from scratch, in no time. All of the important configuration stays on your workstation (and are backed up in a git repository).",
    "description": "What is self-hosting? Self-hosting is the practice of hosting network applications (web / internet / LAN / etc), using your own server hardware, or at least on virtual machines that you fundamentally control (ie. you have root access). As a preparedness skill, the self-hoster prioritizes the use of open source software, as it becomes an inalienable toolset to bootstrap infrastructure in the wilderness.\nYou can apply self-hosting a little bit, or a lot.",
    "tags": [],
    "title": "Introduction",
    "uri": "/d.rymcg.tech/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard and a display (although a workstation could also be a VPS that you SSH into, this book will focus on physical workstations).\nHistorically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really exist anymore, and any computing device can become a workstation. The only important distinction for a workstation is the role that it serves, and how you configure and use it on a daily basis.\nThe role of a workstation is very different than that of a server. A workstation’s only purpose is to serve the user, during the moments that you are interfacing with its physical keyboard/display. A workstation is usually connected to a network, but only as a client, not as a server. (Of course, you may bend this rule if you like, to make your computer a server-workstation or “Sworkstation”, but it is cleaner, and more secure, to use separate [virtual] machines for these very different roles.)\nThis book will describe my preferred method for setting up a new computer, for use as a personal Linux workstation. It will also show you how to bend the rules a bit, and create a few virtual machines (VM) for running local development servers (Docker), or even public, production-lite, and/or LAN party services.\nIndex Fedora Sway Atomic Requirements ",
    "description": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard and a display (although a workstation could also be a VPS that you SSH into, this book will focus on physical workstations).\nHistorically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really exist anymore, and any computing device can become a workstation.",
    "tags": [],
    "title": "Introduction",
    "uri": "/linux-workstation/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how to get started with self-hosting your own Docker server, using the tools provided by d.rymcg.tech.\nd.rymcg.tech Chat with us on Matrix Index Introduction Required Infrastructure Register a domain name Setup public DNS service Create a public server (VPS) Create a private server (libvirt VM) Setup your workstation Install Docker client tools Install d.rymcg.tech tools Setup Docker context Create SSH config and Docker context Install Docker on your remote host Setup d.rymcg.tech per Docker context Traefik Proxy Traefik Quickstart (public VPS) Whoami ",
    "description": "This book describes how to get started with self-hosting your own Docker server, using the tools provided by d.rymcg.tech.\nd.rymcg.tech Chat with us on Matrix Index Introduction Required Infrastructure Register a domain name Setup public DNS service Create a public server (VPS) Create a private server (libvirt VM) Setup your workstation Install Docker client tools Install d.rymcg.tech tools Setup Docker context Create SSH config and Docker context Install Docker on your remote host Setup d.",
    "tags": [],
    "title": "Self-hosting Docker with d.rymcg.tech",
    "uri": "/d.rymcg.tech/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "A public internet Docker server needs several resources that you need to procure :\nA domain name registrar (eg. Gandi.net). A domain name server (eg. DigitalOcean DNS). A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet). An internet network connection (eg. DigitalOcean network). Index Register a domain name Setup public DNS service Create a public server (VPS) Create a private server (libvirt VM) ",
    "description": "A public internet Docker server needs several resources that you need to procure :\nA domain name registrar (eg. Gandi.net). A domain name server (eg. DigitalOcean DNS). A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet). An internet network connection (eg. DigitalOcean network). Index Register a domain name Setup public DNS service Create a public server (VPS) Create a private server (libvirt VM) ",
    "tags": [],
    "title": "Required Infrastructure",
    "uri": "/d.rymcg.tech/required-infrastructure/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Using Org-mode and Emacs Navigating Org-mode files Editing Org-mode files Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Using Org-mode and Emacs Navigating Org-mode files Editing Org-mode files Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Publishing with org-mode, ox-hugo, and literate programming.",
    "uri": "/publishing-with-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": "Configure VM [bash]: Customize and set temporary environment variables NAME=coreos-dev OS_VARIANT=fedora-coreos-stable CPUS=1 MEMORY=2048 DISK_SIZE=25 IP_ADDRESS=192.168.122.5 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') ISO_MEDIA=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-40-1.14.iso Write config file into libvirt user directory [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export ISO_MEDIA=${ISO_MEDIA} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \\ \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" \\ --live --config --parent-index 0 ",
    "description": "Configure VM [bash]: Customize and set temporary environment variables NAME=coreos-dev OS_VARIANT=fedora-coreos-stable CPUS=1 MEMORY=2048 DISK_SIZE=25 IP_ADDRESS=192.168.122.5 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') ISO_MEDIA=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-40-1.14.iso Write config file into libvirt user directory [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export ISO_MEDIA=${ISO_MEDIA} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.",
    "tags": [],
    "title": "Configure VM with .iso boot",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/configure-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Traefik Proxy",
    "content": "Before we get too deep into Traefik configuration, if you just want to setup a public VPS, follow these instructions as a quickstart tutorial:\nChoose your active Docker context [bash]: Run this on your workstation: d context Configure Traefik for your active Docker context [bash]: Run this on your workstation: d make traefik config The configuration is driven by a text wizard menu system.\n(stdout) ? Traefik config main menu: \u003e Create system user on Docker host Configure entrypoints (including dashboard) Configure Certificate Authorities (CA) Configure ACME (Let's Encrypt or Step-CA) Configure TLS certificates and domains (make certs) Configure middleware (including auth) v Configure error page template [↑↓ to move, enter to select, type to filter, ESC to cancel] Use your arrow keys to select only the menu items this tutorial talks about, and press the Enter key. To cancel, press the ESC key.\nOnce complete, it will have created and configured your .env_{CONTEXT} file for you.\nCreate system user on Docker host This option will create a new username on the Docker host, called traefik. This is necessary to reserve a unique UID for traefik to run as on the system. Run this first before anything else.\nSkip: Configure entrypoints For this tutorial, you will use the default entrypoints, so you don’t need to configure anything.\nweb (TCP port 80) websecure (TCP port 443) Skip: Configure Certificate Authorities (CA) For this tutorial you will only need the default CA list provided by the container image.\nConfigure ACME (Let’s Encrypt) (stdout) ? Which ACME provider do you want to use? \u003e Let's Encrypt (ACME) Step-CA (ACME) Disable ACME Cancel / Go back Choose Let's Encrypt (ACME).\nConfigure Let’s Encrypt environment (stdout) ? Which LE environment do you want to use? \u003e Production (recommended!) Staging (untrusted / testing) Tip Always choose the Production environment, unless you really know what you’re doing. Production is the only environment that produces valid (trusted) TLS certificates.\nChoose type of ACME challenge (stdout) ? Which type of ACME challenge should be used? \u003e TLS-ALPN-01 (default for public servers, easy, but no wildcard certs) DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs) Tip For your first install, choose TLS-ALPN-01, it is the easiest method to use for public servers.\nIf you want to use wildcard DNS records, or you need to setup a server behind a firewall, you must choose the more advanced method DNS-01, and setup your DNS platform for programmatic access with an API token.\nSkip: Configure ACME email address You don’t have to provide your email address, but if you do, Let’s Encrypt can email you about configuration issues, like certitficates about to expire.\nConfigure TLS certificates and domains d.rymcg.tech uses explicit certificate requests configured centrally, on the traefik project:\n(stdout) ? Configure Traefik TLS certificates \u003e Manage all certificates. Create a new certificate. Done / Go back Manage all certificates This will show you all the certificate requests that have been defined and allow you to manage each one. It will be blank to start out with.\nCreate a new certificate Use this to define all the certificates you need for all your applications.\nSet certificate main domain (CN) Each certificate needs a main name (CN), which should be the main domain name of the certificate.\nprod.example.com Info Each certificate may also contain several other domain names, known as SANs (Subject Alternative Names). You can use this to list as many additional domain names that you want to be listed on the same certificate.\nConfigure middleware Configure error page template Configure wireguard VPN Install Traefik To install Traefik (on your active Docker context), you can simply choose the Reinstall Traefik option in the menu, or you can run that step all by itself from the command line at any time:\n[bash]: Run this on your workstation: d make traefik install You should always reinstall Traefik after changing any configuration setting.",
    "description": "Before we get too deep into Traefik configuration, if you just want to setup a public VPS, follow these instructions as a quickstart tutorial: Choose your active Docker context [bash]: Run this on your workstation: d context Configure Traefik for your active Docker context [bash]: Run this on your workstation: d make traefik config The configuration is driven by a text wizard menu system. (stdout) ? Traefik config main menu: \u003e Create system user on Docker host Configure entrypoints (including dashboard) Configure Certificate Authorities (CA) Configure ACME (Let's Encrypt or Step-CA) Configure TLS certificates and domains (make certs) Configure middleware (including auth) v Configure error page template [↑↓ to move, enter to select, type to filter, ESC to cancel] Use your arrow keys to select only the menu items this tutorial talks about, and press the Enter key.",
    "tags": [],
    "title": "Traefik Quickstart (public VPS)",
    "uri": "/d.rymcg.tech/traefik-proxy/vps-quickstart/index.html"
  },
  {
    "breadcrumb": "",
    "content": "This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nTable of contents The menu bar on the left contains the index of all the books, with the titles as top level headings. On smaller screens, you may need to expand this menu using the top left hamburger menu.\nAt the top left of every page (and just to the right of the sidebar), there is a button to show the outline of the current page.\nNavigation This website is presented as a book of books, so you can read everything from beginning to end. Use your keyboard left/right arrow keys to flip through the pages. If you are using a touch screen interface, use the arrow buttons at the top right of the page.\nSearch Use the search box in the left hand menu to search all of the books on the site.",
    "description": "This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nTable of contents The menu bar on the left contains the index of all the books, with the titles as top level headings. On smaller screens, you may need to expand this menu using the top left hamburger menu.\nAt the top left of every page (and just to the right of the sidebar), there is a button to show the outline of the current page.",
    "tags": [],
    "title": "book.rymcg.tech",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).\nRead the Linux Workstation chapter for setting up Emacs.\nPlease note that your package manager may container an old version of Hugo that is incompatible with the Relearn theme. You can install the latest version of Hugo from the Hugo GitHub releases page.\nFor example, to download the X86_64 release of hugo v0.123.8:\n[bash]: Run this on your workstation: ## Do this if your package manager installs an old incompatible version of Hugo: cd ~/Downloads wget https://github.com/gohugoio/hugo/releases/download/v0.123.8/hugo_extended_0.123.8_linux-amd64.tar.gz tar xfvz hugo_extended_0.123.8_linux-amd64.tar.gz sudo install hugo /usr/local/bin/hugo You will also need to clone the git source of this website to your workstation:\n[bash]: Run this on your workstation: git clone https://github.com/EnigmaCurry/org.git ~/git/vendor/enigmacurry/org I always recommend to everyone, that you choose to use the ~/git/vendor/ORG_NAME/REPO_NAME path structure when cloning any git repository (including your own!). This suggested path is a vendor-neutral convention, useful for documentation purposes, and which shouldn’t conflict with any existing directory you might have. Therefore the instructions should generally work on all machines. If we all agree to use the same path, the instructions are much easier to write, and read from! If you are adamant about cloning this elsewhere, consider making a symlink from this path anyway (In this case, ~/git/vendor/enigmacurry/org).",
    "description": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).",
    "tags": [],
    "title": "Dependencies",
    "uri": "/publishing-with-org-mode/dependencies/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Create USB installation media Download the Fedora Sway Atomic iso image. Assuming you are temporarily using another Linux workstation, write the .iso image to a USB drive:\n[bash]: Run this on your workstation: dd if=Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your device name, and double check the .iso filename, it may have changed.\nBoot the target workstation computer using the USB drive. You will boot into the Anaconda install wizard. Just follow the prompts to install it, it is exactly the same as any other Fedora / Redhat install.\nTips:\nEnable whole disk encryption and choose a secure passphrase. Especially for laptop computers that you may travel with, this an important thing to do to keep your files safe at rest. Use the entire disk for the install. Dual booting another operating system on the same workstation is not considered a safe/secure thing to do. If you want to run Windows or play games, use a separate computer for that. Once the installer finishes, reboot, remove the USB, and login to your new system.",
    "description": "Create USB installation media Download the Fedora Sway Atomic iso image. Assuming you are temporarily using another Linux workstation, write the .iso image to a USB drive:\n[bash]: Run this on your workstation: dd if=Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your device name, and double check the .iso filename, it may have changed.\nBoot the target workstation computer using the USB drive. You will boot into the Anaconda install wizard.",
    "tags": [],
    "title": "Install Linux (Fedora Atomic)",
    "uri": "/linux-workstation/install/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "description": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "tags": [],
    "title": "Building locally",
    "uri": "/publishing-with-org-mode/building-locally/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from. The default is to boot the newly upgraded image.\nThe above will not upgrade to a new release version, eg. Fedora 39 to Fedora 40. It will only update the packages for the currently installed release.\nTo find the list of all released versions, run :\n[bash]: Run this on your workstation: ostree remote refs fedora | grep \"$(uname -m)/sericea$\" Upgrade to the new release (eg. 40):\n[bash]: Run this on your workstation: rpm-ostree rebase fedora:fedora/40/x86_64/sericea Let it finish downloading the new image, and then reboot again.",
    "description": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from.",
    "tags": [],
    "title": "Upgrading",
    "uri": "/linux-workstation/upgrading/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "See the Fedora docs for Adding Layered Packages. For most packages, you should not install them this way, but you should prefer installing them inside of a toolbox / distrobox container instead. On the Fedora Atomic host, you should install (layer) only those packages that cannot be run from a container (or you really just want to run them natively for some reason).\nTo create efficient layers, you should try to install everything in one go, using as few layers as possible. Here is a list of packages you might want to add all together as one layer:\n[bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top net-tools \\ gvfs-smb gvfs-archive gvfs-nfs gvfs-fuse gvfs-mtp \\ distrobox file-roller thunar-volman pamu2fcfg pam-u2f Fedora Atomic Sway edition (Sericea) already includes a lot of packages layered on top of the core Fedora Atomic. So before you install new things, check what comes preinstalled.\nExamples of applications you might want to layer File explorer (thunar) plugins for archives and removeable drives. Virtual filesystem plugins (gvfs). Container tools (Distrobox). Virtual Machine tools (Qemu and libvirt). Basic network tools (net-tools arp) Web browsers are fickle. Although they mostly work inside toolbx containers just fine, Sericea includes Firefox in its base layer as a native app, and that seems to work great. However, I have also tested Chromium inside of a toolbx container without issue. For use cases where Chromium needs to have native USB access, you might not want to run it in a container.\nCheck the list of layers: [bash]: Run this on your workstation: sudo rpm-ostree status The top layer should list the LayeredPackages in your new layer.\nReboot.\nReset all layers back to stock Warning This will reset all the layered packages back to the stock image. This may be useful if you are trying to clean up from lots of testing.\nAll package layers will be destroyed!\nYour user home directories (/var/home/) and system configuration (/etc/) are not affected.\n[bash]: Run this on your workstation: sudo rpm-ostree reset sudo rpm-ostree cleanup -r ",
    "description": "See the Fedora docs for Adding Layered Packages. For most packages, you should not install them this way, but you should prefer installing them inside of a toolbox / distrobox container instead. On the Fedora Atomic host, you should install (layer) only those packages that cannot be run from a container (or you really just want to run them natively for some reason).\nTo create efficient layers, you should try to install everything in one go, using as few layers as possible.",
    "tags": [],
    "title": "Layering packages",
    "uri": "/linux-workstation/layering-packages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "description": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "tags": [],
    "title": "Publishing with GitHub pages",
    "uri": "/publishing-with-org-mode/publish-with-github-pages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this. You must set all of the following details:\nThe unique name of the remote (eg. book) The hostname of the SFTP server (eg. sftp.example.com) The SFTP username, password, or SSH key, and whether to use the SSH agent (recommended!) The connection details are saved in your clone config file (eg. ~/.config/rclone/rclone.conf)\nThe included Makefile has a variable at the top called PUBLISH_RCLONE_REMOTE (default book). Make sure this is the same as the name of the rclone remote you configured (edit the Makefile if it is not).\nOnce everything is configured, simply run make publish to publish your site to the SFTP remote.\nYour webserver document root needs to be configured to use the same path that the SFTP server is configured for.\nIf you don’t have a webserver or SFTP server, you can use the following from d.rymcg.tech:\nSFTP server Nginx webserver ",
    "description": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this.",
    "tags": [],
    "title": "Publishing with SFTP",
    "uri": "/publishing-with-org-mode/publish-with-sftp/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": " Index Sway Firefox Toolbox Emacs SSH ",
    "description": " Index Sway Firefox Toolbox Emacs SSH ",
    "tags": [],
    "title": "Config",
    "uri": "/linux-workstation/config/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Solokeys are physical hardware authentication (U2F / FIDO2) devices, that you plug into a USB port, which stores a secret key that can be used as primary or secondary authentication factors (2FA), with websites (Webauthn), and machines (sudo and SSH).\nThere are two versions of solokey now, v1 and v2, and they require separate toolchains. The instructions diverge here depending on which hardware revision you have.\nIndex Solokey v1 Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) Sudo with Solokey SSH with Solokey ",
    "description": "Solokeys are physical hardware authentication (U2F / FIDO2) devices, that you plug into a USB port, which stores a secret key that can be used as primary or secondary authentication factors (2FA), with websites (Webauthn), and machines (sudo and SSH).\nThere are two versions of solokey now, v1 and v2, and they require separate toolchains. The instructions diverge here depending on which hardware revision you have.\nIndex Solokey v1 Get your Solokey (v1) Install Solokey CLI (v1) tool Update your Solokey (v1) Program your Solokey (v1) Sudo with Solokey SSH with Solokey ",
    "tags": [],
    "title": "Solokey authentication",
    "uri": "/linux-workstation/sudo-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "Here are some tips on using Org-mode and Emacs.\nRead the Org manual Many of these tips are found in the Org Manual.\nIndex Navigating Org-mode files Editing Org-mode files ",
    "description": "Here are some tips on using Org-mode and Emacs.\nRead the Org manual Many of these tips are found in the Org Manual.\nIndex Navigating Org-mode files Editing Org-mode files ",
    "tags": [],
    "title": "Using Org-mode and Emacs",
    "uri": "/publishing-with-org-mode/org-mode-emacs/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "With strong authentication for sudo taken care of by Solokey, we can separate permissions for privileged data access, by creating additional user accounts.\nOne use case for this can be to control access to command line programs that store sensitive API tokens, via sudo.\nIndex DigitalOcean CLI (doctl) ",
    "description": "With strong authentication for sudo taken care of by Solokey, we can separate permissions for privileged data access, by creating additional user accounts.\nOne use case for this can be to control access to command line programs that store sensitive API tokens, via sudo.\nIndex DigitalOcean CLI (doctl) ",
    "tags": [],
    "title": "Application users",
    "uri": "/linux-workstation/app-users/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example Org / Hugo content",
    "uri": "/publishing-with-org-mode/examples/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "You should dedicate the use a physical or virtual Linux machine to be used as your workstation. A single workstation can manage several remote Docker contexts.\nFollow the Linux Workstation book for details on basic workstation setup.\nAll the commands in this chapter assume you are using the standard Bash shell.\nIndex Install Docker client tools Install d.rymcg.tech tools ",
    "description": "You should dedicate the use a physical or virtual Linux machine to be used as your workstation. A single workstation can manage several remote Docker contexts.\nFollow the Linux Workstation book for details on basic workstation setup.\nAll the commands in this chapter assume you are using the standard Bash shell.\nIndex Install Docker client tools Install d.rymcg.tech tools ",
    "tags": [],
    "title": "Setup your workstation",
    "uri": "/d.rymcg.tech/workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup Docker context",
    "content": "To remotely control your Docker host from your workstation, you need two additional configs:\nSSH Host config in ~/.ssh/config. Docker context config via docker context create .... Both of these can be created automatically by running:\n[bash]: Run this on your workstation: d context new This will prompt you if you really want to proceed:\n(stdout) ? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y You can choose to create a new SSH config, or use an existing one:\n(stdout) ? You must specify the SSH config entry to use I already have an SSH host entry in ~/.ssh/config that I want to use \u003e I want to make a new SSH host entry in ~/.ssh/config [↑↓ to move, enter to select, type to filter, ESC to cancel] Enter the short one word name for the SSH Host entry:\n(stdout) ? Enter the new SSH context name (short host name) : foo Enter the fully qualified DNS name of the Docker host:\n(stdout) ? Enter the fully qualified SSH Host DNS name : foo.example.com It will propose to create a new SSH config entry that looks like this:\n(stdout) ## Here is the new SSH config entry: Host foo Hostname foo.example.com User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p ? Do you want to append this config to ~/.ssh/config? (y/N) y It will ask you if you want to immediately switch the active Docker context:\n(stdout) ? Do you want to switch to the new foo context now? (y/N) y foo Current context is now \"foo\" List all Docker contexts and switch the active one [bash]: Run this on your workstation: d context (stdout) ? Select the Docker context to use deb \u003e foo step-ca [↑↓ to move, enter to select, type to filter, ESC to cancel] Current context is now \"foo\" ",
    "description": "To remotely control your Docker host from your workstation, you need two additional configs:\nSSH Host config in ~/.ssh/config. Docker context config via docker context create .... Both of these can be created automatically by running:\n[bash]: Run this on your workstation: d context new This will prompt you if you really want to proceed:\n(stdout) ? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y You can choose to create a new SSH config, or use an existing one:",
    "tags": [],
    "title": "Create SSH config and Docker context",
    "uri": "/d.rymcg.tech/docker-context/ssh-config-and-docker-context/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.\nIt can contain any additional markup you want.",
    "description": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.",
    "tags": [],
    "title": "Example Org Blocks",
    "uri": "/publishing-with-org-mode/examples/org-blocks/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.\nThe “Atomic” part refers to rpm-ostree, which was originally used by the CoreOS team to build an operating system that is built entirely to support containers. The root file system of an Atomic host is mounted read-only, and the packages are distributed in an image, rather than installed individually. This makes updating (or rolling back) the system far easier, and makes for a more stable environment. There is no need to replace packages one-by-one, you just download the new image provided by the distro, and then reboot the system to use it.\nThe base image includes all the typical things everyone needs: coreutils, a display manager, web browser, terminal apps etc. However, the base image is still pretty bare bones. Furthermore, the image is read-only, so you can’t install packages like you can with a more traditional Linux distro. If you want to install something that isn’t in the base image, you have a few different options:\nPodman or Docker containers. Since containers use their own image, they are separate from the main image, and can be freely created and destroyed separately. Flatpak is a type of application container that includes all of its dependencies, and it is sandboxed/isolated from the host system, therefore they can be installed/managed separately from the base image. Use rpm-ostree itself to create a new image layer. This extends the base layer with extra packages you want to install. This is fully supported, but not optimal, as when you upgrade the base image, this layer needs to be recreated each time. I only use a couple of Flatpak apps for a few things. For almost everything else I use Podman containers via toolbox and/or distrobox and these can even include graphical applications. Creating your own rpm-ostree layers is to be avoided if possible, but some things don’t like running in containers, so this remains an option.",
    "description": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.\nThe “Atomic” part refers to rpm-ostree, which was originally used by the CoreOS team to build an operating system that is built entirely to support containers.",
    "tags": [],
    "title": "Fedora Sway Atomic",
    "uri": "/linux-workstation/introduction/fedora-sway-atomic/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "You need to install Docker Engine (not Docker Desktop!) on your workstation.\nYou will completely disable the Docker daemon on your workstation, you’re only installing Docker Engine for its client tools (eg. the docker command).\nVarious ways to install Docker Engine Try your system package manager Some Linux distributions have decent packages for up-to-date Docker versions. Some other distributions lag behind by several versions, or may even introduce non-standard changes of their own. Your mileage may vary with packages provided by your operating system.\nIf you’re on Arch Linux, this is known to be a good configuration:\nRun this on your Arch Linux workstations: sudo pacman -S docker docker-compose docker-buildx Install from upstream Docker package repository The Docker organization provides several up-to-date packages for various Linux distributions:\nDebian Ubuntu Fedora Use the generic Docker installer to install the latest version If your Linux distribution doesn’t provide a Docker package, or you’ve decided its not good for your situation, you may be better off by running the generic installer script from the upstream Docker organization:\n[bash]: Run this on your workstation: curl -fsSL https://get.docker.com -o install-docker.sh sudo sh install-docker.sh DON’T install Docker Desktop! Docker Desktop isn’t open source. Docker Desktop runs a VM to run the Docker daemon on localhost. (we don’t want that, since we will use a remote Docker context instead.) Docker Desktop does not support host mode networking, so it wouldn’t have worked with our Traefik config anyway. (This situation may have changed in more recent versions of Docker Desktop 4.29+). Docker Desktop provide the same docker client tools, so it will actually still work, if thats the package you prefer to install. Just be sure to disable the VM that it creates by default, you will not need it! Keep your workstation clean, don’t run containers / VMs on it! Disable Docker daemon on your workstation Your workstation is the manager of remote Docker hosts, so it should not run the Docker daemon itself, but only the client.\nRun the following commands to disable the Docker daemon:\n[bash]: Run this on your workstation: sudo systemctl disable --now docker sudo systemctl mask docker Tip There is a vestigal Docker context named “default” left on your system (see docker context ls), and this context was originally used to manage the Docker daemon of the local host (unix:///var/run/docker.sock). However, this will be of no use to you now, since the Docker daemon is now completely disabled on the workstation. Furthermore, the “default” context cannot be deleted, so its best to just ignore it (the d.rymcg.tech CLI won’t even show it). In the next couple of steps, you’ll create and activate new remote SSH contexts that you’ll use instead of the “default” context.",
    "description": "You need to install Docker Engine (not Docker Desktop!) on your workstation.\nYou will completely disable the Docker daemon on your workstation, you’re only installing Docker Engine for its client tools (eg. the docker command).\nVarious ways to install Docker Engine Try your system package manager Some Linux distributions have decent packages for up-to-date Docker versions. Some other distributions lag behind by several versions, or may even introduce non-standard changes of their own.",
    "tags": [],
    "title": "Install Docker client tools",
    "uri": "/d.rymcg.tech/workstation/install-docker-command-line-tools/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Using Org-mode and Emacs",
    "content": "Navigating by search One of the easiest ways of navigating an Org document, isn’t even an Org feature. Just search for the text you’re looking for and jump right to it.\nPress C-s (or M-x isearch-forward) Of course, you might not always know the exact text (or it might not be unique enough to take you right there), so its useful to know some other ways of navigating Org documents.\nNavigating by headers Another great way to navigate your Org documents is by traversing the headers. My emacs config sets the default startup visibility to folded, so you can always get back to a folded state:\nPress C-u C-u TAB (or M-x org-set-startup-visibility) Cycle the visibility of the headers (foldedness):\nPress TAB to cycle the folding of the selected header (your cursor has to be on a header). Press C-u TAB to cycle the folding of the headers in the whole buffer (cursor can be anywhere). Press C-u C-u C-u TAB (or =M-x org-show-all) to show the entire buffer unfolded. If you’re in the middle of a paragraph, and want to move to the header of the current section:\nPress s-\u003cup\u003e (or C-c C-p or M-x org-previous-visible-heading) Press it again to go to the section before that, etc. To move to the next section:\nPress s-\u003cdown\u003e (or C-c C-n or M-x org-next-visible-heading) Moving to the next higher heading is very useful:\nPress C-c C-u (or M-x outline-up-heading). From the parent heading you get to see the outline of the outer context of what you’re currently writing about. From here you can press Tab twice to fold all all the sibling sections and get an overview.\nPress C-c C-u TAB TAB. Here are some other header movement commands:\nC-c C-f (M-x org-forward-heading-same-level) C-c C-b (M-x org-backward-heading-same-level) Jumping around (org-goto) You may frequently find yourself needing to jump around in a document, but don’t want to lose your current place.\nPress C-c C-j (or M-x org-goto). Mnemonic “jump”. Immediately press Enter to close the org-goto menu (theres advanced searching functions in there, but you ignore that for now). This will save your current place, allowing you to go find the place you need to temporarily go to.\nWhen you’re done, and you want to go back to to where you were:\nPress C-c \u0026. (or M-x org-mark-ring-goto). One mnemonic for \u0026 is that it is the same syntax for a C pointer reference.\nIndirect Buffers and Narrow To Subtree One of the advantages of Org-mode is you can organize lots of different articles into one big file. This is also a disadvantage when you are trying to focus on just one of them. It is easy to get lost.\nAs an example, open the other book named d.rymcg.tech.org (found in this same directory). Let’s say we want to focus on the chapter named Traefik Proxy.\nPress C-x 4 c. (or M-x clone-indirect-buffer-other-window). You now have two buffers open for the same file: d.rymcg.tech.org (the original) and d.rymcg.tech.org\u003c2\u003e (the clone), and you are automatically switched focus to the newly cloned buffer.\nRename the new buffer to traefik so you don’t get confused:\nPress C-x x r (or M-x rename-buffer). Type the new name: traefik. Now find the chapter you want to focus on:\nNavigate to the chapter heading named * Traefik Proxy, make sure your cursor is now somewhere on this line. Narrow the buffer to the selected subtree:\nPress C-x n s (or M-x org-narrow-to-subtree). You have now completed the process of narrowing the content of this buffer to only the Traefik Proxy article. It is important to know that the traefik buffer is still an indirect clone of the original d.rymcg.tech.org buffer, and they are both simultaneously editing the same underlying file. But now you know how to focus on a bite sized peice of a larger file. Go ahead and create more buffers to work on other parts you frequently need to focus on.\nIf you need to widen the buffer again:\nPress C-x n w (or M-x widen) ",
    "description": "Navigating by search One of the easiest ways of navigating an Org document, isn’t even an Org feature. Just search for the text you’re looking for and jump right to it.\nPress C-s (or M-x isearch-forward) Of course, you might not always know the exact text (or it might not be unique enough to take you right there), so its useful to know some other ways of navigating Org documents.",
    "tags": [],
    "title": "Navigating Org-mode files",
    "uri": "/publishing-with-org-mode/org-mode-emacs/navigating-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "To host a web service, one of the first things you will need is to register your domain name. This will be the domain name used for all of your service links, and it is what your users will need to type into their browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments. If domain names were free, all the good ones would be taken by now, but because they cost money, there are still some good enough ones left to be had. In return for your fee, you receive exclusive use of your domain name for the period that you paid for. You “own” the domain name, and its configuration, but you need to keep paying a registrar to keep the record active (so its more like renting). You can pre-pay for several years in advance, or for just pay one year at a time. If you stop paying, and the records expire, they will no longer resolve to your services, and you may lose control of the domain, possibly forever.\nDomain names for private servers If you control your own DNS servers, you could use completely made up domain names under the .internal domain, which are RFC recoginized for private usage. But for most public servers, where most clients use different DNS servers, you will want to register a “real” domain instead.\nFor private servers, (eg. running a private Docker server at home), it is still recommended that you use a valid internet domain name, using public DNS servers, because you will still need this in order to create valid TLS certificates from Let’s Encrypt. However, having valid working TLS is not required for development purposes (but certainly nice to have!), so you may choose to make up your own fake domain name instead, and forgo TLS, or you can setup Step-CA for off-grid TLS. In either case, you will still need to setup DNS, and this is explained in the next section.\nRegister an Internet domain name You can buy (rent) a domain name from lots of places. For documentation purposes, we will use Gandi.net, but these instructions will be similar regardless of the domain provider you pick.\nSetup on Gandi.net Sign up for an account at Gandi.net Once signed in, from your dashboard, click Register. Search for any domain name you like, eg. your-name.com. Add your domain to the shopping cart, go to checkout, and complete your purchase. Once you have purchased the domain, it should show up in your Dashboard, under the Domain tab. Leave this browser tab open, you will return to it in the next chapter. ",
    "description": "To host a web service, one of the first things you will need is to register your domain name. This will be the domain name used for all of your service links, and it is what your users will need to type into their browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments.",
    "tags": [],
    "title": "Register a domain name",
    "uri": "/d.rymcg.tech/required-infrastructure/register-a-domain-nameom/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it. However, I use my own custom configuration that I replace it with, and you can do the same if you like.\nOpen the default terminal emulator (foot) with the keyboard shortcut: Win+Enter (hold down the “Windows” key on your keyboard, then simultaneously press Enter.)\nMy custom config replaces several of the default configuration files. So you must first get rid of these files, by renaming them with the suffix .orig for posterity:\n[bash]: Run this on your workstation: mv ~/.config ~/.config.orig mv ~/.bashrc ~/.bashrc.orig mv ~/.bash_profile ~/.bash_profile.orig Next, install my customized sway config repository :\n[bash]: Run this on your workstation: git clone https://github.com/enigmacurry/sway-home \\ ~/git/vendor/enigmacurry/sway-home Run the included setup script:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/sway-home ./setup.sh The setup.sh script will make symlinks to the repository files from the same original paths as the files you just moved. It also asks you some questions to help setup your git profile.\nOnce you have finished entering the information setup asks for, press Win+Shift+E, and choose Log Out. Log back in, and this will load the new config files.\nSetup display resolutions and orientation Fedora Sway Atomic ships with kanshi for display setup. Kanshi does not include any GUI for setting it up, so another program called wdisplays is useful, however it is not included in the base Atomic distribution, and you will have to install it via toolbox.\ninstall wdisplays inside of toolbox sudo dnf install wdisplays You can configure all of your displays using the wdisplays GUI program, however, the configuration will not persist across login sessions. So what you need to do is set it up how you like it, and then transfer that information into the Kanshi config file so that it sets it up the same way everytime you login.\nFor example, on my test system I have two display port monitors, with outputs named DP-3 and DP-4. These are shown in wdisplays and I have set up the size, position, and DPI scaling exactly how I like it:\nDP-3:\nDP-4:\nOpen the Kanshi config file ~/.config/kanshi/config and copy the information into the config file:\nEdit this file: ~/.config/kanshi/config profile { output DP-3 enable mode 2560x1440 position 3840,0 scale 1 transform normal output DP-4 enable mode 3840x2160 position 1920,360 scale 2 transform normal } Check out man 5 kanshi for more config options. Kanshi is automatically started when sway is, so you can test it by logging out and logging back in.",
    "description": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it.",
    "tags": [],
    "title": "Sway",
    "uri": "/linux-workstation/config/sway/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Using Org-mode and Emacs",
    "content": "Hyperlinks To add hyperlinks to documents, I find it easiest to type the text first, and then add the link.\nType the link text. Navigate point to the first character of the link text. Press C-SPC (Control Spacebar) to mark the beginning. Navigate point to the last character of the link text. Press C-c o i (or M-x org-insert-link). Enter the hyperlink URL. Absolute URLs should start with https://. Relative URLs can reference the root of the domain with /. Just remember, since all links are going through Hugo, links have to be in the context of what the web browser can find, not all local Org links are valid. ",
    "description": "Hyperlinks To add hyperlinks to documents, I find it easiest to type the text first, and then add the link.\nType the link text. Navigate point to the first character of the link text. Press C-SPC (Control Spacebar) to mark the beginning. Navigate point to the last character of the link text. Press C-c o i (or M-x org-insert-link). Enter the hyperlink URL. Absolute URLs should start with https://. Relative URLs can reference the root of the domain with /.",
    "tags": [],
    "title": "Editing Org-mode files",
    "uri": "/publishing-with-org-mode/org-mode-emacs/editing-org-mode/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.rymcg.tech d.rymcg.tech Cancel Math Math with MathJax:\n$$\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ Flowcharts --- title: Example Diagram --- graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{\u0026lt;strong\u0026gt;Decision\u0026lt;/strong\u0026gt;} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] Notices Notice This is a generic notice.\nThis is a bug notice.\nInfo This is an information box.\nTip This is a tip or pointer.\nWarning This is a warning.\nOpenAPI Visualize your API with swagger spec.",
    "description": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.",
    "tags": [],
    "title": "Example Shortcodes",
    "uri": "/publishing-with-org-mode/examples/shortcodes/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar. Select Settings.\nGeneral Settings Select Open previous windows and tabs Turn on Dark mode Turn off Recommend extensions as you browse Turn off Recommend features as you browse Home settings New Windows and Tabs Select Blank Page for both new windows and tabs.\nFirefox Home Content The home content won’t show if you set Blank Page above, but I go ahead and turn off all the home stuff anyway.\nSearch Settings Choose a non-Google default search engine, eg. DuckDuckGo. Turn off all Search Suggestions Delete all the corporate Search Shortcuts other than your preferred one (eg. DuckDuckGo). You can select each one and click Remove or you can press the Delete key. Delete Google, Amazon, Bing, eBay, Wikipedia etc.\nPrivacy \u0026 Security settings Enhanced Tracking Protection, select Strict Set Do Not Track to Always Logins and Passwords Unselect Suggest Firefox relay email masks\nUnselect Show alerts about passwords for breached websites (You already use unique passwords for every website, right??)\nIMPORTANT: select Use a Primary Password Without setting a primary password, any password that firefox saves will be unencrypted! You must set a primary (master) password, and you will need to type it in each time you restart your browser, to unlock the password manager.\nAddress Bar - Firefox Suggest Unselect Search engines\nUnselect Suggestions from the web\nUnselect Suggestions from sponsors\nFirefox Data Collection and Use Unselect everything here.\nHTTPs-Only mode Choose Enable HTTPS-Only Mode in all windows\nDNS over HTTPS Especially if you use a portable laptop, or connect to various WiFi access points, you should choose Max Protection.\nExtensions and Themes From the Settings menu, near the bottom, click Extensions \u0026 Themes.\nThemes Choose a theme you like. For example, click Dark and then click Enable.\nExtensions Go to addons.mozilla.org and install the following extensions:\nDark Reader\nDark reader makes all sites darker, and you can customize each site by clicking on the Dark Reader extension in the menu bar.\nUblock Origin\nDisables almost all ads on all websites. There’s not much to configure here, it basically works out of the box. However, you can customize it per site if you want to enable ads on certain pages.\nNoScript\nBy default, all sites will have javascript disabled. On each site you trust, you can customize the javascript availability by clicking the NoScript extension in the menu bar.\nNo Tabs\nIf you’re using a tiling window manager (Sway), you might consider disabling Firefox tabs, and have every site in its own window instead. This extension does that.\nVimium\nOnce vimium is installed, click the icon in the menu bar and click Enable all hosts permission.\nFirefox Multi-Account Containers\nRead about how to use Firefox Containers. Configure sites you trust to open in specific containers, that way you can save your cookies per container. By default, new sites will always open in temporary ones, and so when you close your browser all the cookies for that site disappears.",
    "description": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar.",
    "tags": [],
    "title": "Firefox",
    "uri": "/linux-workstation/config/firefox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "Install d.rymcg.tech and its dependencies on your workstation.\nInstall dependent packages If you run Fedora workstations, run this as root dnf install bash gettext openssl git xdg-utils jq sshfs curl \\ inotify-tools httpd-tools make wireguard-tools If you run Debian/Ubuntu workstations, run this as root apt-get install bash build-essential gettext git openssl \\ apache2-utils xdg-utils jq sshfs wireguard curl \\ inotify-tools If you run Arch Linux workstations, run this as root pacman -S bash base-devel gettext git openssl apache xdg-utils \\ jq sshfs wireguard-tools curl inotify-tools Clone d.rymcg.tech repository [bash]: Run this on your workstation: git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \\ ${HOME}/git/vendor/enigmacurry/d.rymcg.tech Warning By convention, you should not change the clone path. It is intentionally placed in a vendor neutral path location for all to use. But if you’re adamant to do so, it should still work, regardless of where you put it. But watch out, as this may break documentation, and for some external projects that assume ROOT_DIR is using the conventional path. For compatability reasons, consider making a symlink from ${HOME}/git/vendor/enigmacurry/d.rymcg.tech pointing to your actual clone path.\nSetup d.rymcg.tech command line tool You must edit your workstation user’s ~/.bashrc file, which modifies the Bash shell environment config:\nEdit this file: ~/.bashrc ## Put this in ~/.bashrc to enable d.rymcg.tech command line tools: export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user eval \"$(d.rymcg.tech completion bash)\" ## Setup shorter alias for d.rymcg.tech as just 'd' __d.rymcg.tech_cli_alias d Important Close and restart your shell (terminal) to load the new config in a new session.\nTest the d.rymcg.tech aliases In your new shell session, you have the following aliases defined:\nd.rymcg.tech d These are both the same, but for brevity, the rest of this documentation will prefer the d alias, but they can be used interchangeably.\n[bash]: Run this on your workstation: d (stdout) Found ROOT_DIR=/var/home/ryan/git/vendor/enigmacurry/d.rymcg.tech \\## Main d.rymcg.tech sub-commands - Optional arguments are printed in brackets [OPTIONAL_ARG] cd [SUBDIR] Enter a sub-shell and go to the ROOT_DIR directory create [PROJECT] [TEMPLATE] Create a new external project from a template make [PROJECT] [ARGS ...] Run a `make` command for the given d.rymcg.tech project name context View or set the current Docker context new-context Create a new Docker context ssh [COMMAND ...] Run command or shell on active docker context SSH host completion Setup TAB completion in your shell \\## Documentation sub-commands: help Show this help screen list List available d.rymcg.tech projects (not including external projects, unless you symlink them into ROOT_DIR) readme Open the main d.rymcg.tech README.md in your browser readme [PROJECT] Open the README.md for the given project name readme digitalocean Open root documentation file: DIGITALOCEAN.md readme security Open root documentation file: SECURITY.md readme aws Open root documentation file: AWS.md readme license Open root documentation file: LICENSE.txt readme raspberry_pi Open root documentation file: RASPBERRY_PI.md readme makefile_ops Open root documentation file: MAKEFILE_OPS.md ",
    "description": "Install d.rymcg.tech and its dependencies on your workstation.\nInstall dependent packages If you run Fedora workstations, run this as root dnf install bash gettext openssl git xdg-utils jq sshfs curl \\ inotify-tools httpd-tools make wireguard-tools If you run Debian/Ubuntu workstations, run this as root apt-get install bash build-essential gettext git openssl \\ apache2-utils xdg-utils jq sshfs wireguard curl \\ inotify-tools If you run Arch Linux workstations, run this as root pacman -S bash base-devel gettext git openssl apache xdg-utils \\ jq sshfs wireguard-tools curl inotify-tools Clone d.",
    "tags": [],
    "title": "Install d.rymcg.tech tools",
    "uri": "/d.rymcg.tech/workstation/install-d-rymcg-tech/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup Docker context",
    "content": "The base Debian image only has a few basic commands preinstalled. You must now install the Docker packages and enable the service:\nChoose the active Docker context d context [bash]: Run this on your workstation: d install-docker Tip d install-docker will install Docker on the remote VPS, according to your active docker context.\nTest that the context works from your workstation [bash]: Run this on your workstation: docker run hello-world [bash]: Run this on your workstation: docker ps ",
    "description": "The base Debian image only has a few basic commands preinstalled. You must now install the Docker packages and enable the service:\nChoose the active Docker context d context [bash]: Run this on your workstation: d install-docker Tip d install-docker will install Docker on the remote VPS, according to your active docker context.\nTest that the context works from your workstation [bash]: Run this on your workstation: docker run hello-world [bash]: Run this on your workstation: docker ps ",
    "tags": [],
    "title": "Install Docker on your remote host",
    "uri": "/d.rymcg.tech/docker-context/install-docker-on-remote-host/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "You will need the following hardware:\nAn x86_64 desktop or laptop computer. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, PGP keys, and logging into websites with Webauthn.) ",
    "description": "You will need the following hardware:\nAn x86_64 desktop or laptop computer. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, PGP keys, and logging into websites with Webauthn.) ",
    "tags": [],
    "title": "Requirements",
    "uri": "/linux-workstation/introduction/requirements/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "A DNS server maps your domain (and all subdomain) names to the various IP addresses of your servers. DNS is required for your users to be able to type (or click on) your domain name prod.example.com and have it resolve to the IP address that is required to contact your Docker server (prod). Beyond this, DNS is also a means of proving to a third party that you are the owner (controller) of your own domain, which is used as a part of the ACME challenge that Let’s Encrypt (or Step-CA) uses when signing your TLS certificates.\nNow that you have registered a domain name, you need to tell your registrar where your DNS server is. Usually you will use the DNS server that your cloud provider gives you, but you may choose any DNS provider you like. If you are creating a private server, you may still want to choose a public DNS server, but using private IP addresses ranges for the records. You can also setup a local/private DNS server, but this will be discussed later.\nFor the purposes of ACME (automatic TLS certificate issuing/renewals), your DNS server/provider will need to support one of the APIs supported by the go-lego project. Find out what API tokens or other settings your provider may need by by finding your provider in the list on that page.\nFor documentation purposes, this chapter will assume you are using Gandi.net as your domain registrar, and that you want to use DigitalOcean.com as your domain’s public DNS server (and digitalocean is supported by go-lego), but these instructions will be similar regardless of the supported provider you pick.\nConfigure your domain’s DNS server on Gandi.net Setup on Gandi.net Login to your gandi.net dashboard. Click the Domain tab. Find your domain name in the list and click on it. Click on the Nameservers tab. Click on the edit button to create new External nameservers. Delete all existing nameservers that may exist. Add the following nameservers, specific to DigitalOcean: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Wait a few minutes for the change to take effect, then you can verify the setting from your workstation, using the whois command:\n[bash]: Run this on your workstation: whois example.com (stdout) Domain Name: example.com Registrar WHOIS Server: whois.gandi.net Name Server: DNS1.EXAMPLE.NET Name Server: DNS2.EXAMPLE.NET Name Server: DNS3.EXAMPLE.NET Name Server: DNS4.EXAMPLE.NET The output shows a report for your domain registration, including the list of the new nameservers.\nAdd your domain on DigitalOcean.com Tip If you have the doctl client setup, run:\n[bash]: Run this on your workstation: DOMAIN=example.com doctl compute domain create ${DOMAIN} To list all your domains, run:\n[bash]: Run this on your workstation: doctl compute domain list How to do this in the DigitalOcean cloud console Signup for an account at DigitalOcean, if you haven’t already. Login to the cloud console. Click on the Networking tab in the menu. Click on the Domains tab. Enter your domain name into the box and click Add Domain. DigitalOcean is now in charge of your DNS for your domain. You will return to this screen later on, when creating individual subdomain records for your services.",
    "description": "A DNS server maps your domain (and all subdomain) names to the various IP addresses of your servers. DNS is required for your users to be able to type (or click on) your domain name prod.example.com and have it resolve to the IP address that is required to contact your Docker server (prod). Beyond this, DNS is also a means of proving to a third party that you are the owner (controller) of your own domain, which is used as a part of the ACME challenge that Let’s Encrypt (or Step-CA) uses when signing your TLS certificates.",
    "tags": [],
    "title": "Setup public DNS service",
    "uri": "/d.rymcg.tech/required-infrastructure/setup-dns/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "This section will guide you to create your own public Docker server, using a DigitalOcean droplet as an example. In a similar fashion, you can install Docker on any cloud provider, or dedicated host that you prefer.\nChoosing a VPS provider One of the most basic units of cloud computing is the Virtual Private Server (VPS). A VPS is a (Linux) virtual machine that is provisioned by a cloud service, and you are given root access to fully administer it, to install whatever you want on it. VPS generally come with a dedicated IP address and have a public internet connection, although some VPS only have NAT, but with dedicated port forwarding.\nIn this guide you will create a VPS with a DigitalOcean droplet.\nYou can install Docker on almost any Linux machine, but some are better than others. DigitalOcean droplets (VPS) are a good choice for experimenting, because they are billed hourly, and because the service layer has an integrated firewall, external to the droplet operating system. Having a firewall that is external (in front of) the VPS is one of the most important features to look for in a hosting provider.\nSetup your SSH key on DigitalOcean If you have not yet setup an SSH key on your workstation, read the Linux Workstation book and do that first.\nTip If you have the doctl client setup:\nList all your SSH keys:\n[bash]: Run this on your workstation: doctl compute ssh-key list Configure the SSH public key file you want to use:\n[bash]: Customize and set temporary environment variables SSH_KEY=~/.ssh/id_ed25519.pub Install the public key on DigitalOcean:\n[bash]: Run this on your workstation: (set -e test -f ${SSH_KEY} || (echo \"SSH key not found: ${SSH_KEY}\" \u0026\u0026 exit 1) SSH_TMP=$(mktemp) \u0026\u0026 chmod a+r ${SSH_TMP} cat ${SSH_KEY} \u003e ${SSH_TMP} doctl compute ssh-key import ${USER}@${HOSTNAME} --public-key-file ${SSH_TMP} rm -f ${SSH_TMP} ) How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Settings in the menu. Click on the Security tab. Click on the Add SSH Key button. Paste your public SSH key into the box. (copy your pub key from the output of ssh-add -L.) Enter a key name, I recommend this be the name of your workstation computer. Finish adding the key, click Add SSH Key. Create a DigitalOcean firewall template Tip If you have the doctl client setup:\n[bash]: Run this on your workstation: doctl compute firewall list [bash]: Run this on your workstation: (set -e FIREWALL_ID=$(doctl compute firewall create \\ --name \"ssh-web-https-wireguard\" \\ --inbound-rules \"protocol:tcp,ports:22,address:0.0.0.0/0\" \\ --no-header --format ID) doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --inbound-rules \"protocol:tcp,ports:80,address:0.0.0.0/0\" doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --inbound-rules \"protocol:tcp,ports:443,address:0.0.0.0/0\" doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --inbound-rules \"protocol:tcp,ports:51820,address:0.0.0.0/0\" doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --outbound-rules \"protocol:tcp,ports:0,address:0.0.0.0/0\" doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --outbound-rules \"protocol:udp,ports:0,address:0.0.0.0/0\" doctl compute firewall add-rules \"${FIREWALL_ID}\" \\ --outbound-rules \"protocol:icmp,ports:0,address:0.0.0.0/0\" echo ${FIREWALL_ID} ) How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Click the Firewalls tab. Click Create Firewall. Enter the name, eg. ssh-web-https-wireguard. Enter the following rules: SSH: Type: SSH Protocol: TCP Port Range: 22 Sources: All IPv4, All IPv6, or a specific static IP address if you want to be more secure. HTTP: Type: HTTP Protocol: TCP Port Range: 80 Sources: All IPv4, All IPv6. HTTPS: Type: HTTP Protocol: TCP Port Range: 443 Sources: All IPv4, All IPv6. Wireguard VPN (optional): Type: Custom Protocol: UDP Port Range: 51820 Sources: All IPv4, All IPv6. Click Create Firewall. Creating a DigitalOcean droplet for a Docker server DigitalOcean provides a Docker image with which to create a droplet (DigitalOcean’s name for their own VPS product).\nTip If you have the doctl client setup:\nSet variables to configure the droplet:\n[bash]: Customize and set temporary environment variables NAME=docker-dev IMAGE=debian-12-x64 REGION=nyc1 SIZE=s-1vcpu-2gb SSH_KEY=~/.ssh/id_ed25519.pub SSH_FINGERPRINT=$(ssh-keygen -E md5 -l -f ${SSH_KEY} | grep -Po \"MD5:\\K[a-f0-9\\:]+\") Create the droplet:\n[bash]: Run this on your workstation: DROPLET_ID=$(doctl compute droplet create \\ \"${NAME}\" \\ --image \"${IMAGE}\" \\ --size \"${SIZE}\" \\ --region \"${REGION}\" \\ --ssh-keys \"${SSH_FINGERPRINT}\" \\ --tag-names \"doctl-${USERNAME}@${HOST}\" \\ --wait --no-header --format ID) echo ${DROPLET_ID} How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Droplets in the menu. Click Create Droplet. Choose a Region (eg. New York), where the droplet will be created. Underneath the heading Choose an image, choose Debian (select the latest version). Choose a droplet size. 2GB RAM and 50GB disk recommended for medium size production installs. (It is tested working on as little as 512MB ram, if you enable zram and/or create a 1GB swapfile. Do not abuse swap space like this in production! However I think its fine for development use, but you may occasionally run into low memory issues if less than 1GB.) Optional: Add a block storage device, in order to store your Docker volumes. (This is useful to store data separate from the droplet lifecycle, or to have a larger amount of storage than the droplet size gives you for the root filesystem. If your basic droplet size is already sufficient, and you perform regular backups, this might not be needed.) Select your SSH key for the root user. Set the hostname for the docker server. The name should be short and typeable, as it will become a part of the canononical service URLs. For this example, we choose prod. Verify everything’s correct, and then click Create Dropet. Apply the DigitalOcean droplet firewall Tip If you have the doctl client setup:\n[bash]: Run this on your workstation: FIREWALL_ID=$(doctl compute firewall list | grep ssh-web-https-wireguard | cut -d \" \" -f1) doctl compute firewall add-droplets \\ \"${FIREWALL_ID}\" \\ --droplet-ids \"${DROPLET_ID}\" How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Find the firewall template you created, and click it. Click on the firewall’s Droplets tab. Click Add Droplets and search for the droplet you created and select it. Click Add Droplet to add the firewall to the droplet. Create wildcard DNS records for the droplet For the purposes of documentation, assume you you own the domain example.com and you have created the Docker server named prod. You should replace example.com with your actual domain name, and prod with your actual docker instance name/stage.\nTip If you have the doctl client setup:\nList all domains:\n[bash]: Run this on your workstation: doctl compute domain list [bash]: Customize and set temporary environment variables ROOT_DOMAIN=example.com HOST=docker-dev HOST_IP=$(doctl compute droplet get --no-header --format \"Public IPv4\" ${DROPLET_ID}) TTL=1800 List all records for ROOT_DOMAIN:\n[bash]: Run this on your workstation: doctl compute domain records list ${ROOT_DOMAIN} Create Host record:\n[bash]: Run this on your workstation: doctl compute domain records create \\ \"${ROOT_DOMAIN}\" \\ --record-type A \\ --record-name \"${HOST}\" \\ --record-data ${HOST_IP} \\ --record-ttl ${TTL} \\ --record-tag \"doctl-${USERNAME}@${HOST}\" Create Wildcard subdomain record:\n[bash]: Run this on your workstation: doctl compute domain records create \\ \"${ROOT_DOMAIN}\" \\ --record-type A \\ --record-name \"*.${HOST}\" \\ --record-data ${HOST_IP} \\ --record-ttl ${TTL} \\ --record-tag \"doctl-${USERNAME}@${HOST}\" How to do this in the DigitalOcean cloud console Login to the DigitalOcean cloud console. Click Networking in the menu. Click the Domains tab. Find the domain you created earlier, and click it. Create an A record: Hostname: enter the subdomain name without the domain part (eg. prod, the name of your docker server, without the .example.com suffix). Will direct to: select the droplet you created from the list. Click Create Record. Create another A record, for the wildcard: Hostname: enter the same name as before but prepend *. in front of it (eg. if the server is named prod, create a record for *.prod, without the .example.com suffix). Will direct to: select the same droplet as before. Click Create Record. Optional: create additional records on the root domain. If you don’t want the docker instance name in the subdomain you give to people (eg. www.prod.example.com), you could create additional (non-wildcard) records on the root domain now (eg. www.example.com, or even just example.com). However, it would be wasteful to put a wildcard record on the root domain (*.example.com) because then the domain could only be used with a single Docker instance, therefore all records on the root should be non-wildcard, and this means you must add them one by one. Test DNS Test that your wildcard record actually works. Use the dig command (For Debian/Ubuntu install the dnsutils package. For Arch Linux install bind-tools. For Fedora install bind-utils.)\nPick some random subdomain off your domain:\n[bash]: Run this on your workstation: dig laksdflkweieri.prod.example.com (stdout) ;; ANSWER SECTION: laksdflkweieri.prod.example.com. 3600 IN A 153.114.12.78 Since you created the wildcard record for *.prod.example.com dig should return your Docker server’s IP address in the ANSWER SECTION of the output. You can test all your other records the same way.\nIf you run into DNS caching problems, verify with the source DNS server directly:\n[bash]: Run this on your workstation: dig @ns1.digitalocean.com laksdflkweieri.prod.example.com Congratulations You have now finished installation of a remote host running Debian.\nYou must now configure your workstation to remotely control your remote Docker context.",
    "description": "This section will guide you to create your own public Docker server, using a DigitalOcean droplet as an example. In a similar fashion, you can install Docker on any cloud provider, or dedicated host that you prefer.\nChoosing a VPS provider One of the most basic units of cloud computing is the Virtual Private Server (VPS). A VPS is a (Linux) virtual machine that is provisioned by a cloud service, and you are given root access to fully administer it, to install whatever you want on it.",
    "tags": [],
    "title": "Create a public server (VPS)",
    "uri": "/d.rymcg.tech/required-infrastructure/public-docker-server/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Toolbox is an integral part of Fedora Atomic, being one of the main methods of installing software (the alternative being Flatpak), it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie. you can run ps or kill from inside the toolbox, and it will see/affect the host.) Toolbox containers are not sandboxed like normal Docker containers are, but they are a convenience for installing/removing software on Atomic hosts, because theres not really any other way (since the host filesystem is read-only). The applications you install in the container will live only inside the toolbox.\nThe killer feature of a toolbox is that it lets you try things out, and if you want to start over, you can just delete the toolbox container, and create a new one. You are less likely to mess up the host by playing around inside the toolbox. Just remember that /home is bind mounted to the host, and so if you change or delete things in those directories, they are also affected the same way on the host.\nDev toolbox (Fedora) Let’s create a toolbox to install some of the common development tools we will use on a daily basis.\n[bash]: Run this on your workstation: toolbox create dev This will create a new toolbox container called dev based upon the same Fedora version as the host (the toolbox itself is not Atomic though, but the normal Fedora Workstation version instead.)\nTo enter the toolbox run:\n[bash]: Run this on your workstation: toolbox enter dev This will enter the toolbox container, and now you can install extra software:\n[bash]: Run this on your workstation: sudo dnf install keychain htop sudo dnf groupinstall \"Development Tools\" \"Development Libraries\" Arch Linux toolbox You are not limited to running Fedora toolboxes, in fact you can run any container image you want, or even build your own from a Dockerfile. Here is a Dockerfile for Arch Linux you can use to build an Arch Linux toolbox container:\nEdit this file: Dockerfile FROM docker.io/archlinux/archlinux:latest ENV NAME=arch-toolbox VERSION=rolling LABEL com.github.containers.toolbox=\"true\" \\ name=\"$NAME\" \\ version=\"$VERSION\" RUN pacman -Syu --noconfirm \\ \u0026\u0026 pacman -S --noconfirm sudo inetutils less \\ git base-devel go \\ noto-fonts noto-fonts-cjk \\ noto-fonts-emoji noto-fonts-extra \\ \u0026\u0026 pacman -Scc --noconfirm \\ \u0026\u0026 echo \"%wheel ALL=(ALL) NOPASSWD: ALL\" \u003e /etc/sudoers.d/toolbox RUN sudo -u nobody git clone https://aur.archlinux.org/yay-bin.git /tmp/yay \\ \u0026\u0026 cd /tmp/yay \\ \u0026\u0026 sudo -u nobody makepkg -s \\ \u0026\u0026 pacman -U --noconfirm yay-bin-*.pkg.tar.zst CMD [\"bash\"] Write this to a file named Dockerfile and open your host terminal to the same directory. Then run this command to build the container:\n[bash]: Run this on your workstation: podman build -t arch . Now you can create a new toolbox based on the new image (both called arch):\n[bash]: Run this on your workstation: toolbox create --image arch arch To enter the Arch Linux container, run:\n[bash]: Run this on your workstation: toolbox enter arch Now that you’re inside the toolbox, you can run any Arch Linux command (consult the Arch Wiki).\nRun this inside the arch toolbox sudo pacman -Syu sudo pacman -S keychain base-devel Managing toolbox containers You can list all of your toolboxes that you’ve created:\n[bash]: Run this on your workstation: toolbox list You can remove existing toolboxes:\n[bash]: Run this on your workstation: toolbox rm --force arch (force is only required if the toolbox is currently running.)",
    "description": "Toolbox is an integral part of Fedora Atomic, being one of the main methods of installing software (the alternative being Flatpak), it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie.",
    "tags": [],
    "title": "Toolbox",
    "uri": "/linux-workstation/config/toolbox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "Create Debian VM on libvirt Follow the Linux Workstation book chapter on KVM / libvirt to install a Debian VM on your local workstation, and to create a local SSH config to connect to it.\nSetup DNS records for VM services You will need a DNS server to create (wildcard) records for all VM services. You can use the canonical DNS server on the internet, or you can use a local DNS resolver to override the name on the LAN.\nYou can follow the wildcard DNS record guide from the public VPS chapter, except instead of pointing to a droplet IP address, it will be your private VM (or workstation) IP address.\nUse the Traefik ACME DNS-01 challenge If you install Traefik Proxy on a non-public server, and you want to enable ACME for Let’s Encrypt TLS certificiates, make sure to configure ACME for the DNS-01 challenge type, as it is the only challenge type that will work for a server behind a restrictive LAN firewall.",
    "description": "Create Debian VM on libvirt Follow the Linux Workstation book chapter on KVM / libvirt to install a Debian VM on your local workstation, and to create a local SSH config to connect to it.\nSetup DNS records for VM services You will need a DNS server to create (wildcard) records for all VM services. You can use the canonical DNS server on the internet, or you can use a local DNS resolver to override the name on the LAN.",
    "tags": [],
    "title": "Create a private server (libvirt VM)",
    "uri": "/d.rymcg.tech/required-infrastructure/private-docker-server/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).\nTo enable this, you need to be running your dev toolbox:\n[bash]: Run this on your workstation: toolbox enter dev Install Emacs:\nrun this inside the toolbox: sudo dnf install emacs Create Emacs script In order to be able to quickly launch Emacs inside the toolbox from the host, you will need a little script installed on the host.\nYou can create this script and put it in /usr/local/bin/emacs. Run this on the host (not in the toolbox), to create it as the root user:\nEdit this file: /usr/local/bin/emacs #!/bin/bash ## Run Emacs in the dev toolbox and pass it any args: toolbox run -c dev emacs $@ [bash]: Run this on your workstation: sudo chmod a+x /usr/local/bin/emacs Now you can run Emacs from the host, and it will run inside the Toolbox.\nInstall dependencies Most Emacs packages are written in Emacs Lisp, and therefore have no external dependencies. The one exception is for Vterm terminal support, which requires compiling a C library (libvterm). This compilation can be done automatically by Emacs, but it requires you have some tools preinstalled:\nCMake libtool Install the dependencies inside the toolbox:\nrun this inside the toolbox sudo dnf install cmake libtool Remove any existing Emacs config Assuming you want to use my Emacs config, you need to delete any existing config you already have. Also note that Emacs creates a default config the first time it runs, so if you started Emacs already, you may have a config and not even know it.\nHere’s how to remove the existing Emacs config:\n[bash]: Run this on your workstation: rm ~/.emacs ~/.emacs.d -rf Install my Emacs config My Emacs config is on github. Install it with the following script:\n[bash]: Run this on your workstation: REMOTE=git@github.com:EnigmaCurry/emacs.git REPO=${HOME}/git/vendor/enigmacurry/emacs BRANCH=straight (set -e test -d ~/.emacs.d \u0026\u0026 (echo \"~/.emacs.d already exists. Aborting install.\" \u0026\u0026 exit 1) test -d ${REPO} || git clone -b ${BRANCH} ${REMOTE} ${REPO} mkdir ~/.emacs.d \u0026\u0026 ls -1 ${REPO}/*.el | xargs -iXX ln -s XX ~/.emacs.d mkdir ~/.emacs.d/straight \u0026\u0026 ln -s ${REPO}/straight-versions ~/.emacs.d/straight/versions ln -s ${REPO}/snippets ~/.emacs.d/snippets ) Start Emacs to finish the installation The first time Emacs starts, it will install all of the dependencies listed in the main config file ~/.emacs.d/init.el.\nRun:\n[bash]: Run this on your workstation: emacs Wait for everything to install. You may see a blank screen for up to 10 minutes, but you should see some minimal information of the progress in the bottom minibuffer.\nIf it gets stuck at any point, quit and restart it, and it should continue where it left off. If you get any error message, you may want to start Emacs again with debug mode turned on:\n[bash]: Run this on your workstation: emacs --debug-init This will usually give you a more verbose error message which can be helpful in debugging the startup.\nRead the README for my config More notes are available in the README.",
    "description": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).",
    "tags": [],
    "title": "Emacs",
    "uri": "/linux-workstation/config/emacs-on-fedora/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client. Create a server that acts as a bastion or “jump” host, to be a port of entry into a larger private network. SSH is configured to only allow authorized client keys access through the bastion host. Create a server to act as an HTTP (socks) client proxy, to allow remote clients to browse the web, using the server’s IP address as the origin. Remote controlling a Docker server using the docker command line client (SSH Docker Context). SSH is based upon public key cryptography. Both the client and the server need to create their own public/private keypair. Keys can be encrypted on disk (eg. ~/.ssh/id_ecdsa) or they may also be loaded from a USB hardware token. Upon connecting to a remote server for the first time, the client asks the user to validate the server’s public key fingerprint, and then the server’s public key is written into a file called ~/.ssh/known_hosts, which marks the connection as trusted from then on. The server also authorizes the client through a predefined authorized_keys file. If either side rejects the key presented by the other, the connection is unauthorized, and is closed immediately.\nCreate SSH Keys This book recommends the use of hardware authentication tokens, like the Solokey. Traditional SSH keyfiles are also acceptable, but these should be considered as a legacy format, as they are less secure. Finally, plain password authentication (non-key based) is fully deprecated and should never be used.\nSetup Solokey (FIDO2) hardware authentication Plug in your Solokey (or compatible hardware) to the USB port.\nInitialize the hardware with a new SSH key:\n[bash]: Run this on your workstation: ## You only need to do this one time per solokey! ssh-keygen -t ed25519-sk -O resident -O verify-required You will be required to create/enter a PIN for the Solokey.\nTraditional SSH keyfiles The Solokey still has some drawbacks, and cannot be used in all cases. Traditional SSH keyfiles are still useful for automated and unattended clients. Technically, the solokey is supposed to be able to work in a “touchless” mode, by using the -O no-touch-required option, but I never got this to work.\nKey files should be created uniquely for each user and workstation. They should never be shared between multiple users or workstations.\nChoosing the SSH key type It is recommended to use the newer ed25519 key type, which uses the latest encryption standards. Your distribution may still use the older standard rsa by default (which is acceptable). You should explicitly select the key type when creating the keyfile to be sure.\nSome older servers don’t accpet ed25519 keys, and so in those cases you should still create an rsa key as well. Each key type is stored in a different file, so its OK to have multiple types installed on the same machine.\nCreate the new SSH keys Create the rsa key type:\n[bash]: Run this on your workstation: ssh-keygen -t rsa -f ~/.ssh/id_rsa Create the ed25519 key type:\n[bash]: Run this on your workstation: ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 You will be prompted to enter an encryption passphrase for each file, which you should definitely not skip!\nSetup the ssh-agent Because your keyfiles are encrypted with a passphrase, you need to enter the passphrase everytime you use it. This is inconvenient, so you can run ssh-agent to temporarily store your key/identity in memory, and therefore you only need to enter your passphrase once, when you log in. (In the case of the solokey, the key is never held in memory, but you still need to hold the identity of it in the ssh-agent.)\nKeychain is a program that helps you setup the ssh-agent. Install keychain:\nRun this on your Fedora workstations: sudo dnf install keychain Run this on your Debian / Ubuntu workstations: sudo apt install keychain Run this on your Arch Linux workstations: sudo pacman -S keychain To configure keychain, edit your ~/.bashrc file:\nEdit this file: ~/.bashrc ## Put this line in your ~/.bashrc: ## (If you're using my config, this is already in it.) eval $(keychain --eval --quiet) Log out of your desktop session, and log back in. Open your terminal, and you should be automatically prompted to enter your SSH passphrase. Once you have entered the passphrase, the SSH key will remain resident in memory until you log out.\nDouble check that the key has been loaded, run:\nrun this inside your toolbox ssh-add -L The above should print your public key, loaded into the running ssh-agent. Now you should be able to use your key without entering a passphrase. Copy the output and upload it to your services as your authorized key. For servers, put the key into ~/.ssh/authorized_keys. For hosted services, like GitHub, paste the key into your SSH settings page.\nAdd your solokey identity per session Apparently, keychain does not yet know how to load the Solokey automatically. You must add the Solokey to the ssh-agent manually, one time, each time you boot your workstation:\nrun this inside your toolbox ## Do this to load your Solokey into the ssh-agent: ssh-add -K You will be prompted one time to enter your Solokey pin to unlock the key.",
    "description": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client.",
    "tags": [],
    "title": "SSH",
    "uri": "/linux-workstation/config/ssh/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup Docker context",
    "content": "Select your active Docker context [bash]: Run this on your workstation: d context Each Docker context has a separate config file (.env_{CONTEXT}), stored in the root d.rymcg.tech directory (~/git/vendor/enigmacurry/d.rymcg.tech), so you must actively select your current context before you can configure it.\nConfigure d.rymcg.tech for the current Docker context [bash]: Run this on your workstation: d make - config This will create a config file for your current Docker context, and name it .env_{CONTEXT} (eg. .env_prod). You must run this for each new Docker context you create, so that each context has its own config file.\nThe interactive config will ask you to enter the ROOT_DOMAIN variable, which needs to be the root domain that you want to apply to your Docker host.\n(stdout) ROOT_DOMAIN: Enter the root domain for this context (eg. d.example.com) : prod.example.com The root domain serves as the example root domain for all application default configs.",
    "description": "Select your active Docker context [bash]: Run this on your workstation: d context Each Docker context has a separate config file (.env_{CONTEXT}), stored in the root d.rymcg.tech directory (~/git/vendor/enigmacurry/d.rymcg.tech), so you must actively select your current context before you can configure it.\nConfigure d.rymcg.tech for the current Docker context [bash]: Run this on your workstation: d make - config This will create a config file for your current Docker context, and name it .",
    "tags": [],
    "title": "Setup d.rymcg.tech per Docker context",
    "uri": "/d.rymcg.tech/docker-context/main-config-for-d.rymcg/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "To remotely control a Docker server, you need to create a Docker context on your workstation, which is basically the SSH connection information to setup the docker socket connection.\nIndex Create SSH config and Docker context Install Docker on your remote host Setup d.rymcg.tech per Docker context ",
    "description": "To remotely control a Docker server, you need to create a Docker context on your workstation, which is basically the SSH connection information to setup the docker socket connection.\nIndex Create SSH config and Docker context Install Docker on your remote host Setup d.rymcg.tech per Docker context ",
    "tags": [],
    "title": "Setup Docker context",
    "uri": "/d.rymcg.tech/docker-context/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "Traefik Proxy (Traefik) is a core service, an application gateway, for all of the service containers installed on your Docker host. Traefik is an advanced software router: it can serve hundreds of deployed application containers (routes) at the same time. Traefik has a configuration provider that operates by discovery, so that when it is installed on a Docker host, it can automatically configure itself based upon the runtime settings of each individual application it finds. Each application becomes directly in charge of defining its own proxy rules, setting them as Docker container labels. Traefik will automatically discover these container labels (by permission of the host Docker socket), and configure itself for each application.\nTraefik is infrastructure. With Traefik installed, now each service container can take advantage of automatic TLS certificates (ACME), perform user authentication (mTLS, OAuth2, or HTTP Basic with group/certitficate sentry authorization), GeoIP tagging, and client IP address filtering middlewares. Based on all of this criteria, Traefik is in charge of deciding which incoming requests are to be allowed (and forwarded to the backend service containers), and which of these should be blocked (and an error returned to the client).\nIndex Traefik Quickstart (public VPS) ",
    "description": "Traefik Proxy (Traefik) is a core service, an application gateway, for all of the service containers installed on your Docker host. Traefik is an advanced software router: it can serve hundreds of deployed application containers (routes) at the same time. Traefik has a configuration provider that operates by discovery, so that when it is installed on a Docker host, it can automatically configure itself based upon the runtime settings of each individual application it finds.",
    "tags": [],
    "title": "Traefik Proxy",
    "uri": "/d.rymcg.tech/traefik-proxy/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "Whoami is a very simple application, but you can learn a lot from it. After you install Traefik, whoami should be the very first application that you install. It can help you test whether or not your Traefik installation is functioning properly.\nYou should study the configuration of whoami, as it is used as a template for all the other apps provided by d.rymcg.tech. Because of its simplicity, it reduces the complexity of its core components. Whoami can be a good base template for creating your own d.rymcg.tech enabled applications.\nWhat is Whoami? Quickstart Features Configuration Default config file (.env-dist) Configure whoami WHOAMI_TRAEFIK_HOST Sentry authorization Edit the config file by hand Configuration variables Install whoami Open whoami in your web browser View the logs What is Whoami? Whoami is a web application that simply outputs the request headers that it receives itself (reflecting them back to the requesting client):\n[bash]: Run this on your workstation: ## Use your own whoami URL here once you install it: curl https://whoami.example.com (stdout) Name: default Hostname: 38704012c4b3 IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:34610 GET / HTTP/1.1 Host: whoami.example.com User-Agent: curl/7.88.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 10.93.23.114 X-Forwarded-Host: whoami.example.com X-Forwarded-Port: 443 X-Forwarded-Proto: https X-Forwarded-Server: docker X-Real-Ip: 10.93.23.114 This output is useful for end-to-end testing, to verify that the application is capable of serving requests, and that all of the configuration is correct.\nQuickstart Create a new config:\n[bash]: Run this on your workstation: d make whoami config The first question the config asks for is WHOAMI_TRAEFIK_HOST which should be the fully qualified domain name that the whoami app will use for its URL:\n(stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com) ​: whoami.prod.rymcg.tech Optional authentication can be configured:\n(stdout) ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) For now, choose No, to disable authentication. We’ll get back to that later.\nInstall whoami:\n[bash]: Run this on your workstation: d make whoami install Open whoami:\n[bash]: Run this on your workstation: d make whoami open Or just open your web browser to the URL https://{WHOAMI_TRAEFIK_HOST}\nFeatures See the upstream whoami documentation and feature list here.\nIn addition to the features that whoami provides, there are several features that d.rymcg.tech provides through its own configuration and Traefik middlewares:\nRunning multiple separately-configured instances (Instantiation). Traefik sentry authorization per instance (mTLS, OAuth2, HTTP Basic auth). Source IP address filtering (blocking) per instance. Configuration Default config file (.env-dist) The default configuration file is named .env-dist. This config file is used as a template, which is copied whenever you configure a new instance of the application.\nTip The .env-dist file should not be edited normally. It should always contain the default configuration. Each instance will make its own copy of this, and it is inside the copy that you have the opportunity to change those defaults per instance (.env_{CONTEXT}_{INSTANCE}).\nEvery application instance has a unique config file, and the config target automatically creates one if necessary.\nConfigure whoami [bash]: Run this on your workstation: d make whoami config Info The config target configures the specific .env file of the instance: .env_{CONTEXT}_{INSTANCE}. Since we didn’t specify an instance name, the instance name is default. If your Docker context is named prod, then the full instance config file is named .env_prod_default.\nWarning You should not share the .env_{CONTEXT}_{INSTANCE} files. They should not be commited to the git repository. They are listed in the .gitignore file, so you should only have one copy of these files, living on your workstation. If these configs are important to you, you should make an encrypted backup.\nRun d make - backup-env to make a GPG encrypted backup file of all your .env files.\nTheres nothing particularly important inside the whoami .env files, but this is a general warning, as many apps will store their sensitive API keys or passwords in this file.\nConfigure multiple whoami instances Tip Most times you only need one instance of a given app, so you don’t need to set an instance name, and the name default will be used automatically.\nIf you want to configure multiple instances, run d make whoami instance for each one. You can configure unique names for each instance, and they will each have their own .env file: .env_{CONTEXT}_{INSTANCE}.\nd make whoami instance starts a sub-shell so that all commands will run on that instance now by default. Press Ctrl-D to exit the sub-shell, and it will go back to the original default instance (named default).\nWHOAMI_TRAEFIK_HOST The first question the config asks for is WHOAMI_TRAEFIK_HOST which is the fully qualified domain name that the whoami app should use for its URL:\n(stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com) ​: whoami.prod.rymcg.tech ﻿ The default name uses the ROOT_DOMAIN variable you set as part of the main d.rymcg.tech config, which is also named after our current Docker context (prod). Realistically, the WHOAMI_TRAEFIK_HOST may be set to any valid domain name, you just need to setup the DNS for it (to point to the IP address of the Docker host).\nSentry authorization Another question it asks you is about sentry authorization:\n(stdout) ? Do you want to enable sentry authorization in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) Sentry authorization is a collection of middlewares that are deployed in front of your application to allow specific users entry into your app, while denying others, based on a variety of authentication methods. It does not implement any fine-grained permissions in the application itself, but it does filter who can come in the front door. It provides the application with the verified username of the authenticated clients via the X-Forwarded-User HTTP header. Any application may implement additional fine-grained permissions based on this trusted header field.\nTo configure sentry authorization, you can choose any of these choices:\nIf you select No, then sentry authorization will be turned off. The X-Forwarded-User header field will always be blank. Any client will be able to access the application without authenticating (however the application may still perform authentication by itself). If you select Yes, with HTTP Basic Authentication, the application will require all clients to enter a username/password into a dialog presented by the web browser. Clients who enter an incorrect username or password will not be able to view the page. The X-Forwarded-User header field will be set to the username of the authenticated user. If you select Yes, with OAuth2, the application will require all clients to authenticate with another OAuth2 compatible application, which may be a self-hosted Forgejo instance, or it can be an external service like GitHub. Access is granted only to those users who are listed in the corresponding Traefik authorization group that the application is configured for. The X-Forwarded-User header field will be set to the email address of the user’s verified account. If you select Yes, with mTLS, the application will require all clients to authenticate with a client mTLS certificate. Access is granted only to those certificate names that are listed in the application’s config. The X-Forwarded-User header field will be set to the Common Name (CN) of the client certificate with the prefix CN= (eg. CN=client1.example.com) Edit the config file by hand Once the config script has finished, the config file may be inspected to verify valid settings:\n[bash]: Run this on your workstation: d make whoami config-edit This will automatically open the whoami config file for the current context/instance in your default text editor (eg. set EDITOR=/usr/bin/emacs in your ~/.bashrc file), and you may make any changes, and save the file again.\nYou can also open the file manually, the path is ~/git/vendor/enigmacurry/d.rymcg.tech/whoami/.env_{CONTEXT}_{INSTANCE}.\nConfiguration variables WHOAMI_TRAEFIK_HOST This sets the fully qualified domain name of the application.\nWHOAMI_INSTANCE This sets the name of the whoami instance. If left blank, the default name is default.\nWHOAMI_IP_SOURCERANGE This sets the acceptable IP addresses ranges for incoming requests. It is a comma separated list of CIDR formatted netmasks.\nHere are some example settings:\nWHOAMI_IP_SOURCERANGE=0.0.0.0/0 - allow any access from any IP address. WHOAMI_IP_SOURCERANGE=0.0.0.0/32 - allow NO access from any IP address. WHOAMI_IP_SOURCERANGE=192.168.1.0/24,10.3.4.0/24 - allow access ONLY from two different /24 networks (512 addresses in two ranges, comma separated): 192.168.1.0 to 192.168.1.255 10.3.4.0 to 10.3.4.255 WHOAMI_HTTP_AUTH If this is blank, sentry authorization with HTTP Basic Authentication will be disabled (default). Otherwise, this should set the Traefik BasicAuth authorized users list. Don’t attempt to edit this field by hand, as the syntax is very complex. Always use the d make whoami config tool to set it correctly.\nWHOAMI_OAUTH2 If this is blank, or set to false, then sentry authorization with OAuth2 will be disabled (default). If set to true then it will be enabled.\nYou must separately install Traefik Forward Auth\nWHOAMI_OAUTH2_AUTHORIZED_GROUP If WHOAMI_OAUTH2=true, then WHOAMI_OAUTH2_AUTHORIZED_GROUP must be set, which is the name of the authorization group that should be allowed access.\nTip Authorization groups are set separately in the Traefik config:\n[bash]: Run this on your workstation: d make traefik config Choose the menu Configure middleware (including auth).\nChoose the sub-menu OAuth2 sentry authorization (make sentry).\nCreate a new authorization group lists and add authorized email\naddresses.\nReinstall Traefik\nIn the whoami config, set WHOAMI_OAUTH2_AUTHORIZED_GROUP to the\nname of the group you created.\nWHOAMI_MTLS_AUTH If this is blank, or set to false, then sentry authorization with mTLS will be disabled (default). If set to true then it will be enabled.\nWHOAMI_MTLS_AUTHORIZED_CERTS If WHOAMI_MTLS_AUTH=true, then WHOAMI_MTLS_AUTHORIZED_CERTS must be set, which is the list of the certificates names (CN) that should be allowed.\nWildcards are allowed, so a good setting could be like *.clients.example.com to allow any client subdomain of clients.example.com.\nInstall whoami Once the configuration has been verified, you can install the application:\n[bash]: Run this on your workstation: d make whoami install Open whoami in your web browser Once installed, the application should be ready to view in your web browser:\n[bash]: Run this on your workstation: d make whoami open This will automatically open your default web browser to the URL of the installed whoami application. If you want to do so manually, just go to the same URL as you configured for WHOAMI_TRAEFIK_HOST.\nView the logs It may be necessary to inspect the applicaiton logs, which you can do so as follows:\n[bash]: Run this on your workstation: d make whoami logs ",
    "description": "Whoami is a very simple application, but you can learn a lot from it. After you install Traefik, whoami should be the very first application that you install. It can help you test whether or not your Traefik installation is functioning properly.\nYou should study the configuration of whoami, as it is used as a template for all the other apps provided by d.rymcg.tech. Because of its simplicity, it reduces the complexity of its core components.",
    "tags": [],
    "title": "Whoami",
    "uri": "/d.rymcg.tech/whoami/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Application users",
    "content": "doctl is the official DigitalOcean command line interface (CLI). It allows you to interact with the DigitalOcean API via the command line.\nYou should create a dedicated user for the doctl application, so that it can securely store the Personal Access Token for the DigitalOcean API. You can then access the privileged doctl command from your normal workstation account via sudo.\nCreate doctl user [bash]: Run this on your workstation: sudo useradd -s /bin/bash -m doctl Install doctl client Following the doctl install guide, install the doctl client directly in the home directory of the doctl user:\n[bash]: Run this on your workstation: DOCTL_VERSION=1.104.0 DOCTL_PLATFORM=linux-amd64 (set -e sudo curl -L -O --output-dir /usr/local/src https://github.com/digitalocean/doctl/releases/download/v${DOCTL_VERSION}/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz sudo tar -C ~doctl/ -x -f /usr/local/src/doctl-${DOCTL_VERSION}-${DOCTL_PLATFORM}.tar.gz sudo ~doctl/doctl completion bash | sudo tee /etc/profile.d/doctl_completion.sh ) Create app alias for normal user account In your normal workstation account, create this alias in your ~/.bashrc to make it more convenient to run doctl via sudo:\nEdit this file: ~/.bashrc ## DigitalOcean client (dotcl): alias doctl='sudo -u doctl ~doctl/doctl' ## Bash completion for dotcl: BASH_COMPLETION=/etc/profile.d/bash_completion.sh DOCTL_COMPLETION=/etc/profile.d/doctl_completion.sh test -f ${BASH_COMPLETION} \u0026\u0026 source ${BASH_COMPLETION} test -f ${DOCTL_COMPLETION} \u0026\u0026 source ${DOCTL_COMPLETION} Restart your terminal, and you can now use doctl from your normal account.\nCreate a Personal Access Token Read the offical documentation for creating tokens\nTokens allow programmatic access to the resources owned by a single Team.\nCreate a new Team, or choose an existing one. (If the domain name, or another resource you want to use, is already controlled by an existing team, choose that team). Create the new token for the team. Decide what scopes you want to allow the doctl user to access, or choose Full Access. Copy the token string to the clipboard. Register the client using the token, choose any context name (but it should reference your team name and/or role somehow):\n[bash]: Run this on your workstation: DOCTL_CONTEXT=my_team doctl auth init --context \"${DOCTL_CONTEXT}\" Use the doctl client Read the Self-hosting Docker book and setup a Docker server on DigitalOcean, using doctl.\nRead the doctl command reference.",
    "description": "doctl is the official DigitalOcean command line interface (CLI). It allows you to interact with the DigitalOcean API via the command line.\nYou should create a dedicated user for the doctl application, so that it can securely store the Personal Access Token for the DigitalOcean API. You can then access the privileged doctl command from your normal workstation account via sudo.\nCreate doctl user [bash]: Run this on your workstation: sudo useradd -s /bin/bash -m doctl Install doctl client Following the doctl install guide, install the doctl client directly in the home directory of the doctl user:",
    "tags": [],
    "title": "DigitalOcean CLI (doctl)",
    "uri": "/linux-workstation/app-users/digitalocean/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Having sudo privileges enabled for your normal workstation user account is both a convenience and a security concern. The Pluggable Authentication Module for Linux (PAM) allows us to strengthen the requirements for using sudo, to include several authentication methods beyond just asking for a password. This chapter will install pam_u2f, which enables PAM authentication via FIDO2/U2F compatible hardware tokens like the Solokey. Each time sudo asks for authentication, it will prompt for a Solokey button press and a password to be entered.\nCREDITS Some of this guide was adapted from these other guides:\nUsing Solokeys with Fedora Using YubiKeys with Fedora Thank you to the Fedora documentation team!\nOpen a root session as an anti-lockout measure To prevent yourself from being locked out of your own system during the setup process, it is recommended to start a new terminal in a root session, and to keep it open. That way if you lock yourself out, you still have a way you can fix it.\n[bash]: Run this on your workstation: ## Open root session and leave it alone in another window .... sudo su Consider adding a root password If you use sudo a lot, you might not actually know the real root password of your system (or one might not even be set). As a backup, you may want to set a secure long random passphrase for the root user and keep it safe (you will rarely need it).\nWarning Reset the root password with a random string:\n[bash]: Run this on your workstation: (set -e LENGTH=26 PASSWORD=$(tr -dc 'A-Za-z0-9!@#$%^\u0026*()[]~+-_=?\u003c\u003e.,;:' \u003c /dev/urandom | head -c ${LENGTH}) echo -e \"\\nSave this ${LENGTH} character long password somewhere safe: ${PASSWORD}\\n\" read -e -p \"Do you want to reset the root password with this value (y/N)? \" answer (test \"${answer,,}\" == \"y\" || test \"${answer,,}\" == \"yes\") \u0026\u0026 \\ sudo sh -c \"echo 'root:${PASSWORD}' | chpasswd \u0026\u0026 echo Done.\" || \\ echo \"Cancelled.\" ) Test that the root password works without using sudo:\n[bash]: Run this on your workstation: su Register Solokeys It is recommended that you register at least two solokeys: a primary key, and a backup key. That way, if you lose one of the keys, you can still use the other one.\nTip Do the next steps as your normal workstation user account, which is the account that should already have sudo privileges.\nCreate a tempory file to capture solo key registrations:\n[bash]: Customize and set temporary environment variables TMP_KEYS=$(mktemp) Plug in the first solokey, then run: [bash]: Run this on your workstation: pamu2fcfg \u003e\u003e ${TMP_KEYS} \u0026\u0026 \\ echo \u003e\u003e ${TMP_KEYS} It may ask you to enter the PIN of the solokey:\n(stdout) Enter PIN for /dev/hidraw1: When the solokey lights up, press the button.\nUnplug the first solokey and repeat the last command for the second solokey.\nUnplug the second solokey and repeat for additional solokeys.\nWhen you’ve written all the keys to ${TMP_KEYS}, reformat and install them into their final destination:\n[bash]: Run this on your workstation: echo \"${USER}:$(cat ${TMP_KEYS} | \\ cut -d \":\" -f 2 | tr '\\n' ':')\" | sed 's/:$//' | \\ sudo tee /etc/u2f_authorized_keys Create custom PAM modules for U2F You will create two new PAM modules: u2f-required and u2f-sufficient. They will both include these required settings:\nThe authfile path to our authorized key list file. The cue literal to show the Please touch the device prompt message for each authentication. (If you omit this, it will print nothing, which can be confusing). The only difference between the two PAM modules is that one is required, and the other is merely sufficient.\nrequired means to enable 2FA: solokey + password required. sufficient means to disable 2FA: solokey OR password is sufficient. [bash]: Run this on your workstation: cat \u003c\u003c EOF | sudo tee /etc/pam.d/u2f-required #%PAM-1.0 auth required pam_u2f.so authfile=/etc/u2f_authorized_keys cue EOF cat \u003c\u003c EOF | sudo tee /etc/pam.d/u2f-sufficient #%PAM-1.0 auth sufficient pam_u2f.so authfile=/etc/u2f_authorized_keys cue EOF Warning The PAM modules you just created (/etc/pam.d/u2f-required and /etc/pam.d/u2f-sufficient) can be used for extending any of the other pam modules found in /etc/pam.d, by adding an appropriate include line at the right place. This can affect many more system authentication methods than just sudo, so be careful, but only sudo will be covered for now.\nConfigure PAM hook for sudo As root, edit the file /etc/pam.d/sudo, and insert a new line directly after the #%PAM-1.0 header. A PAM module follows rules in top down order, as they are listed. Therefore your solokey rule needs to be the first authentication mechanism, and the existing password flow is the second authentication method.\nEdit this file: /etc/pam.d/sudo #%PAM-1.0 auth\tinclude u2f-required auth include system-auth account include system-auth password include system-auth session optional pam_keyinit.so revoke session required pam_limits.so session include system-auth Tip Line 2 (auth include u2f-required) is the only line that was added to this file. Everything else in this file was here originally and is left intact.\nWarning If you change u2f-required to u2f-sufficient, then it will disable 2FA allowing solokey press OR user password as sufficient!\nTest sudo Tip When testing sudo, always open a new terminal for each test. This is to avoid the auth caching mechanism (which is reset for new terminals).\n[bash]: Run this on your workstation: sudo The PAM system should now ask for you to touch your solokey (or press the button), and afterward prompt for your password.\n(stdout) Please touch the device. [sudo] password for ryan: ",
    "description": "Having sudo privileges enabled for your normal workstation user account is both a convenience and a security concern. The Pluggable Authentication Module for Linux (PAM) allows us to strengthen the requirements for using sudo, to include several authentication methods beyond just asking for a password. This chapter will install pam_u2f, which enables PAM authentication via FIDO2/U2F compatible hardware tokens like the Solokey. Each time sudo asks for authentication, it will prompt for a Solokey button press and a password to be entered.",
    "tags": [],
    "title": "Sudo with Solokey",
    "uri": "/linux-workstation/sudo-2fa/sudo-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication",
    "content": "Follow the chapter on SSH config.",
    "description": "Follow the chapter on SSH config.",
    "tags": [],
    "title": "SSH with Solokey",
    "uri": "/linux-workstation/sudo-2fa/ssh-2fa/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": "Switch to the libvirt user account Info For the rest of this section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: xhost +local:libvirt-admin sudo -u libvirt-admin /bin/bash Tip The xhost line is to allow graphical apps (virt-viewer) from the other user appear on your display. You may need to play with xhost a few times to get it to work. Try xhost + to temporarily allow all hosts to use the DISPLAY (and xhost - afterward to set it back). If you start the VM, and the virt-viewer fails to load, you can just fix it, try it again, and reconnect to an existing VM already running in the background.\nSource the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=coreos-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Download the ISO image: Tip You only need to download each ISO_MEDIA once, they will be cached in ~/libvirt/iso, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/iso curl -LO ${ISO_MEDIA} chmod a-w $(echo ${ISO_MEDIA} | grep -Po \".*/\\K.*$\") ) Create virtual disk Run this as the libvirt-admin user qemu-img create -f qcow2 ~/libvirt/disks/${NAME}.qcow2 ${DISK_SIZE}G Start VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --graphics spice \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --boot cdrom,hd,menu=on \\ --disk ~/libvirt/disks/${NAME}.qcow2 \\ --cdrom ~/libvirt/iso/$(echo ${ISO_MEDIA} | grep -Po \".*/\\K.*$\") Boot Fedora Workstation Live environment Once the VM starts, the virt-viewer window should open and display the virtual console of the VM.\nChoose Start Fedora-Workstation-Live.\nWelcome Wait a minute for the Welcome screen to appear. To use the Live environment, click Not Now.\nPress Alt-F2 to run a command Open the terminal by pressing Alt-F2 and then typing the name of the command: gnome-terminal.\nGnome Terminal Verify network IP address Run this in the Fedora Live environment ip addr show dev enp1s0 | grep inet (stdout) ... inet 192.168.122.5/24 brd 192.168.122.255 scope global dynamic noprefixroute enp1s0 ... Enable remote SSH access Run this in the Fedora Live environment sudo systemctl enable --now sshd Set the live user password Run this in the Fedora Live environment passwd Leave the virt-viewer window alone You’re now done needing to use the graphical console of the live environment, but until you’re done setting things up, you’ll need to leave it running for the time being. For now, just hide the window in another workspace (or minimize the window) but leave it running.\nTip I have noticed that the Live environment is set to go to sleep after a period of inactivity. If it goes to sleep, you may need to move/click the mouse inside the virt-viewer window to wake it up again. There’s probably a great command to disable this, but I don’t know it yet..\nLeave the libvirt-admin shell You’re also done with the libvirt-admin shell for now, press Ctrl-D to leave it. Proceed now, back to using the normal workstation shell.",
    "description": "Switch to the libvirt user account Info For the rest of this section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: xhost +local:libvirt-admin sudo -u libvirt-admin /bin/bash Tip The xhost line is to allow graphical apps (virt-viewer) from the other user appear on your display. You may need to play with xhost a few times to get it to work.",
    "tags": [],
    "title": "Boot VM from .iso",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/install-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Create VM from .iso image",
    "content": " Tip These commands should be run on your normal workstation account.\nConfigure variables to connect to Live environment [bash]: Customize and set temporary environment variables IP_ADDRESS=192.168.122.5 Copy SSH key to the liveuser [bash]: Run this on your workstation: ssh-copy-id liveuser@${IP_ADDRESS} When prompted, type the password that you set for the liveuser account.\nSSH into Live environment From your normal workstation account, connect to the SSH server of the Fedora Live environment:\n[bash]: Run this on your workstation: ssh liveuser@${IP_ADDRESS} Tip The reset of the commands in this section should be run in the Fedora Live environment.\nCreate Butane Config Butane is an intermediate tool used to generate the Ignition bootstrap file required for CoreOS.\nCreate a YAML config file that includes your public SSH keys:\nRun this in the Fedora Live environment (set -eo pipefail cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e fcos.yaml variant: fcos version: 1.5.0 passwd: users: ​ - name: core ssh_authorized_keys: EOF cat ~/.ssh/authorized_keys | xargs -iXX echo \" - XX\" \u003e\u003e fcos.yaml podman pull quay.io/coreos/butane:release podman run --rm --interactive \\ --security-opt label=disable \\ --volume ${PWD}:/pwd --workdir /pwd \\ quay.io/coreos/butane:release \\ --pretty --strict fcos.yaml \u003e fcos.ign ) Identify the storage device to install on Run this in the Fedora Live environment lsblk (stdout) NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS loop0 7:0 0 2G 1 loop loop1 7:1 0 8G 1 loop ├─live-rw 253:0 0 8G 0 dm / └─live-base 253:1 0 8G 1 dm loop2 7:2 0 32G 0 loop └─live-rw 253:0 0 8G 0 dm / sr0 11:0 1 2.1G 0 rom /run/initramfs/live zram0 251:0 0 956M 0 disk [SWAP] vda 252:0 0 25G 0 disk Tip For the default VM config, you can see the 25G device named vda.\n[bash]: Customize and set temporary environment variables DEVICE=vda Install Fedora CoreOS onto the storage device Run this in the Fedora Live environment sudo podman run --pull=always --privileged --rm \\ -v /dev:/dev -v /run/udev:/run/udev -v .:/data -w /data \\ quay.io/coreos/coreos-installer:release \\ install /dev/${DEVICE} -i fcos.ign Shutdown Fedora Live environment CoreOS is now installed, so you can now shutdown the Fedora Live environment:\nRun this in the Fedora Live environment sudo poweroff This will immediately restart the VM and CoreOS should now boot. If successful you should see the console print the following information:\n(stdout) enp1s0: 192.168.122.5 .... Ignition: user-provided config was applied Ignition: wrote ssh authorized keys file for user: core Close virt-viewer window. Shutdown CoreOS VM [bash]: Customize and set temporary environment variables NAME=coreos-dev [bash]: Run this on your workstation: sudo XDG_RUNTIME_DIR=/var/run/user/$(id -u libvirt-admin) -u libvirt-admin \\ virsh destroy ${NAME} Edit VM config Create an XSLT template that will perform the necessary edits to remove the CD-ROM disk and graphics adapter entries:\n[bash]: Run this on your workstation: cat \u003c\u003c EOF \u003e edit-coreos-vm.xslt.xml \u003cxsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\u003e \u003cxsl:output omit-xml-declaration=\"yes\"/\u003e \u003cxsl:template match=\"node()|@*\"\u003e \u003cxsl:copy\u003e \u003cxsl:apply-templates select=\"node()|@*\"/\u003e \u003c/xsl:copy\u003e \u003c/xsl:template\u003e \u003cxsl:template match=\"bootmenu[@enable='yes']\"/\u003e \u003cxsl:template match=\"boot[@dev='cdrom']\"/\u003e \u003cxsl:template match=\"disk[@device='cdrom']\"/\u003e \u003cxsl:template match=\"channel[@type='spicevmc']\"/\u003e \u003cxsl:template match=\"graphics\"/\u003e \u003cxsl:template match=\"sound\"/\u003e \u003cxsl:template match=\"audio\"/\u003e \u003cxsl:template match=\"redirdev[@type='spicevmc']\"/\u003e \u003cxsl:template match=\"video\"/\u003e \u003c/xsl:stylesheet\u003e EOF Redefine the VM using the edited config:\n[bash]: Run this on your workstation: (set -e virsh dumpxml ${NAME} | xsltproc edit-coreos-vm.xslt.xml - \u003e ${NAME}.xml virsh define ${NAME}.xml ) Enable systemd service to start VM [bash]: Run this on your workstation: sudo systemctl enable --now libvirt@${NAME} sudo systemctl status libvirt@${NAME} Create SSH config Create a Host entry in your ~/.ssh/config file to make connections easy:\nEdit this file: ~/.ssh/config Host coreos-dev Hostname 192.168.122.5 User core ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Remove the old host keys from the live user environment for your ~/.ssh/known_hosts file:\n[bash]: Run this on your workstation: ssh-keygen -R ${IP_ADDRESS} Test logging into the VM from your workstation:\n[bash]: Run this on your workstation: ssh coreos-dev Install Docker Docker comes preinstalled on CoreOS, you just have to enable it:\n[bash]: Run this on your workstation: ssh coreos-dev sudo gpasswd -a core docker ssh coreos-dev sudo systemctl enable --now docker Warning Because of the ControlMaster config, you will need to kill your existing connection to reload the session, and load new groups.\n[bash]: Run this on your workstation: ssh -O exit coreos-dev Then check your groups again, to be sure it includes docker:\n[bash]: Run this on your workstation: ssh coreos-dev groups (stdout) core adm wheel sudo systemd-journal docker Next, follow the Self-Hosting Docker book to setup this VM as a Docker context on your workstation.",
    "description": "Tip These commands should be run on your normal workstation account.\nConfigure variables to connect to Live environment [bash]: Customize and set temporary environment variables IP_ADDRESS=192.168.122.5 Copy SSH key to the liveuser [bash]: Run this on your workstation: ssh-copy-id liveuser@${IP_ADDRESS} When prompted, type the password that you set for the liveuser account.\nSSH into Live environment From your normal workstation account, connect to the SSH server of the Fedora Live environment:",
    "tags": [],
    "title": "Bootstrap CoreOS",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/bootstrap-coreos/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": " Index Configure VM (cloud-init) Create VM (cloud-init) ",
    "description": " Index Configure VM (cloud-init) Create VM (cloud-init) ",
    "tags": [],
    "title": "Cloud-Init VMs",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Cloud-Init VMs",
    "content": "Choose a name [bash]: Customize and set temporary environment variables NAME=debian-dev Choose hardware sizes [bash]: Customize and set temporary environment variables MEMORY=1024 CPUS=2 DISK_SIZE=50 Choose cloud image You can choose any standard cloud image that supports cloud-init.\nDebian 12 [bash]: Customize and set temporary environment variables OS_VARIANT=debian12 CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2 Tip On slighly older versions of libvirt, you may need to set OS_VARIANT differently, but the image should still work:\n[bash]: Customize and set temporary environment variables OS_VARIANT=debian11\nFedora 40 [bash]: Customize and set temporary environment variables OS_VARIANT=fedora40 CLOUD_IMAGE=https://download.fedoraproject.org/pub/fedora/linux/releases/40/Cloud/x86_64/images/Fedora-Cloud-Base-Generic.x86_64-40-1.14.qcow2 Find the default subnet (virbr0) [bash]: Run this on your workstation: ip route | grep virbr0 | cut -d \" \" -f 1 (stdout) 192.168.122.0/24 Configure IP Address and MAC address [bash]: Customize and set temporary environment variables IP_ADDRESS=192.168.122.2 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Tip You need to choose a valid IP_ADDRESS in the range of your subnet, although on every machine I’ve tried this on so far, the default has been 192.168.122.0/24. The MAC address will be randomized to create a static lease.\nCreate static DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Tip You can edit the file manually to do more cleanup. After editing, you must stop (destroy) and restart the network.\n[bash]: Run this on your workstation: sudo virsh net-edit default sudo virsh net-destroy default sudo rm /var/lib/libvirt/dnsmasq/virbr0.status sudo virsh net-start default sudo virsh net-dhcp-leases default Create env file to store main config settings [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export CLOUD_IMAGE=${CLOUD_IMAGE} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} export USER_DATA=~/libvirt/cloud-init/${NAME}.yaml EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Tip This will create a new config file in the libvirt-admin user’s home directory ~/libvirt/${NAME}.env.",
    "description": "Choose a name [bash]: Customize and set temporary environment variables NAME=debian-dev Choose hardware sizes [bash]: Customize and set temporary environment variables MEMORY=1024 CPUS=2 DISK_SIZE=50 Choose cloud image You can choose any standard cloud image that supports cloud-init.\nDebian 12 [bash]: Customize and set temporary environment variables OS_VARIANT=debian12 CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2 Tip On slighly older versions of libvirt, you may need to set OS_VARIANT differently, but the image should still work:\n[bash]: Customize and set temporary environment variables OS_VARIANT=debian11",
    "tags": [],
    "title": "Configure VM (cloud-init)",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/config-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Raw disk VMs",
    "content": "Configure VM with raw disk image [bash]: Customize and set temporary environment variables RAW_DISK=https://download.fedoraproject.org/pub/alt/iot/40/IoT/x86_64/images/Fedora-IoT-raw-40-20240422.3.x86_64.raw.xz NAME=fedora-iot OS_VARIANT=fedora40 MEMORY=2048 CPUS=2 DISK_SIZE=30 IP_ADDRESS=192.168.122.6 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Copy config to libvirt-user account [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export RAW_DISK=${RAW_DISK} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_ENV} ~/libvirt/${NAME}.env\" Tip This will create a new config file in the libvirt-admin user’s home directory ~/libvirt/${NAME}.env.",
    "description": "Configure VM with raw disk image [bash]: Customize and set temporary environment variables RAW_DISK=https://download.fedoraproject.org/pub/alt/iot/40/IoT/x86_64/images/Fedora-IoT-raw-40-20240422.3.x86_64.raw.xz NAME=fedora-iot OS_VARIANT=fedora40 MEMORY=2048 CPUS=2 DISK_SIZE=30 IP_ADDRESS=192.168.122.6 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] | tr '[:upper:]' '[:lower:]') Create DHCP lease [bash]: Run this on your workstation: sudo virsh net-update default add-last ip-dhcp-host \"\u003chost mac='${MAC_ADDRESS}' name='${NAME}' ip='${IP_ADDRESS}' /\u003e\" --live --config --parent-index 0 Copy config to libvirt-user account [bash]: Run this on your workstation: TMP_ENV=$(mktemp) cat \u003c\u003c EOF \u003e ${TMP_ENV} export NAME=${NAME} export OS_VARIANT=${OS_VARIANT} export IP_ADDRESS=${IP_ADDRESS} export MAC_ADDRESS=${MAC_ADDRESS} export RAW_DISK=${RAW_DISK} export MEMORY=${MEMORY} export CPUS=${CPUS} export DISK_SIZE=${DISK_SIZE} EOF chmod a+r ${TMP_ENV} sudo su ${VM_ADMIN:-libvirt-admin} -c \\ \"",
    "tags": [],
    "title": "Configure VM (raw disk)",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/config/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Cloud-Init VMs",
    "content": " Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=debian-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Create the cloud-init config file: Run this as the libvirt-admin user cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e ${USER_DATA} #cloud-config hostname: ${NAME} users: ​ - name: root ssh_authorized_keys: ​ - $(cat ~/libvirt/user-ssh.pub) EOF Download the cloud image: Tip You only need to download each CLOUD_IMAGE once, they will be cached in ~/libvirt/cloud-images, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/cloud-images curl -LO ${CLOUD_IMAGE} chmod a-w $(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*$\") ) Clean up old VMs with the same name: Warning If you already have a VM with the same name, and you want to start again from scratch, you need to clean up from the previous install first:\nRun this as the libvirt-admin user ## To cleanup and REMOVE an old VM named debian-dev: virsh destroy debian-dev virsh managedsave-remove debian-dev virsh undefine debian-dev Create the disk image for the new VM: Warning This is destructive of the existing disk file!\nRun this as the libvirt-admin user (set -e cp ~/libvirt/cloud-images/$(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*\") \\ ~/libvirt/disks/${NAME}.qcow2 chmod u+w ~/libvirt/disks/${NAME}.qcow2 qemu-img resize ~/libvirt/disks/${NAME}.qcow2 +${DISK_SIZE}G echo Created ~/libvirt/disks/${NAME}.qcow2 ) Create the VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --graphics none \\ --console pty,target_type=serial \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --cloud-init user-data=${USER_DATA} \\ --import \\ --disk ~/libvirt/disks/${NAME}.qcow2 Watch the console for any errors As the VM starts up, your terminal will attach to the console output of the VM. This is to monitor any errors that may occur during the bootup, especially relating to cloud-init.\nWait until you see this Login message:\n(stdout) debian-dev login: Disconnect from the VM console To disconnect from the VM console, press the keyboard combination Ctrl+] (meaning to hold the Control key and the right square bracket key at the same time.)\nShutdown the VM Info It is important to shut down the VM the first time after install, otherwise you will get an error about the unejected cloud-init ISO.\nRun this as the libvirt-admin usre virsh shutdown ${NAME} Verify VM is shut down Run this as the libvirt-admin user virsh list --all (stdout) ​ Id Name State ​----------------------------- ​ - debian-dev shut off Before proceeding to the next step, make sure the VM is in the off state.",
    "description": "Info For this entire section you need to perform the VM config as the libvirt-admin user. Login to the shell account of libvirt-admin: [bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file: Run this as the libvirt-admin user NAME=debian-dev source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,disks,cloud-init,iso} Create the cloud-init config file: Run this as the libvirt-admin user cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e ${USER_DATA} #cloud-config hostname: ${NAME} users: ​ - name: root ssh_authorized_keys: ​ - $(cat ~/libvirt/user-ssh.",
    "tags": [],
    "title": "Create VM (cloud-init)",
    "uri": "/linux-workstation/kvm-libvirt/cloud-init/create-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt \u003e Raw disk VMs",
    "content": " Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=fedora-iot source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,raw,disks,cloud-init,iso} Download the raw disk: Tip You only need to download each RAW_DISK once, they will be cached in ~/libvirt/raw, so they can be be reused.\nRun this as the libvirt-admin user (set -e cd ~/libvirt/raw curl -LO ${RAW_DISK} chmod a-w $(echo ${RAW_DISK} | grep -Po \".*/\\K.*$\") ) Create the disk image for the new VM: Warning This is destructive of the existing disk file!\nRun this as the libvirt-admin user (set -e xzcat ~/libvirt/raw/$(echo ${RAW_DISK} | grep -Po \".*/\\K.*\") \\ \u003e ~/libvirt/disks/${NAME}.raw chmod u+w ~/libvirt/disks/${NAME}.raw echo Created ~/libvirt/disks/${NAME}.raw ) Create the VM Run this as the libvirt-admin user virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --graphics vnc,port=5901,listen=127.0.0.1 \\ --console pty,target_type=serial \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --import \\ --disk ~/libvirt/disks/${NAME}.raw,format=raw Watch the console for any errors As the VM starts up, your terminal will attach to the console output of the VM. This is to monitor any errors that may occur during the bootup, especially relating to cloud-init.\nWait until you see this Login message:\n(stdout) debian-dev login: Disconnect from the VM console To disconnect from the VM console, press the keyboard combination Ctrl+] (meaning to hold the Control key and the right square bracket key at the same time.)\nShutdown the VM Info It is important to shut down the VM the first time after install, otherwise you will get an error about the unejected cloud-init ISO.\nRun this as the libvirt-admin usre virsh shutdown ${NAME} Verify VM is shut down Run this as the libvirt-admin user virsh list --all (stdout) ​ Id Name State ​----------------------------- ​ - debian-dev shut off Before proceeding to the next step, make sure the VM is in the off state.",
    "description": "Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su libvirt-admin -l Source the config Now, and anytime you come back later to work on the same VM, source the config file:\nRun this as the libvirt-admin user NAME=fedora-iot source ~/libvirt/${NAME}.env Create directories to hold the VM disks and config files: Run this as the libvirt-admin user mkdir -p ~/libvirt/{cloud-images,raw,disks,cloud-init,iso} Download the raw disk: Tip You only need to download each RAW_DISK once, they will be cached in ~/libvirt/raw, so they can be be reused.",
    "tags": [],
    "title": "Create VM (raw disk)",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/create-vm/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Idealistically, the introduction declared a “No Sworkstations” rule (No Server-Workstations). Pragmatically, you can bend this rule a bit, by hosting some development servers inside of virtual machines (VM). Hosting VMs on your workstation is convenient for having a portable lab environment. By using virtual machines for all services, we get to maintain our core distinction between the roles of workstation and server.\nThis paradigm is considerably more adhoc than a proper hypervisor operating system like Proxmox. For pure server installs, Proxmox should be preferred. But if you want to have a mixed-mode native workstation, with extra server VMs, in the same portable platform, this setup works really well.\nUsing this config, your workstation will stay relatively pure, because these VMs are isolated from your normal account. They are automatically started on boot, running under a dedicated VM user account (libvirt-admin). You can treat these VMs just like any other remote Linux host. From your normal workstation account, you can access the VM’s root shell, over (local) SSH connection, and you can remotely install Docker on these target VMs.\nThese instructions will cover installing libvirt, and creating a barebones Debian or Fedora VM (but any cloud-init image should work), inside of a private host-only network (No public ports are open by default, but outgoing internet access is allowed). This is mainly for local development/testing purposes only, but near the end of this chapter, you’ll get to decide if you’d like to bend this rule too, and open the VMs up to public (LAN) routes for production-lite roles.\nGuest OS compatibility The following guest Linux distributions, have been tested as working:\n✅ Debian 12 cloud image ✅ Fedora 40 cloud image ✅ Ubuntu 24.04 cloud image These instructions should work for any operating system that is shipped as a “Cloud” image (Cloud-Init image).\nHost workstation compatibility The following host Linux distributions, have been tested as working (only x86_64 tested so far):\n✅ Fedora Atomic Workstation (40) ✅ Fedora Server (40) ✅ Fedora CoreOS (40) ✅ Arch Linux The following host Linux distributions have some issues:\n🚧 Debian (12) hosts are only partially compatible, I have not been able to get the autostart service to run, due to an app armor permission issue, however the VMs do run if you start them manually. Index Install libvirtd Setup libvirtd Create VM admin Cloud-Init VMs Configure VM (cloud-init) Create VM (cloud-init) Systemd services to control VMs Public routes to VMs Setup workstation SSH config ",
    "description": "Idealistically, the introduction declared a “No Sworkstations” rule (No Server-Workstations). Pragmatically, you can bend this rule a bit, by hosting some development servers inside of virtual machines (VM). Hosting VMs on your workstation is convenient for having a portable lab environment. By using virtual machines for all services, we get to maintain our core distinction between the roles of workstation and server.\nThis paradigm is considerably more adhoc than a proper hypervisor operating system like Proxmox.",
    "tags": [],
    "title": "KVM / libvirt",
    "uri": "/linux-workstation/kvm-libvirt/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "If you OS is not packaged as a cloud-init enabled image, you can boot a raw disk image instead. The example will install Fedora IoT (40) from raw disk image.\nIndex ",
    "description": "If you OS is not packaged as a cloud-init enabled image, you can boot a raw disk image instead. The example will install Fedora IoT (40) from raw disk image.\nIndex ",
    "tags": [],
    "title": "Raw disk VMs",
    "uri": "/linux-workstation/kvm-libvirt/raw-disk/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example of a deeply …",
    "uri": "/publishing-with-org-mode/examples/deeply/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "Systemd services can provide an easy way to manage the on/off state of the VMs (systemctl start/stop), and can (optionally) start VMs automatically when the host system boots.\nWarning libvirt has its own autostart feature, but we’re not using that, because I couldn’t get it to work in user session mode. Systemd units per VM feels nicer anyway.\nDownload libvirt python interface Tip You should now be in your normal workstation account Bash shell.\n[bash]: Run this on your workstation: (set -e sudo mkdir -p /usr/local/src/ sudo su -c \"cd /usr/local/src \u0026\u0026 git clone https://github.com/EnigmaCurry/virsh-start-stop\" ) CREDITS EnigmaCurry/virsh-start-stop is my own fork of avollmerhaus/virsh-start-stop which has been slightly customized for this configuration. Thank you to avollmerhaus for creating this service manager!\nCreate Unit template This is an instantiable template used for all VM services:\n[bash]: Run this on your workstation: VM_ADMIN=${VM_ADMIN:-libvirt-admin} cat \u003c\u003c EOF | sudo tee /etc/systemd/system/libvirt@.service [Unit] Description=${VM_ADMIN} VM: %i Requires=libvirtd.service After=libvirtd.service [Service] Type=oneshot RemainAfterExit=true User=${VM_ADMIN} Group=libvirt Environment=\"XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})\" ExecStart=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state started ExecStop=/usr/bin/python /usr/local/src/virsh-start-stop/src/virsh_start_stop/virsh_start_stop.py --machine %i --state stopped [Install] WantedBy=default.target EOF Enable each VM service This will instantiate the VM service template, and enable a VM named debian-dev, which will automatically start on workstation boot:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl enable --now libvirt@${NAME} sudo systemctl status libvirt@${NAME} ",
    "description": "Systemd services can provide an easy way to manage the on/off state of the VMs (systemctl start/stop), and can (optionally) start VMs automatically when the host system boots.\nWarning libvirt has its own autostart feature, but we’re not using that, because I couldn’t get it to work in user session mode. Systemd units per VM feels nicer anyway.\nDownload libvirt python interface Tip You should now be in your normal workstation account Bash shell.",
    "tags": [],
    "title": "Systemd services to control VMs",
    "uri": "/linux-workstation/kvm-libvirt/systemd/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication \u003e Solokey v1",
    "content": "I know of two places to buy solokeys:\nhttps://solokeys.com/collections/all https://www.crowdsupply.com/solokeys/somu#products What to buy:\nRecommended: Solo 1 Tap USB-A (durable clicky button, but sticks out of the USB port). Recommended: Somu (semi-permanent flush mount USB-A port, soft touch design). Get the “secure” version, don’t buy the “hacker” version. Buy at least two (and store one as a backup). ",
    "description": "I know of two places to buy solokeys:\nhttps://solokeys.com/collections/all https://www.crowdsupply.com/solokeys/somu#products What to buy:\nRecommended: Solo 1 Tap USB-A (durable clicky button, but sticks out of the USB port). Recommended: Somu (semi-permanent flush mount USB-A port, soft touch design). Get the “secure” version, don’t buy the “hacker” version. Buy at least two (and store one as a backup). ",
    "tags": [],
    "title": "Get your Solokey (v1)",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/get-your-solokey/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication \u003e Solokey v1",
    "content": "Create Python environment for solokey [bash]: Run this on your workstation: SOLO_ROOT=~/git/vendor/solokeys (set -e git clone https://github.com/solokeys/solo1-cli \\ ${SOLO_ROOT}/solo1-cli ) Lock Fido2 version to 0.9.1 to fix outstanding bugs Warning Double check if these outstanding bugs are still open:\nhttps://github.com/solokeys/solo1-cli/issues/151 https://github.com/solokeys/solo1-cli/discussions/156 Both of these are related to Fido2 v1.0.0. If you lock the version to the last known good version of 0.9.1, it will work:\n[bash]: Run this on your workstation: sed -i 's/fido2 \u003e= 0.9.1/fido2 == 0.9.1/' ${SOLO_ROOT}/solo1-cli/pyproject.toml Build solo1 key environment [bash]: Run this on your workstation: python -m venv ${SOLO_ROOT}/env ${SOLO_ROOT}/env/bin/pip3 install -e ${SOLO_ROOT}/solo1-cli Add solo alias to your .bashrc Edit this file: ~/.bashrc alias solo=${HOME}/git/vendor/solokeys/env/bin/solo1 Restart your shell to load the new alias.",
    "description": "Create Python environment for solokey [bash]: Run this on your workstation: SOLO_ROOT=~/git/vendor/solokeys (set -e git clone https://github.com/solokeys/solo1-cli \\ ${SOLO_ROOT}/solo1-cli ) Lock Fido2 version to 0.9.1 to fix outstanding bugs Warning Double check if these outstanding bugs are still open: https://github.com/solokeys/solo1-cli/issues/151 https://github.com/solokeys/solo1-cli/discussions/156 Both of these are related to Fido2 v1.0.0. If you lock the version to the last known good version of 0.9.1, it will work: [bash]: Run this on your workstation: sed -i 's/fido2 \u003e= 0.",
    "tags": [],
    "title": "Install Solokey CLI (v1) tool",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/install-solo-cli/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication \u003e Solokey v1",
    "content": "Plug your solokey into the USB port Identify your solokey [bash]: Run this on your workstation: solo ls (stdout) :: Solos AABBCC00112233: SoloKeys Solo 4.1.5 Update the firmware Check for the latest release of solo v1 and compare it to the version that is reported by solo ls. If your solokey is not running the latest version, it is recommended to update it.\nEnter bootloader mode:\n[bash]: Run this on your workstation: solo program aux enter-bootloader The solokey should now be rapidly flashing to indicate it is in boot loader mode.\nUpdate the firmware:\n[bash]: Run this on your workstation: solo key update (stdout) ... Congratulations, your key was updated to the latest firmware version: 4.1.5 ",
    "description": "Plug your solokey into the USB port Identify your solokey [bash]: Run this on your workstation: solo ls (stdout) :: Solos AABBCC00112233: SoloKeys Solo 4.1.5 Update the firmware Check for the latest release of solo v1 and compare it to the version that is reported by solo ls. If your solokey is not running the latest version, it is recommended to update it.\nEnter bootloader mode:\n[bash]: Run this on your workstation: solo program aux enter-bootloader The solokey should now be rapidly flashing to indicate it is in boot loader mode.",
    "tags": [],
    "title": "Update your Solokey (v1)",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/update-solokey/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Solokey authentication \u003e Solokey v1",
    "content": "Reset solokey (recommended first time only) Warning This will wipe all identity from the solokey device!\n[bash]: Run this on your workstation: solo key reset Set device PIN [bash]: Run this on your workstation: solo key set-pin Tip This will only work if the device does not already have a pin (which is the state it is in after a reset).\nIf you want to change the PIN which was already set:\n[bash]: Run this on your workstation: solo key change-pin Verify PIN [bash]: Run this on your workstation: solo key verify (stdout) PIN: Please press the button on your Solo key Register valid Valid Solo with firmware from SoloKeys. ",
    "description": "Reset solokey (recommended first time only) Warning This will wipe all identity from the solokey device!\n[bash]: Run this on your workstation: solo key reset Set device PIN [bash]: Run this on your workstation: solo key set-pin Tip This will only work if the device does not already have a pin (which is the state it is in after a reset).\nIf you want to change the PIN which was already set:",
    "tags": [],
    "title": "Program your Solokey (v1)",
    "uri": "/linux-workstation/sudo-2fa/solo-v1/program-solokey/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "By default, all incoming traffic to the VMs must originate from your workstation (or another VM on your workstation) - no traffic is routed to your VMs from any other interface.\nIf you want to break this rule, and allow public routes into these VMs (DNAT port forwarding), you will need to install the libvirt hook that sets up the iptables forwarding rules:\nDownload the port-forwarding hook [bash]: Run this on your workstation: sudo mkdir -p /usr/local/src/ sudo su -c \"cd /usr/local/src \u0026\u0026 git clone https://github.com/EnigmaCurry/libvirt-hook-qemu.git\" CREDITS EnigmaCurry/libvirt-hook-qemu is my own fork of saschpe/libvirt-hook-qemu which has been slightly customized for this configuration. Thank you to Sascha Peilicke for creating this hook!\nInstall the hook files [bash]: Run this on your workstation: sudo mkdir -p /etc/libvirt-dnat-hook sudo cp /usr/local/src/libvirt-hook-qemu/hooks.schema.json /etc/libvirt-dnat-hook Set config variables Set some temporary variables the same as from your config:\n[bash]: Customize and set temporary environment variables NAME=debian-dev IP_ADDRESS=192.168.122.2 Customize the port-forwarding hook Use the example and schema as a reference, then setup the port mapping you want for each VM:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} IP_ADDRESS=${IP_ADDRESS:-192.168.122.2} cat \u003c\u003c EOF | jq | sudo tee /etc/libvirt-dnat-hook/hooks.json { \"${NAME}\": { \"interface\": \"virbr0\", \"private_ip\": \"${IP_ADDRESS}\", \"port_map\": { \"tcp\": [ [2222, 22], [80, 80], [443, 443] ] } } } EOF Tip This example opens the following public ports:\nPublic TCP port 2222 forwards to the VM’s port 22. Public TCP port 80 forwards to the VM’s port 80. Public TCP port 443 forwards to the VM’s port 443. UDP ports need to be in their own section, a sibling of TCP. Each VM needs its own config, mapped at the top level by the VM’s unique name.\nAutostart port-forwarding script on boot I have not figured out how libvirt hooks are supposed to work with user-mode VMs. It seems like when the VM starts, the hook never gets called. So, this section adds another service that triggers the hook manually on boot to setup the port forwarding for each VM.\nCreate DNAT service template [bash]: Run this on your workstation: VM_ADMIN=${VM_ADMIN:-libvirt-admin} cat \u003c\u003c EOF | sudo tee /etc/systemd/system/libvirt-DNAT@.service [Unit] Description=${VM_ADMIN} VM: %i - DNAT port forwarding Requires=libvirt@%i.service Requires=network-online.target After=libvirt@%i.service After=network-online.target [Service] Type=oneshot RemainAfterExit=true Environment=\"XDG_RUNTIME_DIR=/run/user/$(id -u ${VM_ADMIN})\" Environment=\"CONFIG_PATH=/etc/libvirt-dnat-hook\" ExecStart=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i start ExecStop=/usr/bin/python /usr/local/src/libvirt-hook-qemu/hooks %i stopped [Install] WantedBy=multi-user.target EOF sudo systemctl daemon-reload Enable DNAT service once per VM you want to expose [bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl enable --now libvirt-DNAT@${NAME}.service sudo systemctl status libvirt-DNAT@${NAME}.service Stopping and/or Disabling the service If you want to disable the port mapping, run:\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl disable --now libvirt-DNAT@${NAME}.service Or to temporarily stop the port mapping (until you run start or reboot):\n[bash]: Run this on your workstation: NAME=${NAME:-debian-dev} sudo systemctl stop libvirt-DNAT@${NAME}.service Reboot workstation Once rebooted, test that your port forward rule exists in iptables rules:\n[bash]: Run this on your workstation: sudo iptables-save | grep 2222 (stdout) -A DNAT-debian-dev -d 10.13.13.227/32 -p tcp -m tcp --dport 2222 -j DNAT --to-destination 192.168.122.2:22 -A SNAT-debian-dev -s 192.168.122.2/32 -d 192.168.122.2/32 -p tcp -m tcp --dport 2222 -j MASQUERADE ",
    "description": "By default, all incoming traffic to the VMs must originate from your workstation (or another VM on your workstation) - no traffic is routed to your VMs from any other interface.\nIf you want to break this rule, and allow public routes into these VMs (DNAT port forwarding), you will need to install the libvirt hook that sets up the iptables forwarding rules:\nDownload the port-forwarding hook [bash]: Run this on your workstation: sudo mkdir -p /usr/local/src/ sudo su -c \"",
    "tags": [],
    "title": "Public routes to VMs",
    "uri": "/linux-workstation/kvm-libvirt/public-routes/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": " Info For this section, you are back to using your normal workstation user.\nAppend a new host config into your SSH config (~/.ssh/config):\nEdit this file: ~/.ssh/config Host debian-dev Hostname 192.168.122.2 User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Info Make sure Host and Hostname are set correctly for your VM.\nWith this config, you can now use SSH to control the VM:\n[bash]: Run this on your workstation: ssh debian-dev whoami (stdout) root Install Docker You’re now ready to use your VM as an install target for whatever you want. It is recommended to install Docker, which you can learn about in the volume Self-hosting Docker in the chapter called Setup your workstation.",
    "description": "Info For this section, you are back to using your normal workstation user.\nAppend a new host config into your SSH config (~/.ssh/config):\nEdit this file: ~/.ssh/config Host debian-dev Hostname 192.168.122.2 User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p Info Make sure Host and Hostname are set correctly for your VM.\nWith this config, you can now use SSH to control the VM:\n[bash]: Run this on your workstation: ssh debian-dev whoami (stdout) root Install Docker You’re now ready to use your VM as an install target for whatever you want.",
    "tags": [],
    "title": "Setup workstation SSH config",
    "uri": "/linux-workstation/kvm-libvirt/setup-workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply …",
    "content": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Nested …",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e KVM / libvirt",
    "content": "The previous section named Create VM (cloud-init) installed a VM from a cloud-init enabled image (colloquially known as a “cloud image”), which is the streamlined and preferred method of VM installation. However, not all Linux distributions have a cloud image available. You may need to manually install the OS using a traditional graphical installer. Thats what this section is all about.\nAs an example, these are the steps to install a VM using Fedora CoreOS (which does not support cloud-init, nor a traditional installer). You will be using the graphical Fedora Workstation Live .iso image as a temporary OS to bootstrap CoreOS onto a blank virtual disk.\nIndex ",
    "description": "The previous section named Create VM (cloud-init) installed a VM from a cloud-init enabled image (colloquially known as a “cloud image”), which is the streamlined and preferred method of VM installation. However, not all Linux distributions have a cloud image available. You may need to manually install the OS using a traditional graphical installer. Thats what this section is all about.\nAs an example, these are the steps to install a VM using Fedora CoreOS (which does not support cloud-init, nor a traditional installer).",
    "tags": [],
    "title": "Create VM from .iso image",
    "uri": "/linux-workstation/kvm-libvirt/vm-from-iso/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "description": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "tags": [],
    "title": "Sub-chapter 1",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter1/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 2",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter2/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 3",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter3/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:\nThe MIT License (MIT) Copyright (c) 2021 Sören Weber Copyright (c) 2017 Valere JEANTET Copyright (c) 2016 MATHIEU CORNIC Copyright (c) 2014 Grav Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "description": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:",
    "tags": [],
    "title": "LICENSE",
    "uri": "/license/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
