var relearn_search_index = [
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH KVM / libvirt ",
    "description": "This book describes how I setup a Linux Workstation (on a personal Desktop or Laptop computer).\nIndex Introduction Fedora Sway Atomic Requirements Install Linux (Fedora Atomic) Upgrading Layering packages Config Sway Firefox Toolbox Emacs SSH KVM / libvirt ",
    "tags": [],
    "title": "Linux Workstation",
    "uri": "/linux-workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "What is self-hosting? Self-hosting is the practice of hosting network applications (web / internet / LAN / etc), using your own server hardware, or at least on virtual machines that you fundamentally control (ie. you have root access). As a preparedness skill, the self-hoster prioritizes the use of open source software, as it becomes an inalienable toolset to bootstrap infrastructure in the wilderness.\nYou can apply self-hosting a little bit, or a lot. On the one hand, you could post all of your content on Facebook (obviously, this is not self-hosting), and on the other hand you could build all your servers yourself, from parts, and run them in your basement, on your own network, bootstrapping everything. For most people though, self-hosting means to use a Raspberry Pi at home, or a cloud computing provider that offers you a generic Linux VPS (virtual private server) on the public internet, to configure in any way you wish, but still letting the cloud provider handle the hardware and network side of things for a monthly fee.\nDemarcate your own level of abstraction. Test that your operations work in a generic way, portable to any other provider at the same level of abstraction. Try running it entirely at home, at least for development purposes. Don’t get locked into a single vendor. Use open source software, or software you built yourself. This is self-hosting.\nWhat is Docker? Docker is a software platform for running containers on Linux. Containers let you install and run software in an isolated and generic way. It solves the problems of “dependency hell” and “But it works on my computer!”, for all Linux distributions. Containers are created from images that include all of their dependencies, including the operating system to support it. The only thing a container does not include, is the Linux kernel, which is shared from the host with all the containers running on the same host. This abstraction makes it work the same way on all computers, regardless of Linux distribution (assuming an up to date kernel). Docker maintains persistent volumes for each container, so that they may mount it into their own virtual filesystem, and thus storing all of its important data into the volume. You may upgrade, or even delete these containers, and as long as you keep the volume(s), you can simply reprovision the same images (even on new hardware), and the containers will load all of its same data from before.\nWhat is a container? Although it is possible to run desktop software inside of a Docker container, 99% of the time a Docker container is created to run a service, assumed to run on a server, assumed to be serving remote clients. Generally, a container is designed only to run a single service. For example: A web server, a chat server, a DNS server, a python server you write, etc. Multiple instances of the same image can run as separate containers, and they can even share volumes, if you want (though generally not).\nContainers are related to a different technology that you might already be familar with: Virtual Machines. However, there are several fundamental differences between containers and virtual machines, and so it is useful to describe them here as a comparison:\nFeature Container Virtual Machine Kernel Containers share a kernel with the host VMs runs their own kernel Hardware Containers share hardware with the host, but with the addition of a permissions model to access it VMs use hardware virtualization features Memory Containers share memory with the host VMs use a fixed size virtual hardware memory space Disk Containers share storage system with the host (volumes live under /var/lib/docker/ by default) VMs use a fixed size (but expandable) virtual hard disk image Network Containers support Host level networking, or can do NAT NAT or bridge network, not host level Execution model Containers are just a regular Linux processes, run under a given user account VMs run their own kernel and init (systemd) Init process Containers don’t need an init process, Docker runs the containers process (CMD) directly VMs run their own kernel and init (systemd) Process isolation Containers run as as regular Linux processes, which have a capabilities system to limit privileges VMs are like a separate machine, and a have a separate process space Root filesystem Containers inherit a root filesystem from their image, which contain all the application files, and the OS, minus a kernel VMs are run from (linked) virtual disk images Volumes Containers automatically mount volumes provided from Docker. Docker maintains the lifecycle of these volumes. VMs can have multiple virtual disks, or manually mount remote volumes Containerization uses features of the Linux kernel, (specifically, namespaces and cgroups). For the purposes of this book, the term “container” will always imply that it is running on a Linux host; it is inseparable from the host kernel, and it can’t work without it! (You may be aware that you can install a product called “Docker Desktop” on Windows or MacOS. This product installs a Linux virtual machine on your host OS and runs Docker inside it, and then it installs the docker client on the host OS, so it appears seamless.)\nIn a general context, there are other OS containers, like Windows containers, however they are on the fringe, and will not be discussed in this book. Containers imply Linux.\nDocker is a good platform to pick for self-hosting containers, because it’s a mature open source project, and it works on virtually any Linux computer or VPS. Docker is server focussed, and therefore ideal for self-hosting. Docker is easy to get started with, even if you’re a beginner.\nWhat is Docker Compose? Docker uses a client-server API pattern of control. You install the Docker daemon on a server machine, and this machine is called the Docker Host. Usually you interact with the API through the command line docker tool. Docker provides primitive commands for running single containers directly, with docker run. However, for larger projects that need more than one container (eg. a webserver + a database) and need to be able to talk to one another, docker run is not the best tool to use.\ndocker compose is a command that operates your containers from a project level abstraction. docker compose lets you define all the containers and volumes that you need for a given project, in a declarative way, in a docker-compose.yaml file.\nWith docker compose you can start/stop/delete all the project containers together, as a single unit.\nWhat is d.rymcg.tech? d.rymcg.tech is a collection of docker compose projects for various open source server applications, but it can also be used as a template for your own services. It has an integrated frontend proxy (Traefik Proxy), including sentry authorization middleware (mTLS, OAuth2, or HTTP Basic auth) and IP address filtering. It is a framework for packaging your own applications, and managing several container instances at the same time, each with seprate configs in .env files.\nd.rymcg.tech focuses on the config rules of the 12-factor principle. All of the configuration for a container should be specified as environment variables, which Docker loads from a standard .env file. All of the data for a container should live inside a Docker Volume (not a bind mount), and so the lifecycle of the volume is maintained by Docker directly.\nd.rymcg.tech is designed to run on a workstation, not the docker host. The Docker server API is accessed remotely over SSH. Only your personal workstation should be used to issue docker commands that affect the server, they should never be run on the server itself. It’s important to keep the server as bare bones and hands off as possible. The server’s only job is to run containers. The job of configuring them is always performed from a remote workstation. Once the server is setup, you won’t normally need to even login to the server console ever again. By controlling the server from your workstation, you can manage the server in a clean fashion. You can even create a new server from scratch, in no time. All of the important configuration stays on your workstation (and are backed up in a git repository).",
    "description": "What is self-hosting? Self-hosting is the practice of hosting network applications (web / internet / LAN / etc), using your own server hardware, or at least on virtual machines that you fundamentally control (ie. you have root access). As a preparedness skill, the self-hoster prioritizes the use of open source software, as it becomes an inalienable toolset to bootstrap infrastructure in the wilderness.\nYou can apply self-hosting a little bit, or a lot.",
    "tags": [],
    "title": "Introduction",
    "uri": "/d.rymcg.tech/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard to type on, and a display to display things on. Historically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really exist anymore, and any computing device can become a workstation. The only important distinction for a workstation is the role that it serves, and how you configure and use it on daily basis.\nThe role of a workstation is very different than that of a server. A workstation’s only purpose is to serve you, the user, while interacting with its physical keyboard/mouse/etc interface. A workstation is usually connected to a network, but only as a client, not as a server. (Of course, you may bend this rule if you like, to make your computer a server-workstation or “Sworkstation”, but it is cleaner, and more secure, to use separate machines for these very different roles.)\nThis book will describe my preferred method for setting up a brand new computer for use as a personal workstation.\nIndex Fedora Sway Atomic Requirements ",
    "description": "A Linux Workstation is a single user computer that you use as your primary interface for computing, especially for “work” purposes. At a bare minimum, a workstation includes a keyboard to type on, and a display to display things on. Historically, there has been a hardware distinction between a personal computer (PC) and a Unix workstation, but ever since the introduction of Linux, the difference in hardware doesn’t really exist anymore, and any computing device can become a workstation.",
    "tags": [],
    "title": "Introduction",
    "uri": "/linux-workstation/introduction/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how to get started with self-hosting your own Docker server, using the tools provided by d.rymcg.tech.\nd.rymcg.tech Chat with us on Matrix Index Introduction Required Infrastructure Register a domain name Setup public DNS service Create a public server (VPS) Setup your workstation Install Docker client tools Install d.rymcg.tech tools Create SSH config and Docker Context Install Docker on your remote host Main config for d.rymcg.tech Install Traefik Proxy Whoami ",
    "description": "This book describes how to get started with self-hosting your own Docker server, using the tools provided by d.rymcg.tech.\nd.rymcg.tech Chat with us on Matrix Index Introduction Required Infrastructure Register a domain name Setup public DNS service Create a public server (VPS) Setup your workstation Install Docker client tools Install d.rymcg.tech tools Create SSH config and Docker Context Install Docker on your remote host Main config for d.rymcg.tech Install Traefik Proxy Whoami ",
    "tags": [],
    "title": "Self-hosting Docker with d.rymcg.tech",
    "uri": "/d.rymcg.tech/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "A public internet Docker server needs several resources that you need to procure :\nA domain name registrar (eg. Gandi.net). A domain name server (eg. DigitalOcean DNS). A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet). An internet network connection (eg. DigitalOcean network). Index Register a domain name Setup public DNS service Create a public server (VPS) ",
    "description": "A public internet Docker server needs several resources that you need to procure :\nA domain name registrar (eg. Gandi.net). A domain name server (eg. DigitalOcean DNS). A Linux compute platform on which to install Docker (eg. DigitalOcean Droplet). An internet network connection (eg. DigitalOcean network). Index Register a domain name Setup public DNS service Create a public server (VPS) ",
    "tags": [],
    "title": "Required Infrastructure",
    "uri": "/d.rymcg.tech/required-infrastructure/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This book describes how this site is written, in Org-mode, with ox-hugo, and bits of Literate Programming.\nIndex Dependencies Building locally Publishing with GitHub pages Publishing with SFTP Example Org / Hugo content Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Publishing with org-mode, ox-hugo, and literate programming.",
    "uri": "/publishing-with-org-mode/index.html"
  },
  {
    "breadcrumb": "",
    "content": "This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nTable of contents In HTML form, the menu bar on the left contains the table of contents, and shows the book titles as top level headings, and chapter headings beneath it. On smaller screens, you may need to expand this menu using the top left hamburger menu.\nWhen viewing any chapter, the section sub-headings can be shown on a per-chapter basis, via the Table of Contents button at the top left.\nNavigation The entire site is presented as a book of books, so you can read through them all, simply by navigating through to the next page, until you get to the end. Use your keyboard arrow keys, left and right, to flip backwards and forwards through the pages. If you are using a touch screen interface, use the arrow buttons at the top right of the page instead.\nSearch Use the search box in the left hand menu to search all of the books on the site.",
    "description": "This repository contains a collection of books written by EnigmaCurry.\nThis content is open-source, CC BY 4.0. See LICENSE for attribution rules.\nTable of contents In HTML form, the menu bar on the left contains the table of contents, and shows the book titles as top level headings, and chapter headings beneath it. On smaller screens, you may need to expand this menu using the top left hamburger menu.\nWhen viewing any chapter, the section sub-headings can be shown on a per-chapter basis, via the Table of Contents button at the top left.",
    "tags": [],
    "title": "book.rymcg.tech",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).\nRead the Linux Workstation chapter for setting up Emacs.\nPlease note that your package manager may container an old version of Hugo that is incompatible with the Relearn theme. You can install the latest version of Hugo from the Hugo GitHub releases page.\nFor example, to download the X86_64 release of hugo v0.123.8:\n[bash]: Run this on your workstation: ## Do this if your package manager installs an old incompatible version of Hugo: cd ~/Downloads wget https://github.com/gohugoio/hugo/releases/download/v0.123.8/hugo_extended_0.123.8_linux-amd64.tar.gz tar xfvz hugo_extended_0.123.8_linux-amd64.tar.gz sudo install hugo /usr/local/bin/hugo You will also need to clone the git source of this website to your workstation:\n[bash]: Run this on your workstation: git clone https://github.com/EnigmaCurry/org.git ~/git/vendor/enigmacurry/org I always recommend to everyone, that you choose to use the ~/git/vendor/ORG_NAME/REPO_NAME path structure when cloning any git repository (including your own!). This suggested path is a vendor-neutral convention, useful for documentation purposes, and which shouldn’t conflict with any existing directory you might have. Therefore the instructions should generally work on all machines. If we all agree to use the same path, the instructions are much easier to write, and read from! If you are adamant about cloning this elsewhere, consider making a symlink from this path anyway (In this case, ~/git/vendor/enigmacurry/org).",
    "description": "This site is built with:\nEmacs Org-mode Ox-hugo Hugo (extended edition) GitHub actions (also compatible with Gitea actions) The GitHub/Gitea actions file includes all its dependencies declaratively.\nTo build locally, you must install Emacs (29+), and hugo (v0.120+), using your package manager, or by downloading directly from their respective project pages. Please be aware that hugo has two editions: standard and extended, and this build requires the extended edition (TODO: verify this - I had some problems before - but maybe they are resolved - I am still using the extended edition for now).",
    "tags": [],
    "title": "Dependencies",
    "uri": "/publishing-with-org-mode/dependencies/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "Create USB installation media Download the Fedora Sway Atomic iso image. Assuming you are temporarily using another Linux workstation, write the .iso image to a USB drive:\n[bash]: Run this on your workstation: dd if=Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your device name, and double check the .iso filename, it may have changed.\nBoot the target workstation computer using the USB drive. You will boot into the Anaconda install wizard. Just follow the prompts to install it, it is exactly the same as any other Fedora / Redhat install.\nTips:\nEnable whole disk encryption and choose a secure passphrase. Especially for laptop computers that you may travel with, this an important thing to do to keep your files safe at rest. Use the entire disk for the install. Dual booting another operating system on the same workstation is not considered a safe/secure thing to do. If you want to run Windows or play games, use a separate computer for that. Once the installer finishes, reboot, remove the USB, and login to your new system.",
    "description": "Create USB installation media Download the Fedora Sway Atomic iso image. Assuming you are temporarily using another Linux workstation, write the .iso image to a USB drive:\n[bash]: Run this on your workstation: dd if=Fedora-Sericea-ostree-x86_64-40-1.14.iso \\ of=/dev/sdX bs=10M status=progress conv=sync Info Replace /dev/sdX with your device name, and double check the .iso filename, it may have changed.\nBoot the target workstation computer using the USB drive. You will boot into the Anaconda install wizard.",
    "tags": [],
    "title": "Install Linux (Fedora Atomic)",
    "uri": "/linux-workstation/install/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "description": "Change into the directory where you cloned the source:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/org Run the install method to download the theme:\n[bash]: Run this on your workstation: ## This just downloads/installs the theme: make install Build the site:\n[bash]: Run this on your workstation: ## This builds the entire static site into the public/ directory: make build Run the development server:\n[bash]: Run this on your workstation: ## This builds the entire site, and then runs the live reload server: make serve ",
    "tags": [],
    "title": "Building locally",
    "uri": "/publishing-with-org-mode/building-locally/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from. The default is to boot the newly upgraded image.\nThe above will not upgrade to a new release version, eg. Fedora 39 to Fedora 40. It will only update the packages for the currently installed release.\nTo find the list of all released versions, run :\n[bash]: Run this on your workstation: ostree remote refs fedora | grep \"$(uname -m)/sericea$\" Upgrade to the new release (eg. 40):\n[bash]: Run this on your workstation: rpm-ostree rebase fedora:fedora/40/x86_64/sericea Let it finish downloading the new image, and then reboot again.",
    "description": "As mentioned before, Fedora Atomic is distributed as a full system image. You can both upgrade the image, as well as rollback the image (in case you have any issues with the upgrade.)\nTo upgrade to the latest image:\n[bash]: Run this on your workstation: sudo rpm-ostree upgrade Let it finish downloading the new image, and then you must reboot:\n[bash]: Run this on your workstation: sudo systemctl reboot The boot manager lists the last several images, which are still available to choose from.",
    "tags": [],
    "title": "Upgrading",
    "uri": "/linux-workstation/upgrading/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": "See the Fedora docs for Adding Layered Packages\nTo create efficient layers, you should try to install everything you want into as few layers as possible.\nHere is a list of packages you might want to add all together as one layer:\n[bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top net-tools \\ gvfs-smb gvfs-archive gvfs-nfs gvfs-fuse gvfs-mtp Check the list of layers:\n[bash]: Run this on your workstation: sudo rpm-ostree status The top layer should list the LayeredPackages in your new layer.\nReboot.",
    "description": "See the Fedora docs for Adding Layered Packages\nTo create efficient layers, you should try to install everything you want into as few layers as possible.\nHere is a list of packages you might want to add all together as one layer:\n[bash]: Run this on your workstation: sudo rpm-ostree install qemu-kvm libvirt virt-manager virt-viewer \\ virt-install libvirt-daemon-config-network libvirt-daemon-kvm \\ libguestfs-tools python3-libguestfs virt-top net-tools \\ gvfs-smb gvfs-archive gvfs-nfs gvfs-fuse gvfs-mtp Check the list of layers:",
    "tags": [],
    "title": "Layering packages",
    "uri": "/linux-workstation/layering-packages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "description": "This site is automatically published to GitHub Pages via the included action file: .github/workflows/deploy.yaml. You can fork the repository and enable the action to run on your behalf and publish to your own site automatically, whenever you run git push.",
    "tags": [],
    "title": "Publishing with GitHub pages",
    "uri": "/publishing-with-org-mode/publish-with-github-pages/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this. You must set all of the following details:\nThe unique name of the remote (eg. book) The hostname of the SFTP server (eg. sftp.example.com) The SFTP username, password, or SSH key, and whether to use the SSH agent (recommended!) The connection details are saved in your clone config file (eg. ~/.config/rclone/rclone.conf)\nThe included Makefile has a variable at the top called PUBLISH_RCLONE_REMOTE (default book). Make sure this is the same as the name of the rclone remote you configured (edit the Makefile if it is not).\nOnce everything is configured, simply run make publish to publish your site to the SFTP remote.\nYour webserver document root needs to be configured to use the same path that the SFTP server is configured for.\nIf you don’t have a webserver or SFTP server, you can use the following from d.rymcg.tech:\nSFTP server Nginx webserver ",
    "description": "If you don’t want to use GitHub pages, you can alternatively publish to any webserver via SFTP.\nTo do so, you must install Rclone.\nFor example, on Fedora:\n[bash]: Run this on your workstation: ## On Fedora atomic, make sure to do this in a toolbox container: sudo dnf install rclone Once installed, you need to configure the remote SFTP server you want to publish to:\n[bash]: Run this on your workstation: rclone config Follow the prompts to setup your SFTP remote, or you can see the example SFTP documentation for doing this.",
    "tags": [],
    "title": "Publishing with SFTP",
    "uri": "/publishing-with-org-mode/publish-with-sftp/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation",
    "content": " Index Sway Firefox Toolbox Emacs SSH KVM / libvirt ",
    "description": " Index Sway Firefox Toolbox Emacs SSH KVM / libvirt ",
    "tags": [],
    "title": "Config",
    "uri": "/linux-workstation/config/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode",
    "content": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": "This chapter serves as an example of various shortcodes/markup for Ox-Hugo and the Hugo Relearn theme.\nThis chapter is broken into several sub-chapters to discuss the various Hugo related features.\nIndex Example Org Blocks Example Shortcodes Example of a deeply … Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example Org / Hugo content",
    "uri": "/publishing-with-org-mode/examples/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "You should dedicate the use a physical or virtual Linux machine to be used as your workstation. A single workstation can manage several remote Docker contexts.\nFollow the Linux Workstation book for details on basic workstation setup.\nAll the commands in this chapter assume you are using the standard Bash shell.\nIndex Install Docker client tools Install d.rymcg.tech tools Create SSH config and Docker Context Install Docker on your remote host Main config for d.rymcg.tech ",
    "description": "You should dedicate the use a physical or virtual Linux machine to be used as your workstation. A single workstation can manage several remote Docker contexts.\nFollow the Linux Workstation book for details on basic workstation setup.\nAll the commands in this chapter assume you are using the standard Bash shell.\nIndex Install Docker client tools Install d.rymcg.tech tools Create SSH config and Docker Context Install Docker on your remote host Main config for d.",
    "tags": [],
    "title": "Setup your workstation",
    "uri": "/d.rymcg.tech/workstation/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.\nIt can contain any additional markup you want.",
    "description": "A couple examples ripped from the ox-hugo docs.\nAsides This is a normal paragraph.\nThis is an aside note, which should wrap and stay close to the right hand side of the page. It is used to call out things in an editorial voice.\nThis is another normal paragraph.\nMarkers This paragraph has some highlighted words in it.\nDetails This section shows some hidden details:\nThis content is hidden by default.",
    "tags": [],
    "title": "Example Org Blocks",
    "uri": "/publishing-with-org-mode/examples/org-blocks/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.\nThe “Atomic” part refers to rpm-ostree which was developed by the CoreOS team to build an operating system that is built entirely to support containers. The root file system of the host operating system is mounted read-only, and the packages are distributed in an image, rather than installed individually. This makes updating (or rolling back) the system far easier, and makes for a more stable environment. There is no need to replace packages one-by-one, you just download the new image provided by the distro, and then reboot the system to use it.\nThe base image includes all the typical things everyone needs: coreutils, a display manager, web browser, terminal apps etc. However, the base image is still pretty bare bones. Furthermore, the image is read-only, so you can’t install packages like you can with a more traditional Linux distro. If you want to install something that isn’t in the base image, you have a few different options:\nPodman or Docker containers. Since containers use their own image, they are separate from the main image, and can be freely created and destroyed separately. Flatpak is a type of application container that includes all of its dependencies, and it is sandboxed/isolated from the host system, therefore they can be installed/managed separately from the base image. Use rpm-ostree itself to create a new image layer. This extends the base layer with extra packages you want to install. This is fully supported, but not optimal, as when you upgrade the base image, this layer needs to be recreated each time. I only use a couple of Flatpak apps for a few things. For almost everything else I use Podman containers via toolbox and/or distrobox and these can even include graphical applications. Creating your own rpm-ostree layers is to be avoided if possible, but some things don’t like running in containers, so this remains an option.",
    "description": "I have tried a great many different Linux distributions over the years, but I have recently settled on using Fedora Sway Atomic for my desktop and laptop workstations.\nSway is a minimal tiling window manager for Wayland. It is ideal for efficient keyboard centric development and for getting out of your way.\nThe “Atomic” part refers to rpm-ostree which was developed by the CoreOS team to build an operating system that is built entirely to support containers.",
    "tags": [],
    "title": "Fedora Sway Atomic",
    "uri": "/linux-workstation/introduction/fedora-sway-atomic/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "You need to install Docker Engine (not Docker Desktop!) on your workstation.\nYou will completely disable the Docker daemon on your workstation, you’re only installing Docker Engine for its client tools (eg. the docker command).\nVarious ways to install Docker Engine Try your system package manager Some Linux distributions have decent packages for up-to-date Docker versions. Some other distributions lag behind by several versions, or may even introduce non-standard changes of their own. Your mileage may vary with packages provided by your operating system.\nIf you’re on Arch Linux, this is known to be a good configuration:\nRun this on your Arch Linux workstations: sudo pacman -S docker docker-compose docker-buildx Install from upstream Docker package repository The Docker organization provides several up-to-date packages for various Linux distributions:\nDebian Ubuntu Fedora Use the generic Docker installer to install the latest version If your Linux distribution doesn’t provide a Docker package, or you’ve decided its not good for your situation, you may be better off by running the generic installer script from the upstream Docker organization:\n[bash]: Run this on your workstation: curl -fsSL https://get.docker.com -o install-docker.sh sudo sh install-docker.sh DON’T install Docker Desktop! Docker Desktop isn’t open source. Docker Desktop runs a VM to run the Docker daemon on localhost. (we don’t want that, since we will use a remote Docker context instead.) Docker Desktop does not support host mode networking, so it wouldn’t have worked with our Traefik config anyway. (This situation may have changed in more recent versions of Docker Desktop 4.29+). Docker Desktop provide the same docker client tools, so it will actually still work, if thats the package you prefer to install. Just be sure to disable the VM that it creates by default, you will not need it! Keep your workstation clean, don’t run containers / VMs on it! Disable Docker daemon on your workstation Your workstation is the manager of remote Docker hosts, so it should not run the Docker daemon itself, but only the client.\nRun the following commands to disable the Docker daemon:\n[bash]: Run this on your workstation: sudo systemctl disable --now docker sudo systemctl mask docker Tip There is a vestigal Docker context named “default” left on your system (see docker context ls), and this context was originally used to manage the Docker daemon of the local host (unix:///var/run/docker.sock). However, this will be of no use to you now, since the Docker daemon is now completely disabled on the workstation. Furthermore, the “default” context cannot be deleted, so its best to just ignore it (the d.rymcg.tech CLI won’t even show it). In the next couple of steps, you’ll create and activate new remote SSH contexts that you’ll use instead of the “default” context.",
    "description": "You need to install Docker Engine (not Docker Desktop!) on your workstation.\nYou will completely disable the Docker daemon on your workstation, you’re only installing Docker Engine for its client tools (eg. the docker command).\nVarious ways to install Docker Engine Try your system package manager Some Linux distributions have decent packages for up-to-date Docker versions. Some other distributions lag behind by several versions, or may even introduce non-standard changes of their own.",
    "tags": [],
    "title": "Install Docker client tools",
    "uri": "/d.rymcg.tech/workstation/install-docker-command-line-tools/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "To host a web service, one of the first things you will need is to register your domain name. This will be the domain name used for all of your service links, and it is what your users will need to type into their browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments. If domain names were free, all the good ones would be taken by now, but because they cost money, there are still some good enough ones left to be had. In return for your fee, you receive exclusive use of your domain name for the period that you paid for. You “own” the domain name, and its configuration, but you need to keep paying a registrar to keep the record active (so its more like renting). You can pre-pay for several years in advance, or for just pay one year at a time. If you stop paying, and the records expire, they will no longer resolve to your services, and you may lose control of the domain, possibly forever.\nDomain names for private servers If you control your own DNS servers, you could use completely made up domain names under the .internal domain, which are RFC recoginized for private usage. But for most public servers, where most clients use different DNS servers, you will want to register a “real” domain instead.\nFor private servers, (eg. running a private Docker server at home), it is still recommended that you use a valid internet domain name, using public DNS servers, because you will still need this in order to create valid TLS certificates from Let’s Encrypt. However, having valid working TLS is not required for development purposes (but certainly nice to have!), so you may choose to make up your own fake domain name instead, and forgo TLS, or you can setup Step-CA for off-grid TLS. In either case, you will still need to setup DNS, and this is explained in the next section.\nRegister an Internet domain name You can buy (rent) a domain name from lots of places. For documentation purposes, we will use Gandi.net, but these instructions will be similar regardless of the domain provider you pick.\nSign up for an account at Gandi.net Once signed in, from your dashboard, click Register. Search for any domain name you like, eg. your-name.com. Add your domain to the shopping cart, go to checkout, and complete your purchase. Once you have purchased the domain, it should show up in your Dashboard, under the Domain tab. Leave this browser tab open, you will return to it in the next chapter. ",
    "description": "To host a web service, one of the first things you will need is to register your domain name. This will be the domain name used for all of your service links, and it is what your users will need to type into their browsers (or click on) to visit your pages.\nPublic domain names are a scarce resource. Because of their scarcity, you must pay for your domain registrations, doing so in 1 year increments.",
    "tags": [],
    "title": "Register a domain name",
    "uri": "/d.rymcg.tech/required-infrastructure/register-a-domain-nameom/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it. However, I use my own custom configuration that I replace it with, and you can do the same if you like.\nOpen the default terminal emulator (foot) with the keyboard shortcut: Win+Enter (hold down the “Windows” key on your keyboard, then simultaneously press Enter.)\nMy custom config replaces several of the default configuration files. So you must first get rid of these files, by renaming them with the suffix .orig for posterity:\n[bash]: Run this on your workstation: mv ~/.config ~/.config.orig mv ~/.bashrc ~/.bashrc.orig mv ~/.bash_profile ~/.bash_profile.orig Next, install my customized sway config repository :\n[bash]: Run this on your workstation: git clone https://github.com/enigmacurry/sway-home \\ ~/git/vendor/enigmacurry/sway-home Run the included setup script:\n[bash]: Run this on your workstation: cd ~/git/vendor/enigmacurry/sway-home ./setup.sh The setup.sh script will make symlinks to the repository files from the same original paths as the files you just moved. It also asks you some questions to help setup your git profile.\nOnce you have finished entering the information setup asks for, press Win+Shift+E, and choose Log Out. Log back in, and this will load the new config files.\nSetup display resolutions and orientation Fedora Sway Atomic ships with kanshi for display setup. Kanshi does not include any GUI for setting it up, so another program called wdisplays is useful, however it is not included in the base Atomic distribution, and you will have to install it via toolbox.\ninstall wdisplays inside of toolbox sudo dnf install wdisplays You can configure all of your displays using the wdisplays GUI program, however, the configuration will not persist across login sessions. So what you need to do is set it up how you like it, and then transfer that information into the Kanshi config file so that it sets it up the same way everytime you login.\nFor example, on my test system I have two display port monitors, with outputs named DP-3 and DP-4. These are shown in wdisplays and I have set up the size, position, and DPI scaling exactly how I like it:\nDP-3:\nDP-4:\nOpen the Kanshi config file ~/.config/kanshi/config and copy the information into the config file:\nEdit this file: ~/.config/kanshi/config profile { output DP-3 enable mode 2560x1440 position 3840,0 scale 1 transform normal output DP-4 enable mode 3840x2160 position 1920,360 scale 2 transform normal } Check out man 5 kanshi for more config options. Kanshi is automatically started when sway is, so you can test it by logging out and logging back in.",
    "description": "Sway is a reimagining of i3wm (X11), rewritten for Wayland. Sway (like i3wm) is a keyboard centric tiling window manager. Although not a source fork of i3wm, the configuration and user interface of Sway is almost identical to that of i3wm.\nSway Config The Fedora Atomic Sway edition includes a default configuration for Sway. It’s pretty nice out of the box, and so if you like it, you can just use it.",
    "tags": [],
    "title": "Sway",
    "uri": "/linux-workstation/config/sway/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.rymcg.tech d.rymcg.tech Cancel Math Math with MathJax:\n$$\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ Flowcharts --- title: Example Diagram --- graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{\u0026lt;strong\u0026gt;Decision\u0026lt;/strong\u0026gt;} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] Notices Notice This is a generic notice.\nThis is a bug notice.\nInfo This is an information box.\nTip This is a tip or pointer.\nWarning This is a warning.\nOpenAPI Visualize your API with swagger spec.",
    "description": "Here are some example usage of the shortcodes provided by the Hugo Relearn theme. Shortcodes are a native feature of Hugo and Hugo themes. For use with Ox-Hugo, you need to set the #+hugo_paired_shortcodes (For examples, see Ox-hugo docs or the top of this source file).\nYou can only use the icon names from the “free” set provided by fontawesome.\nBadges 1.0.0 99,999 867-5309 Email me@example.com Docs Dumpster Fire Buttons d.",
    "tags": [],
    "title": "Example Shortcodes",
    "uri": "/publishing-with-org-mode/examples/shortcodes/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar. Select Settings.\nGeneral Settings Select Open previous windows and tabs Turn on Dark mode Turn off Recommend extensions as you browse Turn off Recommend features as you browse Home settings New Windows and Tabs Select Blank Page for both new windows and tabs.\nFirefox Home Content The home content won’t show if you set Blank Page above, but I go ahead and turn off all the home stuff anyway.\nSearch Settings Choose a non-Google default search engine, eg. DuckDuckGo. Turn off all Search Suggestions Delete all the corporate Search Shortcuts other than your preferred one (eg. DuckDuckGo). You can select each one and click Remove or you can press the Delete key. Delete Google, Amazon, Bing, eBay, Wikipedia etc.\nPrivacy \u0026 Security settings Enhanced Tracking Protection, select Strict Set Do Not Track to Always Logins and Passwords Unselect Suggest Firefox relay email masks\nUnselect Show alerts about passwords for breached websites (You already use unique passwords for every website, right??)\nIMPORTANT: select Use a Primary Password Without setting a primary password, any password that firefox saves will be unencrypted! You must set a primary (master) password, and you will need to type it in each time you restart your browser, to unlock the password manager.\nAddress Bar - Firefox Suggest Unselect Search engines\nUnselect Suggestions from the web\nUnselect Suggestions from sponsors\nFirefox Data Collection and Use Unselect everything here.\nHTTPs-Only mode Choose Enable HTTPS-Only Mode in all windows\nDNS over HTTPS Especially if you use a portable laptop, or connect to various WiFi access points, you should choose Max Protection.\nExtensions and Themes From the Settings menu, near the bottom, click Extensions \u0026 Themes.\nThemes Choose a theme you like. For example, click Dark and then click Enable.\nExtensions Go to addons.mozilla.org and install the following extensions:\nDark Reader\nDark reader makes all sites darker, and you can customize each site by clicking on the Dark Reader extension in the menu bar.\nUblock Origin\nDisables almost all ads on all websites. There’s not much to configure here, it basically works out of the box. However, you can customize it per site if you want to enable ads on certain pages.\nNoScript\nBy default, all sites will have javascript disabled. On each site you trust, you can customize the javascript availability by clicking the NoScript extension in the menu bar.\nNo Tabs\nIf you’re using a tiling window manager (Sway), you might consider disabling Firefox tabs, and have every site in its own window instead. This extension does that.\nVimium\nOnce vimium is installed, click the icon in the menu bar and click Enable all hosts permission.\nFirefox Multi-Account Containers\nRead about how to use Firefox Containers. Configure sites you trust to open in specific containers, that way you can save your cookies per container. By default, new sites will always open in temporary ones, and so when you close your browser all the cookies for that site disappears.",
    "description": "Fedora Atomic ships with the Firefox browser preinstalled. This section describes how I like to set it up.\nRemove clutter Remove Firefox View, right click the upper left icon and select Remove from toolbar. Remove existing bookmarks from bookmark bar, right click each one and select Delete. Remove Pocket, right click the pocket icon in the upper right toolbar, select Remove from toolbar Remove Firefox Account icon, select Remove from toolbar Firefox Settings Go into the Firefox settings: click the “hamburger” menu in the top right toolbar.",
    "tags": [],
    "title": "Firefox",
    "uri": "/linux-workstation/config/firefox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "Install d.rymcg.tech and its dependencies on your workstation.\nInstall dependent packages If you run Fedora workstations, run this as root dnf install bash gettext openssl git xdg-utils jq sshfs curl \\ inotify-tools httpd-tools make wireguard-tools If you run Debian/Ubuntu workstations, run this as root apt-get install bash build-essential gettext git openssl \\ apache2-utils xdg-utils jq sshfs wireguard curl \\ inotify-tools If you run Arch Linux workstations, run this as root pacman -S bash base-devel gettext git openssl apache xdg-utils \\ jq sshfs wireguard-tools curl inotify-tools Clone d.rymcg.tech repository [bash]: Run this on your workstation: git clone https://github.com/EnigmaCurry/d.rymcg.tech.git \\ ${HOME}/git/vendor/enigmacurry/d.rymcg.tech Warning By convention, you should not change the clone path. It is intentionally placed in a vendor neutral path location for all to use. But if you’re adamant to do so, it should still work, regardless of where you put it. But watch out, as this may break documentation, and for some external projects that assume ROOT_DIR is using the conventional path. For compatability reasons, consider making a symlink from ${HOME}/git/vendor/enigmacurry/d.rymcg.tech pointing to your actual clone path.\nSetup d.rymcg.tech command line tool You must edit your workstation user’s ~/.bashrc file, which modifies the Bash shell environment config:\nEdit this file: ~/.bashrc ## Put this in ~/.bashrc to enable d.rymcg.tech command line tools: export PATH=${PATH}:${HOME}/git/vendor/enigmacurry/d.rymcg.tech/_scripts/user eval \"$(d.rymcg.tech completion bash)\" ## Setup shorter alias for d.rymcg.tech as just 'd' __d.rymcg.tech_cli_alias d Important Close and restart your shell (terminal) to load the new config in a new session.\nTest the d.rymcg.tech aliases In your new shell session, you have the following aliases defined:\nd.rymcg.tech d These are both the same, but for brevity, the rest of this documentation will prefer the d alias, but they can be used interchangeably.\n[bash]: Run this on your workstation: d (stdout) Found ROOT_DIR=/var/home/ryan/git/vendor/enigmacurry/d.rymcg.tech ## Main d.rymcg.tech sub-commands - Optional arguments are printed in brackets [OPTIONAL_ARG] cd [SUBDIR] Enter a sub-shell and go to the ROOT_DIR directory create [PROJECT] [TEMPLATE] Create a new external project from a template make [PROJECT] [ARGS …] Run a make command for the given d.rymcg.tech project name context View or set the current Docker context new-context Create a new Docker context ssh [COMMAND …] Run command or shell on active docker context SSH host completion Setup TAB completion in your shell\n## Documentation sub-commands: help Show this help screen list List available d.rymcg.tech projects (not including external projects, unless you symlink them into ROOT_DIR) readme Open the main d.rymcg.tech README.md in your browser readme [PROJECT] Open the README.md for the given project name readme digitalocean Open root documentation file: DIGITALOCEAN.md readme security Open root documentation file: SECURITY.md readme aws Open root documentation file: AWS.md readme license Open root documentation file: LICENSE.txt readme raspberry_pi Open root documentation file: RASPBERRY_PI.md readme makefile_ops Open root documentation file: MAKEFILE_OPS.md ",
    "description": "Install d.rymcg.tech and its dependencies on your workstation.\nInstall dependent packages If you run Fedora workstations, run this as root dnf install bash gettext openssl git xdg-utils jq sshfs curl \\ inotify-tools httpd-tools make wireguard-tools If you run Debian/Ubuntu workstations, run this as root apt-get install bash build-essential gettext git openssl \\ apache2-utils xdg-utils jq sshfs wireguard curl \\ inotify-tools If you run Arch Linux workstations, run this as root pacman -S bash base-devel gettext git openssl apache xdg-utils \\ jq sshfs wireguard-tools curl inotify-tools Clone d.",
    "tags": [],
    "title": "Install d.rymcg.tech tools",
    "uri": "/d.rymcg.tech/workstation/install-d-rymcg-tech/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Introduction",
    "content": "You will need the following hardware:\nAn x86_64 desktop or laptop computer. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, PGP keys, and logging into websites with Webauthn.) ",
    "description": "You will need the following hardware:\nAn x86_64 desktop or laptop computer. A USB drive for copying the .iso installer to. A solokey or other FIDO2 compatible hardware authentication key. (This is optional, but highly recommended for storing secure shell keys, PGP keys, and logging into websites with Webauthn.) ",
    "tags": [],
    "title": "Requirements",
    "uri": "/linux-workstation/introduction/requirements/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "A DNS server maps your domain (and all subdomain) names to the various IP addresses of your servers. DNS is required for your users to be able to type (or click on) your domain name prod.example.com and have it resolve to the IP address that is required to contact your Docker server (prod). Beyond this, DNS is also a means of proving to a third party that you are the owner (controller) of your own domain, which is used as a part of the ACME challenge that Let’s Encrypt (or Step-CA) uses when signing your TLS certificates.\nNow that you have registered a domain name, you need to tell your registrar where your DNS server is. Usually you will use the DNS server that your cloud provider gives you, but you may choose any DNS provider you like. If you are creating a private server, you may still want to choose a public DNS server, but using private IP addresses ranges for the records. You can also setup a local/private DNS server, but this will be discussed later.\nFor the purposes of ACME (automatic TLS certificate issuing/renewals), your DNS server/provider will need to support one of the APIs supported by the go-lego project. Find out what API tokens or other settings your provider may need by by finding your provider in the list on that page.\nFor documentation purposes, this chapter will assume you are using Gandi.net as your domain registrar, and that you want to use DigitalOcean.com as your domain’s public DNS server (and digitalocean is supported by go-lego), but these instructions will be similar regardless of the supported provider you pick.\nConfigure your domain’s DNS server on Gandi.net Login to your gandi.net dashboard. Click the Domain tab. Find your domain name in the list and click on it. Click on the Nameservers tab. Click on the edit button to create new External nameservers. Delete all existing nameservers that may exist. Add the following nameservers, specific to DigitalOcean: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Wait a few minutes for the change to take effect, then you can verify the setting from your workstation, using the whois command:\n[bash]: Run this on your workstation: whois example.com (stdout) Domain Name: example.com Registrar WHOIS Server: whois.gandi.net Name Server: DNS1.EXAMPLE.NET Name Server: DNS2.EXAMPLE.NET Name Server: DNS3.EXAMPLE.NET Name Server: DNS4.EXAMPLE.NET The output shows a report for your domain registration, including the list of the new nameservers.\nSetup public DNS on DigitalOcean.com Signup for an account at DigitalOcean, if you haven’t already. Login to the cloud console. Click on the Networking tab in the menu. Click on the Domains tab. Enter your domain name into the box and click Add Domain. DigitalOcean is now in charge of your DNS for your domain. You will return to this screen later on, when creating individual subdomain records for your services.",
    "description": "A DNS server maps your domain (and all subdomain) names to the various IP addresses of your servers. DNS is required for your users to be able to type (or click on) your domain name prod.example.com and have it resolve to the IP address that is required to contact your Docker server (prod). Beyond this, DNS is also a means of proving to a third party that you are the owner (controller) of your own domain, which is used as a part of the ACME challenge that Let’s Encrypt (or Step-CA) uses when signing your TLS certificates.",
    "tags": [],
    "title": "Setup public DNS service",
    "uri": "/d.rymcg.tech/required-infrastructure/setup-dns/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Required Infrastructure",
    "content": "This section will guide you to create your own public Docker server, using a DigitalOcean droplet as an example. In a similar fashion, you can install Docker on any cloud provider, or dedicated host that you prefer.\nChoosing a VPS provider One of the most basic units of cloud computing is the Virtual Private Server (VPS). A VPS is a (Linux) virtual machine that is provisioned by a cloud service, and you are given root access to fully administer it, to install whatever you want on it. VPS generally come with a dedicated IP address and have a public internet connection, although some VPS only have NAT, but with dedicated port forwarding.\nIn this guide you will create a VPS with a DigitalOcean droplet.\nYou can install Docker on almost any Linux machine, but some are better than others. DigitalOcean droplets (VPS) are a good choice for experimenting, because they are billed hourly, and because the service layer has an integrated firewall, external to the droplet operating system. Having a firewall that is external (in front of) the VPS is one of the most important features to look for in a hosting provider.\nSetup your SSH key on DigitalOcean If you have not yet setup an SSH key on your workstation, read the Linux Workstation book and do that first.\nLogin to the DigitalOcean cloud console. Click Settings in the menu. Click on the Security tab. Click on the Add SSH Key button. Paste your public SSH key into the box. (copy your pub key from the output of ssh-add -L.) Enter a key name, I recommend this be the name of your workstation computer. Finish adding the key, click Add SSH Key. Create a DigitalOcean firewall template Login to the DigitalOcean cloud console. Click Networking in the menu. Click the Firewalls tab. Click Create Firewall. Enter the name, eg. basic-docker-public-web. Enter the following rules: SSH: Type: SSH Protocol: TCP Port Range: 22 Sources: All IPv4, All IPv6, or a specific static IP address if you want to be more secure. HTTP: Type: HTTP Protocol: TCP Port Range: 80 Sources: All IPv4, All IPv6. HTTPS: Type: HTTP Protocol: TCP Port Range: 443 Sources: All IPv4, All IPv6. Wireguard VPN (optional): Type: Custom Protocol: UDP Port Range: 51820 Sources: All IPv4, All IPv6. Click Create Firewall. Creating a DigitalOcean droplet for a Docker server DigitalOcean provides a Docker image with which to create a droplet (DigitalOcean’s name for their own VPS product).\nLogin to the DigitalOcean cloud console. Click Droplets in the menu. Click Create Droplet. Choose a Region (eg. New York), where the droplet will be created. Underneath the heading Choose an image, choose Debian (select the latest version). Choose a droplet size. 2GB RAM and 50GB disk recommended for medium size production installs. (It is tested working on as little as 512MB ram, if you enable zram and/or create a 1GB swapfile. Do not abuse swap space like this in production! However I think its fine for development use, but you may occasionally run into low memory issues if less than 1GB.) Optional: Add a block storage device, in order to store your Docker volumes. (This is useful to store data separate from the droplet lifecycle, or to have a larger amount of storage than the droplet size gives you for the root filesystem. If your basic droplet size is already sufficient, and you perform regular backups, this might not be needed.) Select your SSH key for the root user. Set the hostname for the docker server. The name should be short and typeable, as it will become a part of the canononical service URLs. For this example, we choose prod. Verify everything’s correct, and then click Create Dropet. Apply the DigitalOcean droplet firewall Login to the DigitalOcean cloud console. Click Networking in the menu. Find the firewall template you created, and click it. Click on the firewall’s Droplets tab. Click Add Droplets and search for the droplet you created and select it. Click Add Droplet to add the firewall to the droplet. Create wildcard DNS records for the droplet For the purposes of documentation, assume you you own the domain example.com and you have created the Docker server named prod. You should replace example.com with your actual domain name, and prod with your actual docker instance name/stage.\nLogin to the DigitalOcean cloud console. Click Networking in the menu. Click the Domains tab. Find the domain you created earlier, and click it. Create an A record: Hostname: enter the subdomain name without the domain part (eg. prod, the name of your docker server, without the .example.com suffix). Will direct to: select the droplet you created from the list. Click Create Record. Create another A record, for the wildcard: Hostname: enter the same name as before but prepend *. in front of it (eg. if the server is named prod, create a record for *.prod, without the .example.com suffix). Will direct to: select the same droplet as before. Click Create Record. Optional: create additional records on the root domain. If you don’t want the docker instance name in the subdomain you give to people (eg. www.prod.example.com), you could create additional (non-wildcard) records on the root domain now (eg. www.example.com, or even just example.com). However, it would be wasteful to put a wildcard record on the root domain (*.example.com) because then the domain could only be used with a single Docker instance, therefore all records on the root should be non-wildcard, and this means you must add them one by one. Test that your wildcard record actually works. Use the dig command (For Debian/Ubuntu install the dnsutils package. For Arch Linux install bind-tools. For Fedora install bind-utils.)\nPick some random subdomain off your domain:\n[bash]: Run this on your workstation: dig laksdflkweieri.prod.example.com (stdout) ;; ANSWER SECTION: laksdflkweieri.prod.example.com. 3600 IN A 153.114.12.78 Since you created the wildcard record for *.prod.example.com dig should return your Docker server’s IP address in the ANSWER SECTION of the output. You can test all your other records the same way.\nIf you run into DNS caching problems, verify with the source DNS server directly:\n[bash]: Run this on your workstation: dig @ns1.digitalocean.com laksdflkweieri.prod.example.com Congratulations You have now finished installation of a remote host running Debian.\nYou must now configure your workstation to remotely control your remote Docker context.",
    "description": "This section will guide you to create your own public Docker server, using a DigitalOcean droplet as an example. In a similar fashion, you can install Docker on any cloud provider, or dedicated host that you prefer.\nChoosing a VPS provider One of the most basic units of cloud computing is the Virtual Private Server (VPS). A VPS is a (Linux) virtual machine that is provisioned by a cloud service, and you are given root access to fully administer it, to install whatever you want on it.",
    "tags": [],
    "title": "Create a public server (VPS)",
    "uri": "/d.rymcg.tech/required-infrastructure/public-docker-server/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "To remotely control your Docker host from your workstation, you need two additional configs:\nSSH Host config in ~/.ssh/config. Docker Context config via docker context create .... Both of these can be created automatically by running:\n[bash]: Run this on your workstation: d context new This will prompt you if you really want to proceed:\n(stdout) ? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y You can choose to create a new SSH config, or use an existing one:\n(stdout) ? You must specify the SSH config entry to use I already have an SSH host entry in ~/.ssh/config that I want to use \u003e I want to make a new SSH host entry in ~/.ssh/config [↑↓ to move, enter to select, type to filter, ESC to cancel] Enter the short one word name for the SSH Host entry:\n(stdout) ? Enter the new SSH context name (short host name) : foo Enter the fully qualified DNS name of the Docker host:\n(stdout) ? Enter the fully qualified SSH Host DNS name : foo.example.com It will propose to create a new SSH config entry that looks like this:\n(stdout) ## Here is the new SSH config entry: Host foo Hostname foo.example.com User root ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p ? Do you want to append this config to ~/.ssh/config? (y/N) y It will ask you if you want to immediately switch the active Docker context:\n(stdout) ? Do you want to switch to the new foo context now? (y/N) y foo Current context is now \"foo\" List all Docker contexts and switch the active one [bash]: Run this on your workstation: d context (stdout) ? Select the Docker context to use deb \u003e foo step-ca [↑↓ to move, enter to select, type to filter, ESC to cancel] Current context is now “foo” ",
    "description": "To remotely control your Docker host from your workstation, you need two additional configs:\nSSH Host config in ~/.ssh/config. Docker Context config via docker context create .... Both of these can be created automatically by running:\n[bash]: Run this on your workstation: d context new This will prompt you if you really want to proceed:\n(stdout) ? This command can help create a new SSH config and Docker context. Proceed? (Y/n) y You can choose to create a new SSH config, or use an existing one:",
    "tags": [],
    "title": "Create SSH config and Docker Context",
    "uri": "/d.rymcg.tech/workstation/ssh-config-and-docker-context/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Toolbox is an integral part of Fedora Atomic, being one of the main methods of installing software (the alternative being Flatpak), it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie. you can run ps or kill from inside the toolbox, and it will see/affect the host.) Toolbox containers are not sandboxed like normal Docker containers are, but they are a convenience for installing/removing software on Atomic hosts, because theres not really any other way (since the host filesystem is read-only). The applications you install in the container will live only inside the toolbox.\nThe killer feature of a toolbox is that it lets you try things out, and if you want to start over, you can just delete the toolbox container, and create a new one. You are less likely to mess up the host by playing around inside the toolbox. Just remember that /home is bind mounted to the host, and so if you change or delete things in those directories, they are also affected the same way on the host.\nDev toolbox (Fedora) Let’s create a toolbox to install some of the common development tools we will use on a daily basis.\n[bash]: Run this on your workstation: toolbox create dev This will create a new toolbox container called dev based upon the same Fedora version as the host (the toolbox itself is not Atomic though, but the normal Fedora Workstation version instead.)\nTo enter the toolbox run:\n[bash]: Run this on your workstation: toolbox enter dev This will enter the toolbox container, and now you can install extra software:\n[bash]: Run this on your workstation: sudo dnf install keychain htop sudo dnf groupinstall \"Development Tools\" \"Development Libraries\" Arch Linux toolbox You are not limited to running Fedora toolboxes, in fact you can run any container image you want, or even build your own from a Dockerfile. Here is a Dockerfile for Arch Linux you can use to build an Arch Linux toolbox container:\nEdit this file: Dockerfile FROM docker.io/archlinux/archlinux:latest ENV NAME=arch-toolbox VERSION=rolling LABEL com.github.containers.toolbox=\"true\" \\ name=\"$NAME\" \\ version=\"$VERSION\" RUN pacman -Syu --noconfirm \\ \u0026\u0026 pacman -S --noconfirm sudo inetutils less \\ git base-devel go \\ noto-fonts noto-fonts-cjk \\ noto-fonts-emoji noto-fonts-extra \\ \u0026\u0026 pacman -Scc --noconfirm \\ \u0026\u0026 echo \"%wheel ALL=(ALL) NOPASSWD: ALL\" \u003e /etc/sudoers.d/toolbox RUN sudo -u nobody git clone https://aur.archlinux.org/yay-bin.git /tmp/yay \\ \u0026\u0026 cd /tmp/yay \\ \u0026\u0026 sudo -u nobody makepkg -s \\ \u0026\u0026 pacman -U --noconfirm yay-bin-*.pkg.tar.zst CMD [\"bash\"] Write this to a file named Dockerfile and open your host terminal to the same directory. Then run this command to build the container:\n[bash]: Run this on your workstation: podman build -t arch . Now you can create a new toolbox based on the new image (both called arch):\n[bash]: Run this on your workstation: toolbox create --image arch arch To enter the Arch Linux container, run:\n[bash]: Run this on your workstation: toolbox enter arch Now that you’re inside the toolbox, you can run any Arch Linux command (consult the Arch Wiki).\nRun this inside the arch toolbox sudo pacman -Syu sudo pacman -S keychain base-devel Managing toolbox containers You can list all of your toolboxes that you’ve created:\n[bash]: Run this on your workstation: toolbox list You can remove existing toolboxes:\n[bash]: Run this on your workstation: toolbox rm --force arch (force is only required if the toolbox is currently running.)",
    "description": "Toolbox is an integral part of Fedora Atomic, being one of the main methods of installing software (the alternative being Flatpak), it lets you run your applications inside of Podman containers. Toolbox can actually be used on any Linux system that is capable of running Podman, but is especially useful on Atomic hosts. Toolbox is more tightly integrated with your host OS than Docker or Podman containers normally are. Toolbox containers share the same /home directory with the host (bind mounted), and they live in the same network and process namespace as the host (ie.",
    "tags": [],
    "title": "Toolbox",
    "uri": "/linux-workstation/config/toolbox/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).\nTo enable this, you need to be running your dev toolbox:\n[bash]: Run this on your workstation: toolbox enter dev Install Emacs:\nrun this inside the toolbox: sudo dnf install emacs Create Emacs script In order to be able to quickly launch Emacs inside the toolbox from the host, you will need a little script installed on the host.\nYou can create this script and put it in /usr/local/bin/emacs. Run this on the host (not in the toolbox), to create it as the root user:\nEdit this file: /usr/local/bin/emacs #!/bin/bash ## Run Emacs in the dev toolbox and pass it any args: toolbox run -c dev emacs $@ [bash]: Run this on your workstation: sudo chmod a+x /usr/local/bin/emacs Now you can run Emacs from the host, and it will run inside the Toolbox.\nInstall dependencies Most Emacs packages are written in Emacs Lisp, and therefore have no external dependencies. The one exception is for Vterm terminal support, which requires compiling a C library (libvterm). This compilation can be done automatically by Emacs, but it requires you have some tools preinstalled:\nCMake libtool Install the dependencies inside the toolbox:\nrun this inside the toolbox sudo dnf install cmake libtool Remove any existing Emacs config Assuming you want to use my Emacs config, you need to delete any existing config you already have. Also note that Emacs creates a default config the first time it runs, so if you started Emacs already, you may have a config and not even know it.\nHere’s how to remove the existing Emacs config:\n[bash]: Run this on your workstation: rm ~/.emacs ~/.emacs.d -rf Install my Emacs config My Emacs config is on github. Install it with the following script:\n[bash]: Run this on your workstation: REMOTE=git@github.com:EnigmaCurry/emacs.git REPO=${HOME}/git/vendor/enigmacurry/emacs BRANCH=straight (set -e test -d ~/.emacs.d \u0026\u0026 (echo “~/.emacs.d already exists. Aborting install.” \u0026\u0026 exit 1) test -d ${REPO} || git clone -b ${BRANCH} ${REMOTE} ${REPO} mkdir ~/.emacs.d \u0026\u0026 ls -1 ${REPO}/*.el | xargs -iXX ln -s XX ~/.emacs.d mkdir ~/.emacs.d/straight \u0026\u0026 ln -s ${REPO}/straight-versions ~/.emacs.d/straight/versions ln -s ${REPO}/snippets ~/.emacs.d/snippets ) Start Emacs to finish the installation The first time Emacs starts, it will install all of the dependencies listed in the main config file ~/.emacs.d/init.el.\nRun:\n[bash]: Run this on your workstation: emacs Wait for everything to install. You may see a blank screen for up to 10 minutes, but you should see some minimal information of the progress in the bottom minibuffer.\nIf it gets stuck at any point, quit and restart it, and it should continue where it left off. If you get any error message, you may want to start Emacs again with debug mode turned on:\n[bash]: Run this on your workstation: emacs --debug-init This will usually give you a more verbose error message which can be helpful in debugging the startup.\nRead the README for my config More notes are available in the README.",
    "description": "Emacs is my long time favorite code editor (IDE) and for writing documentation (including this book).\nInstall Emacs Because Sway runs on Wayland, you’ll want to install the Wayland (pgtk) version of Emacs. In Fedora 40 onwards, the Wayland (pgtk) version is already the default. For Fedora 39, you can use this COPR (a COPR is to Fedora what PPA is to Ubuntu and what AUR is to Arch Linux), which includes a custom build for Wayland (pgtk).",
    "tags": [],
    "title": "Emacs",
    "uri": "/linux-workstation/config/emacs-on-fedora/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "The base Debian image only has a few basic commands preinstalled. You must now install the Docker packages and enable the service:\nChoose the active Docker context d context [bash]: Run this on your workstation: d install-docker Tip d install-docker will install Docker on the remote VPS, according to your active docker context.\nTest that the context works from your workstation [bash]: Run this on your workstation: docker run hello-world [bash]: Run this on your workstation: docker ps ",
    "description": "The base Debian image only has a few basic commands preinstalled. You must now install the Docker packages and enable the service:\nChoose the active Docker context d context [bash]: Run this on your workstation: d install-docker Tip d install-docker will install Docker on the remote VPS, according to your active docker context.\nTest that the context works from your workstation [bash]: Run this on your workstation: docker run hello-world [bash]: Run this on your workstation: docker ps ",
    "tags": [],
    "title": "Install Docker on your remote host",
    "uri": "/d.rymcg.tech/workstation/install-docker-on-remote-host/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client. Create a server that acts as a bastion or “jump” host, to be a port of entry into a larger private network. SSH is configured to only allow authorized client keys access through the bastion host. Create a server to act as an HTTP (socks) client proxy, to allow remote clients to browse the web, using the server’s IP address as the origin. Remote controlling a Docker server using the docker command line client (SSH Docker Context). SSH is based upon public key cryptography. Both the client and the server need to create their own public/private keypair. Keys can be encrypted on disk (eg. ~/.ssh/id_ecdsa) or they may also be loaded from a USB hardware token. Upon connecting to a remote server for the first time, the client asks the user to validate the server’s public key fingerprint, and then the server’s public key is written into a file called ~/.ssh/known_hosts, which marks the connection as trusted from then on. The server also authorizes the client through a predefined authorized_keys file. If either side rejects the key presented by the other, the connection is unauthorized, and is closed immediately.\nCreate SSH Keys This book recommends the use of hardware authentication tokens, like the Solokey. Traditional SSH keyfiles are also acceptable, but these should be considered as a legacy format, as they are less secure. Finally, plain password authentication (non-key based) is fully deprecated and should never be used.\nSetup Solokey (FIDO2) hardware authentication Plug in your Solokey (or compatible hardware) to the USB port.\nInitialize the hardware with a new SSH key:\n[bash]: Run this on your workstation: ## You only need to do this one time per solokey! ssh-keygen -t ed25519-sk -O resident -O verify-required You will be required to create/enter a PIN for the Solokey.\nTraditional SSH keyfiles The Solokey still has some drawbacks, and cannot be used in all cases. Traditional SSH keyfiles are still useful for automated and unattended clients. Technically, the solokey is supposed to be able to work in a “touchless” mode, by using the -O no-touch-required option, but I never got this to work.\nKey files should be created uniquely for each user and workstation. They should never be shared between multiple users or workstations.\nChoosing the SSH key type It is recommended to use the newer ed25519 key type, which uses the latest encryption standards. Your distribution may still use the older standard rsa by default (which is acceptable). You should explicitly select the key type when creating the keyfile to be sure.\nSome older servers don’t accpet ed25519 keys, and so in those cases you should still create an rsa key as well. Each key type is stored in a different file, so its OK to have multiple types installed on the same machine.\nCreate the new SSH keys Create the rsa key type:\n[bash]: Run this on your workstation: ssh-keygen -t rsa -f ~/.ssh/id_rsa Create the ed25519 key type:\n[bash]: Run this on your workstation: ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 You will be prompted to enter an encryption passphrase for each file, which you should definitely not skip!\nSetup the ssh-agent Because your keyfiles are encrypted with a passphrase, you need to enter the passphrase everytime you use it. This is inconvenient, so you can run ssh-agent to temporarily store your key/identity in memory, and therefore you only need to enter your passphrase once, when you log in. (In the case of the solokey, the key is never held in memory, but you still need to hold the identity of it in the ssh-agent.)\nKeychain is a program that helps you setup the ssh-agent. Install keychain:\nRun this on your Fedora workstations: sudo dnf install keychain Run this on your Debian / Ubuntu workstations: sudo apt install keychain Run this on your Arch Linux workstations: sudo pacman -S keychain To configure keychain, edit your ~/.bashrc file:\nEdit this file: ~/.bashrc ## Put this line in your ~/.bashrc: ## (If you're using my config, this is already in it.) eval $(keychain --eval --quiet) Log out of your desktop session, and log back in. Open your terminal, and you should be automatically prompted to enter your SSH passphrase. Once you have entered the passphrase, the SSH key will remain resident in memory until you log out.\nDouble check that the key has been loaded, run:\nrun this inside your toolbox ssh-add -L The above should print your public key, loaded into the running ssh-agent. Now you should be able to use your key without entering a passphrase. Copy the output and upload it to your services as your authorized key. For servers, put the key into ~/.ssh/authorized_keys. For hosted services, like GitHub, paste the key into your SSH settings page.\nAdd your solokey identity per session Apparently, keychain does not yet know how to load the Solokey automatically. You must add the Solokey to the ssh-agent manually, one time, each time you boot your workstation:\nrun this inside your toolbox ## Do this to load your Solokey into the ssh-agent: ssh-add -K You will be prompted one time to enter your Solokey pin to unlock the key.",
    "description": "SSH (secure shell) is a secure networking tool used between a client and a server. Using an encrypted network protocol, it can be used to securely login to a server remotely, as well as for more advanded networking scenarios. Typical use cases for SSH include:\nAccess to a server’s console shell, remotely. Transfer files between the server and client (using rsync, scp, or sftp). Create network tunnels to access private servers, in both directions, either on the server, or on the client.",
    "tags": [],
    "title": "SSH",
    "uri": "/linux-workstation/config/ssh/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Linux Workstation \u003e Config",
    "content": "You can bend the workstation “no server” rule a bit, by hosting some development servers inside of virtual machines (VM). Keeping your servers in isolated VMs will keep your workstation clean. You can treat these VMs just like any other remote Linux host, and access them over SSH.\nThese instructions will install a barebones Debian server in a VM, with NAT networking (private IP address, no public ports open), for local development/testing purposes only.\nEnable libvirtd Create a dedicated user account for VM management Copy your public SSH key into the libvirt-admin home directory Create VM with the libvirt-admin user Run the commands in this section with the libvirt-admin user Configure temporary variables for a Debian VM config: Create directories to hold our VM disks and config files: Create the cloud-init config file: Download the cloud image: Clean up old VMs with the same name: Create the disk image for the new VM: Create the VM: Find the IP address of the VM (named debian) TODO Enable auto start on boot VM Management List all defined VMs Start VM (named debian) Stop VM (named debian) Undefine VM (named debian) Serial console of VM (named debian) Setup your normal workstation user for SSH access to VM Enable libvirtd [bash]: Run this on your workstation: sudo systemctl enable --now libvirtd Add the existing libvirt group to /etc/group :\n[bash]: Run this on your workstation: sudo bash -c \"getent group libvirt \u003e\u003e /etc/group\" (I’m not sure why Fedora Atomic doesn’t do this automatically)\nCreate a dedicated user account for VM management [bash]: Run this on your workstation: VM_ADMIN=libvirt-admin sudo useradd ${VM_ADMIN} -G libvirt sudo loginctl enable-linger ${VM_ADMIN} Copy your public SSH key into the libvirt-admin home directory [bash]: Run this on your workstation: SSH_KEY=~/.ssh/id_ed25519.pub TMP_SSH=$(mktemp) cat ${SSH_KEY} \u003e ${TMP_SSH} chmod a+r ${TMP_SSH} sudo su ${VM_ADMIN:-libvirt-admin} -c \"mkdir -p ~/libvirt \u0026\u0026 cp ${TMP_SSH} ~/libvirt/user-ssh.pub\" Create VM with the libvirt-admin user Run the commands in this section with the libvirt-admin user Info For this entire section you need to perform the VM config as the libvirt-admin user.\nLogin to the shell account of libvirt-admin:\n[bash]: Run this on your workstation: sudo su -l ${VM_ADMIN:-libvirt-admin}\nConfigure temporary variables for a Debian VM config: [bash]: Customize and set temporary environment variables CLOUD_IMAGE=https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2 NAME=debian OS_VARIANT=debian12 MEMORY=1024 CPUS=2 DISK_SIZE=50 MAC_ADDRESS=$(printf '00:60:2F:%02X:%02X:%02X\\n' $[RANDOM%256] $[RANDOM%256] $[RANDOM%256]) USER_DATA=~/libvirt/cloud-init/${NAME}.yaml Create directories to hold our VM disks and config files: [bash]: Run this on your workstation: mkdir -p ~/libvirt/{cloud-images,disks,cloud-init} Create the cloud-init config file: [bash]: Run this on your workstation: cat \u003c\u003c EOF | sed 's/\\xe2\\x80\\x8b//g' \u003e ${USER_DATA} #cloud-config hostname: ${NAME} users: ​ - name: admin ssh_authorized_keys: ​ - $(cat ~/libvirt/user-ssh.pub) sudo: ALL=(ALL) NOPASSWD:ALL EOF Download the cloud image: Tip You only need to download each CLOUD_IMAGE once, they will be cached in ~/libvirt/cloud-images, so they can be be reused.\n[bash]: Run this on your workstation: (cd ~/libvirt/cloud-images; curl -LO ${CLOUD_IMAGE}) chmod a-w ~/libvirt/cloud-images/$(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*$\") Clean up old VMs with the same name: Warning If you already have a VM with the same name, and you want to start again from scratch, you need to clean up from the previous install first:\n[bash]: Run this on your workstation: # To cleanup up and REMOVE an old VM named debian: virsh destroy debian virsh undefine debian\nCreate the disk image for the new VM: Warning This is destructive of the existing disk file!\n[bash]: Run this on your workstation: (set -e cp ~/libvirt/cloud-images/$(echo ${CLOUD_IMAGE} | grep -Po \".*/\\K.*\") \\ ~/libvirt/disks/${NAME}.qcow2 chmod u+w ~/libvirt/disks/${NAME}.qcow2 qemu-img resize ~/libvirt/disks/${NAME}.qcow2 +${DISK_SIZE}G echo Created ~/libvirt/disks/${NAME}.qcow2 ) Create the VM: Create VM using cloud image: virt-install \\ --name ${NAME} \\ --os-variant ${OS_VARIANT} \\ --virt-type kvm \\ --graphics none \\ --console pty,target_type=serial \\ --noautoconsole \\ --cpu host \\ --vcpus ${CPUS} \\ --memory ${MEMORY} \\ --network bridge=virbr0,model=virtio,mac=${MAC_ADDRESS} \\ --cloud-init user-data=${USER_DATA} \\ --import \\ --disk ~/libvirt/disks/${NAME}.qcow2 Wait a minute for the VM to boot and bring up its network interface. Find the IP address of the VM (named debian) [bash]: Run this on your workstation: NAME=debian MAC_ADDRESS=$(virsh domiflist ${NAME} | grep virbr0 | grep -Po \".* \\K.*$\") arp -n | grep $MAC_ADDRESS | cut -d \" \" -f 1 TODO Enable auto start on boot [bash]: Run this on your workstation: NAME=debian virsh autostart ${NAME} VM Management List all defined VMs [bash]: Run this on your workstation: virsh list -all (stdout) ​ Id Name State ​------------------------ ​ 5 debian running Start VM (named debian) [bash]: Run this on your workstation: virsh start debian Stop VM (named debian) [bash]: Run this on your workstation: ​# destroy actually just means stop, not delete virsh destroy debian Undefine VM (named debian) [bash]: Run this on your workstation: ​# undefine removes the VM configuration virsh undefine debian Serial console of VM (named debian) [bash]: Run this on your workstation: virsh console debian To exit the console, press Ctrl-]. (Control + right square bracket).\nSetup your normal workstation user for SSH access to VM Info For this section, you are back to using your normal workstation user.\nEdit your ~/.ssh/config and create a new config entry for the VM:\nEdit this file: ~/.ssh/config Host debian Hostname 192.168.122.42 User admin ControlMaster auto ControlPersist yes ControlPath /tmp/ssh-%u-%r@%h:%p With this config, you can now use SSH to control the VM:\n[bash]: Run this on your workstation: ssh debian whoami It is recommended to install Docker on your Debian VM. Please read the other book on Self-hosting Docker, and the chapter on installing Docker",
    "description": "You can bend the workstation “no server” rule a bit, by hosting some development servers inside of virtual machines (VM). Keeping your servers in isolated VMs will keep your workstation clean. You can treat these VMs just like any other remote Linux host, and access them over SSH.\nThese instructions will install a barebones Debian server in a VM, with NAT networking (private IP address, no public ports open), for local development/testing purposes only.",
    "tags": [],
    "title": "KVM / libvirt",
    "uri": "/linux-workstation/config/kvm-virt-manager/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker \u003e Setup your workstation",
    "content": "Select your active Docker context [bash]: Run this on your workstation: d context Each Docker context has a separate config file (.env_{CONTEXT}), stored in the root d.rymcg.tech directory (~/git/vendor/enigmacurry/d.rymcg.tech), so you must actively select your current context before you can configure it.\nConfigure d.rymcg.tech for the current Docker context [bash]: Run this on your workstation: d make - config This will create a config file for your current Docker context, and name it .env_{CONTEXT} (eg. .env_prod). You must run this for each new Docker context you create, so that each context has its own config file.\nThe interactive config will ask you to enter the ROOT_DOMAIN variable, which needs to be the root domain that you want to apply to your Docker host.\n(stdout) ROOT_DOMAIN: Enter the root domain for this context (eg. d.example.com) : prod.example.com The root domain serves as the example root domain for all application default configs.",
    "description": "Select your active Docker context [bash]: Run this on your workstation: d context Each Docker context has a separate config file (.env_{CONTEXT}), stored in the root d.rymcg.tech directory (~/git/vendor/enigmacurry/d.rymcg.tech), so you must actively select your current context before you can configure it.\nConfigure d.rymcg.tech for the current Docker context [bash]: Run this on your workstation: d make - config This will create a config file for your current Docker context, and name it .",
    "tags": [],
    "title": "Main config for d.rymcg.tech",
    "uri": "/d.rymcg.tech/workstation/main-config-for-d.rymcg/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "Traefik Proxy is a core service that acts as a gateway for all of the other applications installed on your Docker host. Everything that is served behind Traefik Proxy can take advantage of automatic TLS certificates (ACME), perform user authentication (mTLS, OAuth2, HTTP Basic), apply sentry authorization (user account filtering), and IP address filtering middlewares. Based on all of this criteria, Traefik Proxy ultimately decides whether to route incoming requests to the backend service containers, or to block it and return an error.\nConfigure Traefik Proxy [bash]: Run this on your workstation: d make traefik config This creates a config for Traefik on your active Docker context. The configuration is driven by a text wizard menu system.\n(stdout) ? Traefik config main menu: \u003e Create system user on Docker host Configure entrypoints (including dashboard) Configure Certificate Authorities (CA) Configure ACME (Let's Encrypt or Step-CA) Configure TLS certificates and domains (make certs) Configure middleware (including auth) v Configure error page template [↑↓ to move, enter to select, type to filter, ESC to cancel] Use your arrow keys to select a menu item and press the Enter key. To cancel, press the ESC key.\nOnce complete, it will have created and configured your .env_{CONTEXT} file for you.\nCreate system user on Docker host This option will create a new username on the Docker host, called traefik. This is necessary to reserve a unique UID for traefik to run as on the system. Run this first before anything else.\nConfigure entrypoints Traefik uses various entrypoints to allow requests on certain TCP ports. By default, only port 80 and 443 are enabled. You can enable extra entrypoints through this menu, which may be necessary for any application that doesn’t use the standard websecure entrypoint (port 443).\nBy default, the Traefik Dashboard is not enabled. To enable it, you must select it via this menu option, and set a username / password. It is only ever exposed to localhost, or through an SSH tunnel, never to the public network, but it is still best to leave it turned off if you don’t need it.\nConfigure Certificate Authorities (CA) If you’re planning on running a public server, using TLS certificates from Let’s Encrypt, you can skip this option.\nYou only need to run this if you wish to modify the TLS certificate trust store to accomodate a “self-signed” Step-CA authority.\nConfigure ACME (Let’s Encrypt or Step-CA) Choose this option to configure ACME, which makes requesting and renewing TLS certificates an easy and automatic process.\n(stdout) ? Which ACME provider do you want to use? \u003e Let's Encrypt (ACME) Step-CA (ACME) Disable ACME Cancel / Go back For most installs, you should choose Let's Encrypt (ACME). This is the only option that will create valid TLS certificates for public websites.\nIf you want to run private services, you may want to consider using Step-CA instead, as it does not rely upon any external platform like Let’s Encrypt does.\nFinally, if you want to setup TLS certificates manually, you can choose Disable ACME.\nConfigure Let’s Encrypt environment (stdout) ? Which LE environment do you want to use? \u003e Production (recommended!) Staging (untrusted / testing) Tip Always choose the Production environment, unless you really know what you’re doing. Production is the only environment that produces valid (trusted) TLS certificates.\nChoose type of ACME challenge (stdout) ? Which type of ACME challenge should be used? \u003e TLS-ALPN-01 (default for public servers, easy, but no wildcard certs) DNS-01 (requires API key, but good behind firewalls, and allows wildcard certs) Tip For your first install, choose TLS-ALPN-01, it is the easiest method to use for public servers.\nIf you want to use wildcard DNS records, you must choose the more advanced method DNS-01, and setup your DNS platform for programmatic access with an API token.\nConfigure ACME email address (optional) You don’t have to provide your email address, but if you do, Let’s Encrypt can email you about configuration issues, like certitficates about to expire.\nConfigure TLS certificates and domains d.rymcg.tech uses explicit certificate requests configured centrally, on the traefik project:\n(stdout) ? Configure Traefik TLS certificates \u003e Manage all certificates. Create a new certificate. Done / Go back Manage all certificates This will show you all the certificate requests that have been defined and allow you to manage each one. It will be blank to start out with.\nCreate a new certificate Use this to define all the certificates you need for all your applications.\nSet certificate main domain (CN) Each certificate needs a main name (CN), which should be the main domain name of the certificate.\nprod.example.com Info Each certificate may also contain several other domain names, known as SANs (Subject Alternative Names). You can use this to list as many additional domain names that you want to be listed on the same certificate.\nConfigure middleware Configure error page template Configure wireguard VPN Install Traefik To install Traefik (on your active Docker context), you can simply choose the Reinstall Traefik option in the menu, or you can run that step all by itself from the command line at any time:\n[bash]: Run this on your workstation: d make traefik install You should always reinstall Traefik after changing any configuration setting.",
    "description": "Traefik Proxy is a core service that acts as a gateway for all of the other applications installed on your Docker host. Everything that is served behind Traefik Proxy can take advantage of automatic TLS certificates (ACME), perform user authentication (mTLS, OAuth2, HTTP Basic), apply sentry authorization (user account filtering), and IP address filtering middlewares. Based on all of this criteria, Traefik Proxy ultimately decides whether to route incoming requests to the backend service containers, or to block it and return an error.",
    "tags": [],
    "title": "Install Traefik Proxy",
    "uri": "/d.rymcg.tech/install-traefik-proxy/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Self-hosting Docker",
    "content": "Whoami is a very simple application, but you can learn a lot from it. After you install Traefik, whoami should be the very first application that you install. It can help you test whether or not your Traefik installation is functioning properly.\nYou should study the configuration of whoami, as it is used as a template for all the other apps provided by d.rymcg.tech. Because of its simplicity, it reduces the complexity of its core components. Whoami can be a good base template for creating your own d.rymcg.tech enabled applications.\nWhat is Whoami? Quickstart Features Configuration Default config file (.env-dist) Configure whoami WHOAMI_TRAEFIK_HOST Sentry authorization Edit the config file by hand Configuration variables Install whoami Open whoami in your web browser View the logs What is Whoami? Whoami is a web application that simply outputs the request headers that it receives itself (reflecting them back to the requesting client):\n[bash]: Run this on your workstation: ## Use your own whoami URL here once you install it: curl https://whoami.example.com (stdout) Name: default Hostname: 38704012c4b3 IP: 127.0.0.1 IP: ::1 IP: 172.19.0.2 RemoteAddr: 172.19.0.1:34610 GET / HTTP/1.1 Host: whoami.example.com User-Agent: curl/7.88.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 10.93.23.114 X-Forwarded-Host: whoami.example.com X-Forwarded-Port: 443 X-Forwarded-Proto: https X-Forwarded-Server: docker X-Real-Ip: 10.93.23.114 This output is useful for end-to-end testing, to verify that the application is capable of serving requests, and that all of the configuration is correct.\nQuickstart Create a new config:\n[bash]: Run this on your workstation: d make whoami config The first question the config asks for is WHOAMI_TRAEFIK_HOST which should be the fully qualified domain name that the whoami app will use for its URL:\n(stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com) ​: whoami.prod.rymcg.tech Optional authentication can be configured:\n(stdout) ? Do you want to enable sentry authentication in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) For now, choose No, to disable authentication. We’ll get back to that later.\nInstall whoami:\n[bash]: Run this on your workstation: d make whoami install Open whoami:\n[bash]: Run this on your workstation: d make whoami open Or just open your web browser to the URL https://{WHOAMI_TRAEFIK_HOST}\nFeatures See the upstream whoami documentation and feature list here.\nIn addition to the features that whoami provides, there are several features that d.rymcg.tech provides through its own configuration and Traefik middlewares:\nRunning multiple separately-configured instances (Instantiation). Traefik sentry authorization per instance (mTLS, OAuth2, HTTP Basic auth). Source IP address filtering (blocking) per instance. Configuration Default config file (.env-dist) The default configuration file is named .env-dist. This config file is used as a template, which is copied whenever you configure a new instance of the application.\nTip The .env-dist file should not be edited normally. It should always contain the default configuration. Each instance will make its own copy of this, and it is inside the copy that you have the opportunity to change those defaults per instance (.env_{CONTEXT}_{INSTANCE}).\nEvery application instance has a unique config file, and the config target automatically creates one if necessary.\nConfigure whoami [bash]: Run this on your workstation: d make whoami config Info The config target configures the specific .env file of the instance: .env_{CONTEXT}_{INSTANCE}. Since we didn’t specify an instance name, the instance name is default. If your Docker context is named prod, then the full instance config file is named .env_prod_default.\nWarning You should not share the .env_{CONTEXT}_{INSTANCE} files. They should not be commited to the git repository. They are listed in the .gitignore file, so you should only have one copy of these files, living on your workstation. If these configs are important to you, you should make an encrypted backup.\nRun d make - backup-env to make a GPG encrypted backup file of all your .env files.\nTheres nothing particularly important inside the whoami .env files, but this is a general warning, as many apps will store their sensitive API keys or passwords in this file.\nConfigure multiple whoami instances Tip Most times you only need one instance of a given app, so you don’t need to set an instance name, and the name default will be used automatically.\nIf you want to configure multiple instances, run d make whoami instance for each one. You can configure unique names for each instance, and they will each have their own .env file: .env_{CONTEXT}_{INSTANCE}.\nd make whoami instance starts a sub-shell so that all commands will run on that instance now by default. Press Ctrl-D to exit the sub-shell, and it will go back to the original default instance (named default).\nWHOAMI_TRAEFIK_HOST The first question the config asks for is WHOAMI_TRAEFIK_HOST which is the fully qualified domain name that the whoami app should use for its URL:\n(stdout) WHOAMI_TRAEFIK_HOST: Enter the whoami domain name (eg. whoami.example.com) ​: whoami.prod.rymcg.tech ﻿ The default name uses the ROOT_DOMAIN variable you set as part of the main d.rymcg.tech config, which is also named after our current Docker context (prod). Realistically, the WHOAMI_TRAEFIK_HOST may be set to any valid domain name, you just need to setup the DNS for it (to point to the IP address of the Docker host).\nSentry authorization Another question it asks you is about sentry authorization:\n(stdout) ? Do you want to enable sentry authorization in front of this app (effectively making the entire site private)? \u003e No Yes, with HTTP Basic Authentication Yes, with Oauth2 Yes, with Mutual TLS (mTLS) Sentry authorization is a collection of middlewares that are deployed in front of your application to allow specific users entry into your app, while denying others, based on a variety of authentication methods. It does not implement any fine-grained permissions in the application itself, but it does filter who can come in the front door. It provides the application with the verified username of the authenticated clients via the X-Forwarded-User HTTP header. Any application may implement additional fine-grained permissions based on this trusted header field.\nTo configure sentry authorization, you can choose any of these choices:\nIf you select No, then sentry authorization will be turned off. The X-Forwarded-User header field will always be blank. Any client will be able to access the application without authenticating (however the application may still perform authentication by itself). If you select Yes, with HTTP Basic Authentication, the application will require all clients to enter a username/password into a dialog presented by the web browser. Clients who enter an incorrect username or password will not be able to view the page. The X-Forwarded-User header field will be set to the username of the authenticated user. If you select Yes, with OAuth2, the application will require all clients to authenticate with another OAuth2 compatible application, which may be a self-hosted Forgejo instance, or it can be an external service like GitHub. Access is granted only to those users who are listed in the corresponding Traefik authorization group that the application is configured for. The X-Forwarded-User header field will be set to the email address of the user’s verified account. If you select Yes, with mTLS, the application will require all clients to authenticate with a client mTLS certificate. Access is granted only to those certificate names that are listed in the application’s config. The X-Forwarded-User header field will be set to the Common Name (CN) of the client certificate with the prefix CN= (eg. CN=client1.example.com) Edit the config file by hand Once the config script has finished, the config file may be inspected to verify valid settings:\n[bash]: Run this on your workstation: d make whoami config-edit This will automatically open the whoami config file for the current context/instance in your default text editor (eg. set EDITOR=/usr/bin/emacs in your ~/.bashrc file), and you may make any changes, and save the file again.\nYou can also open the file manually, the path is ~/git/vendor/enigmacurry/d.rymcg.tech/whoami/.env_{CONTEXT}_{INSTANCE}.\nConfiguration variables WHOAMI_TRAEFIK_HOST This sets the fully qualified domain name of the application.\nWHOAMI_INSTANCE This sets the name of the whoami instance. If left blank, the default name is default.\nWHOAMI_IP_SOURCERANGE This sets the acceptable IP addresses ranges for incoming requests. It is a comma separated list of CIDR formatted netmasks.\nHere are some example settings:\nWHOAMI_IP_SOURCERANGE=0.0.0.0/0 - allow any access from any IP address. WHOAMI_IP_SOURCERANGE=0.0.0.0/32 - allow NO access from any IP address. WHOAMI_IP_SOURCERANGE=192.168.1.0/24,10.3.4.0/24 - allow access ONLY from two different /24 networks (512 addresses in two ranges, comma separated): 192.168.1.0 to 192.168.1.255 10.3.4.0 to 10.3.4.255 WHOAMI_HTTP_AUTH If this is blank, sentry authorization with HTTP Basic Authentication will be disabled (default). Otherwise, this should set the Traefik BasicAuth authorized users list. Don’t attempt to edit this field by hand, as the syntax is very complex. Always use the d make whoami config tool to set it correctly.\nWHOAMI_OAUTH2 If this is blank, or set to false, then sentry authorization with OAuth2 will be disabled (default). If set to true then it will be enabled.\nYou must separately install Traefik Forward Auth\nWHOAMI_OAUTH2_AUTHORIZED_GROUP If WHOAMI_OAUTH2=true, then WHOAMI_OAUTH2_AUTHORIZED_GROUP must be set, which is the name of the authorization group that should be allowed access.\nTip Authorization groups are set separately in the Traefik config:\n[bash]: Run this on your workstation: d make traefik config\nChoose the menu Configure middleware (including auth).\nChoose the sub-menu OAuth2 sentry authorization (make sentry).\nCreate a new authorization group lists and add authorized email\naddresses.\nReinstall Traefik\nIn the whoami config, set WHOAMI_OAUTH2_AUTHORIZED_GROUP to the\nname of the group you created.\nWHOAMI_MTLS_AUTH If this is blank, or set to false, then sentry authorization with mTLS will be disabled (default). If set to true then it will be enabled.\nWHOAMI_MTLS_AUTHORIZED_CERTS If WHOAMI_MTLS_AUTH=true, then WHOAMI_MTLS_AUTHORIZED_CERTS must be set, which is the list of the certificates names (CN) that should be allowed.\nWildcards are allowed, so a good setting could be like *.clients.example.com to allow any client subdomain of clients.example.com.\nInstall whoami Once the configuration has been verified, you can install the application:\n[bash]: Run this on your workstation: d make whoami install Open whoami in your web browser Once installed, the application should be ready to view in your web browser:\n[bash]: Run this on your workstation: d make whoami open This will automatically open your default web browser to the URL of the installed whoami application. If you want to do so manually, just go to the same URL as you configured for WHOAMI_TRAEFIK_HOST.\nView the logs It may be necessary to inspect the applicaiton logs, which you can do so as follows:\n[bash]: Run this on your workstation: d make whoami logs ",
    "description": "Whoami is a very simple application, but you can learn a lot from it. After you install Traefik, whoami should be the very first application that you install. It can help you test whether or not your Traefik installation is functioning properly.\nYou should study the configuration of whoami, as it is used as a template for all the other apps provided by d.rymcg.tech. Because of its simplicity, it reduces the complexity of its core components.",
    "tags": [],
    "title": "Whoami",
    "uri": "/d.rymcg.tech/whoami/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content",
    "content": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Nested … Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Example of a deeply …",
    "uri": "/publishing-with-org-mode/examples/deeply/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply …",
    "content": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "description": " Index Sub-chapter 1 Sub-chapter 2 Sub-chapter 3 ",
    "tags": [],
    "title": "Nested …",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "description": "This is a deeply nested sub-chapter. Take a look at the Org source. It requires that you create several headings and create the index in a sub-heading of the same name. It is a strangeness about ox-hugo that this is required. If you make a strictly hierarchical outline, the content will be duplicated, however the structure we’re using hides the nested content on the index pages, leaving it for the nested page only.",
    "tags": [],
    "title": "Sub-chapter 1",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter1/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 2",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter2/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech \u003e Publishing with org-mode \u003e Example Org / Hugo content \u003e Example of a deeply … \u003e Nested …",
    "content": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "description": "This is another deeply nested sub-chapter as a sibling of the one before it.",
    "tags": [],
    "title": "Sub-chapter 3",
    "uri": "/publishing-with-org-mode/examples/deeply/nested/subchapters/subchapter3/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:\nThe MIT License (MIT) Copyright (c) 2021 Sören Weber Copyright (c) 2017 Valere JEANTET Copyright (c) 2016 MATHIEU CORNIC Copyright (c) 2014 Grav Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "description": "book.rymcg.tech is © 2023, 2024 EnigmaCurry.\nExcept as listed below, all books and other files in this domain and/or git repository are licensed: Creative Commons Attribution 4.0. You can reference this repository like this, or by any other content equivalent custom formatting:\nbook.rymcg.tech is © 2024 EnigmaCurry used by permission CC BY 4.0See the full CC BY license at http://creativecommons.org/licenses/by/4.0\nExceptions The compiled/rendered HTML site uses hugo-theme-relearn which is distributed under the MIT license:",
    "tags": [],
    "title": "LICENSE",
    "uri": "/license/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "book.rymcg.tech",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
